%!TEX program = xelatex
\documentclass[a4paper]{report}
\usepackage[ngerman, english]{babel}
\usepackage[nottoc]{tocbibind}
\usepackage{csquotes}
\usepackage{amsmath,amsfonts,amssymb,amsthm,bbm,mathrsfs}
\usepackage{comment}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{makeidx}
\usepackage{showidx}
\usepackage{pgf,tikz,pgfplots}
\usetikzlibrary{arrows, positioning}
\pgfplotsset{compat=1.16}
\makeindex

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem*{theorem*}{Theorem}
\newtheorem*{theoremmain*}{Theorem \ref{thm:DiscMainThm}}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{property}[theorem]{Property}
\newtheorem{properties}[theorem]{Properties}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{definition}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{fact}[theorem]{Fact}

\numberwithin{equation}{chapter}

\hypersetup{%
  colorlinks = true
}

%Afkortingen voor wiskundige symbolen
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\renewcommand{\C}{\mathbb{C}}

\let\P\relax
\DeclareMathOperator{\P}{\mathbb{P}}
\DeclareMathOperator{\V}{\mathbb{V}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\1}{\mathbbm{1}}
\newcommand{\F}{\mathcal{F}}
\renewcommand{\G}{\mathcal{G}}
\renewcommand{\H}{\mathcal{H}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}

\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\range}{range}
\DeclareMathOperator{\acc}{acc}

\newcommand{\Pmod}{\mathcal{P}^*}
\newcommand{\Psafe}{\tilde{\P}}
\newcommand{\Uonesafe}{\tilde{\1}_U}
\newcommand{\Usafe}{\tilde{U}}

\newcommand{\EnvInd}{\1_{\{B=2A\}}}
\newcommand{\EnvIndSafe}{\tilde{\1}_{\{B=2A\}}}
\newcommand{\MontyInd}{\1_{\{U=a\}}}
\newcommand{\DieInd}{\1_{\{U=3\}}}
\newcommand{\DieIndSafe}{\tilde{\1}_{\{Y=3\}}}
\newcommand{\ChildInd}{\1_{\{U=bg\}}}
\newcommand{\ChildIndSafe}{\tilde{\1}_{\{U=bg\}}}
\newcommand{\ChildTwoInd}{\1_{\{U=bb\}}}
\newcommand{\ChildTwoIndSafe}{\tilde{\1}_{\{U=bb\}}}
\newcommand{\GeneralInd}{\1_{\{U=u\}}}
\newcommand{\GeneralGenInd}{\1_{\{U\in\X'\}}}
\newcommand{\GeneralGenIndSafe}{\tilde{\1}_{\{U\in\X'\}}}

\title{Thesis}
\author{Mathijs Kolkhuis Tanke}
\date{\today}

\begin{document}
\begin{titlepage}
\pagenumbering{gobble}

\maketitle
\end{titlepage}

\pagenumbering{roman}

\begin{abstract}
This is my thesis.
\end{abstract}


\pagenumbering{roman}
\setcounter{page}{2}
\tableofcontents

\chapter{Introduction}
\pagenumbering{arabic}
Probability theory is one of the most important and most researched fields in mathematics. It is in essence based on just three axioms first stated by Andrey Kolmogorov \cite{Kolmogorov33}, namely that the probability of an event is non-negative, the probability measure is a unit measure and the probability measure is countably additive on disjoint sets. These three axioms however do not prevent the existence of certain paradoxes, like the Borel-Kolmogorov paradox, Monty Hall's problem and the Sleeping Beauty problem. Some paradoxes arise from wrongly using probability theory, others are a misinterpretation of results.

This thesis focuses mainly paradoxes arising from conditional probability, such as the Borel-Kolmogorov paradox, Monty Hall's problem and the two envelope problem. We study will these problems and address their paradoxical nature. Ultimately it will be shown that all paradoxes arise by incorrectly applying conditional probability.

Take a look at the Borel-Kolmogorov paradox first. A sphere is equipped with the uniform probability measure. Suppose a point exists on a great circle of the sphere, but you do not know where that point is. Is there a probability distribution on this great circle for that point? If one models this problem using latitudes, the conditional distribution on the great circle is uniform. However, if one models this problem using meridians, the conditional distribution is a cosine.

Borel \cite{Borel09} and Kolmogorov \cite{Kolmogorov33} both addressed this problem and Kolmogorov gave the following answer:
\foreignblockquote{ngerman}[Andrey Kolmogoroff, \cite{Kolmogorov33}]{Dieser Umstand zeigt, daß der Begriff der bedingten Wahrscheinlichkeit in bezug auf eine isoliert gegebene Hypothese, deren Wahrscheinlichkeit gleich Null ist, unzulässig ist: nur dann erhält man auf einem Meridiankreis eine Wahrscheinlichkeitsverteilung für [Breite] Theta, wenn dieser Meridiankreis als Element der Zerlegung der ganzen Kugelfläche in Meridiankreise mit den gegebenen Polen betrachtet wird.}
In summary, Kolmogorov states that the concept of conditional probability on a great circle is inadmissible, since the event that the point lies on a great circle of the sphere has zero measure. Furthermore, the sole reason of a cosine distribution on a great circle arising when considering meridians is that the meridian circle serves as an element of the decomposition of the whole spherical surface in meridian circles with the poles considered.

Despite Kolmogorov's explanation this problem is still upon debate. Recently Gyenis, Hofer-Szabó and Rédei \cite{Gyenis17} studied this problem and provided more insight and an in my opinion satisfying discussion to the problem, eventually drawing the same conclusion as Kolmogorov already did. This problem is more elaborately discussed in Chapter~\ref{chap:BorelKolmogorov} where we will expand the analysis of \cite{Gyenis17} and not only consider latitudes and meridians, but their combination as well. Furthermore, we will look whether a conditional probability on a zero set can be uniquely approached by traditional conditional probability on sets of decreasing measure as stated in Conjecture~\ref{con:BorelConjecture}. This conjecture turns out to be false, again affirming that conditional probabilities on sets of measure zero are not uniquely defined.

Another paradox arising from conditional probability is Monty Hall's problem. In Monty Hall's problem, a player is facing three doors called $a$, $b$ and $c$. One door has a car behind and the other two have goats. Suppose the player initially chooses door $a$. The game master then opens either door $b$ or $c$, but always a door with a goat. The player now faces two doors and is asked whether he wants to switch. One possible solution is that the player faces two doors without any preference for either door, thus the probability is 50\%. Another possible solution is that first the player had a 33\% chance of correctly guessing the door with the car. If for example door $c$ is opened, door $b$ remains with a conditional probability of 67\% of having the car. Which solution is correct?

Let $\X=\{a,b,c\}$ be the set of doors and $U$ the random variable denoting the location of the car. Conditional probability then states
\begin{equation*}\label{eq:IntMonty}
\P[U=b\mid U\in\{a,b\}]=\frac{\P[U=b,U\in\{a,b\}]}{\P[U\in\{a,b\}]}=\frac{\frac{1}{3}}{\frac{2}{3}}=\frac{1}{2},
\end{equation*}
supporting the claim that a probability of 50\% is the correct answer. However, the space conditioned on door $c$ is opened is $\{a,b\}$ and the space conditioned on door $b$ is opened is $\{a,c\}$. If door $a$ has the car, the game master can open either door and the set of events we must condition on is $\{\{a,b\},\{a,c\}\}$. These two events do not form a partition, preventing us from using traditional conditional probability.

Thus in addition to Kolmogorov's statement, we must not only be wary for conditioning on events with measure 0, we cannot condition on arbitrary events at all. I propose that when using conditional probability, one must provide a pair of a sub-$\sigma$-algebra and the event from that $\sigma$-algebra to condition on. Regarding Monty Hall's problem there is no $\sigma$-algebra on $\{a,b,c\}$ containing the set $\{\{a,b\},\{a,c\}\}$. In the case of the Borel-Kolmogorov paradox providing sub-$\sigma$-algebras immediately make clear why the conditional distribution on a great circle is not unique, as both calculations are supported by different sub-$\sigma$-algebras.

The crux of the Monty Hall problem is that the initial distribution of the car is unknown and the player does not know with which probability door $b$ is opened given the car is behind door $a$. Thus there is a set of different possible probability distributions where one is the correct distribution. Using the theory of \emph{safe probability} we can obtain a strategy that give equal results for all distributions in a specified model. This theory is introduced by Grünwald \cite{Grunwald18} and summarized here in Chapter~\ref{chap:SafeProp}. Safe probability is then applied in Chapter~\ref{chap:DiscPara} to problems as the Monty Hall problem and to the two envelope problem in Chapter~\ref{chap:TwoEnvelope}.

In Chapter~\ref{chap:DiscPara} the results of the analysis of Monty Hall's problem are generalized to a theorem, which can be used to provide safe distributions for other problems like the boy or girl problem.
\begin{theoremmain*}
Let $\X$ be countable and $\Y$ be finite. Let $U$ be an $\X$-valued random variable and $V$ be a $\Y$-valued random variable. Let $p_u\in[0,1]$ with $\sum_{u\in\X}p_u=1$. Let
\begin{equation}
\Pmod\subseteq\{\P\mid\forall u\in\X:\P[U=u]=p_u\}
\end{equation}
be our model of probability distributions on $\X\times\Y$ where $|\Y|$ distributions $\P_1,\ldots,\P_{|\Y|}\in\Pmod$ impose $|\Y|$ linearly independent vectors $(\P_i[V=v])_{v\in\Y}$ with $i\in\{1,\ldots,|\Y|\}$. Let $u\in\X$ be arbitrary and let $\Psafe$ be a distribution on $\X\times\Y$ with full support on $V$, then the following are equivalent:
\begin{enumerate}
    \item For all $v\in\Y$ we have $\Psafe[U=u|V=v]=p_{u}$.
    \item $\Psafe$ is safe for $\GeneralInd|[V]$.
    \item $\Psafe$ is safe for $\langle\GeneralInd\rangle|\langle V\rangle$.
\end{enumerate}
\end{theoremmain*}

This theorem and its notation will be explained, proven and applied in Chapter~\ref{chap:DiscPara}, but it essentially states the following: in the case of the Monty Hall problem if one assumes the car is initially distributed evenly between the doors, the probability of the car being behind the originally chosen door $a$ can be assumed to be $\frac{1}{3}$. Using this assumption one must always switch to the other door as the probability of the car being behind that door can be assumed to be $\frac{2}{3}$, resulting in a 67\% chance of winning the car. It is not at all clear whether this is the correct distribution. However, this assumption always yields to a 67\% chance of winning the car independent on the probability of opening door $b$ when the car is behind door $a$.

Another paradox we will treat is the two envelope problem. There are two envelopes, where one is filled with value $a$ and the other with value $b$. The only thing the player knows is that either $a=2b$ or $b=2a$. An envelope is given to the player, with the player receiving either envelope with equal probability. Call this envelope~$A$ and suppose the player observes value $a$. Should he switch to envelope~$B$ or keep the contents of $A$?

At first glance, he should. Either $b=2a$ or $b=\frac{a}{2}$ holds with equal probability, thus \[\E[B|A=a]=\frac{1}{2}\cdot2a+\frac{1}{2}\cdot\frac{a}{2}=\frac{5}{4}a.\]
However, the player has received an envelope at random and only knows the contents of that particular envelope. So he could also have been given envelope~$B$ with value $b$, for which $\E[A|B=b]=\frac{5}{4}b$ holds. Therefore no matter what envelope the player receives, he should switch. This solution must clearly be wrong and it is. When conditioning on $A=a$, then either $b=2a$ or $a=2b$ holds with probability $1$ in the conditioned probability space. This renders the previous calculation of $\E[B|A=a]$ to be incorrect. However, we do not know which event takes place.

Now let $x=\min\{a,b\}$ be the lowest value, then either $a=x$ or $a=2x$ holds with equal probability. For both envelopes we now have
\[
\E[A|B=b]=\E[B|A=a]=\frac{1}{2}x+\frac{1}{2}\cdot2x=\frac{3}{2}x.
\]
Both envelopes thus have on average the same contents, as is expected when the envelopes are handed out uniformly. Unfortunately, we do not know the value of $x$. Furthermore, if $x$ is picked from an unbounded set and we assume that given an observation the other envelope must hold twice as much or half the value with equal probability, then $x$ must be taken from a uniform probability distribution on the unbounded set. Such distribution does not exist. We conclude that the value of $\E[B|A=a]$ does depend on a prior distribution on the chosen value $x$.

There are two ways to address this problem. Using safe probability, like in the case of Monty Hall, we will devise a strategy where the player wins $\frac{3}{2}\E[X]$ on average, where $X$ the actual unknown distribution for the lowest value in the envelopes on the positive number line with finite expectation. This strategy is in fact that the player must flip a fair coin and switch when it lands heads, which is quite intuitive.\\
Another method is using a switching strategy introduced by McDonell and Abbott~\cite{McDonnell09,Abbott10,McDonnell11}. Let $f\colon (0,\infty)\to[0,1]$ be a function that takes an observation $a$ and equips it with a probability. The player must switch with probability $f(a)$ when observing value $a$. When $f$ is a decreasing function and strictly decreases on an interval where distribution $X$ has positive measure, then switching using $f$ will always return on average a higher value than $\frac{3}{2}\E[X]$. If $f$ is a threshold switch, for example $f=\1_{(0,a^*]}$, then for some distributions $X$ the strategy $f$ is actually the best strategy available. However, when playing the game, the player does not know how much strategy $f$ outperforms switching using safe probability. By any means, distribution $X$ gives $f$ an arbitrarily small advantage over safe probability, making it an unnecessarily complicated method to marginally increase the average value won.

The two envelope problem will be discussed further in Chapter~\ref{chap:TwoEnvelope}.

For every problem there is a different reason for getting paradoxical results. There is one recurring theme with all paradoxes, namely when analysing these problems most of the times the underlying $\sigma$-algebra is not taken into account. This yields to various conflicting results, as conditioning on events that cannot be conditioned on to not recognizing that multiple probability distributions are possible. The theme of is thesis this therefore that when doing probability theory, the underlying probability space and $\sigma$-algebra must never be ignored and not providing a sub-$\sigma$-algebra with a conditional distribution must become a bad habit instead of an accepted practice.

\chapter{The Borel-Kolmogorov paradox}\label{chap:BorelKolmogorov}
The first paradox we will study in more detail is the Borel-Kolmogorov paradox. It was first studied by Borel \cite{Borel09} and Kolmogorov \cite{Kolmogorov33} and has sparked debate over the centuries afterwards\footnote{Bronnen lezen en invoeren.}. We will take a look at the following version of the paradox.

Suppose a random variable has a uniform probability distribution on the unit sphere. If one conditions on a great circle, what will the resulting conditional distribution be? If the great circle is viewed as a latitude, the conditional distribution will be uniform as well. However, if the great circle is modelled as a meridian, the conditional distribution has a cosine as density function. We have two different conditional distributions on the same set, thus which one is correct?

The basic solution to the paradox is to use measure-theoretic conditional probability, so that one is given not just a set like a great circle to condition on but rather a set and an accompanying sub-$\sigma$-algebra containing this set. The definition of measure-theoretic conditional probability now provides an answer that is unique and meaningful up to a set of zero measure. When conditional probability is defined traditionally based on density functions, it is defined on every point even though each such point has measure zero. One may now ask the following question: can we generally extend the measure-theoretic conditional probability to be defined on all points once a sub-$\sigma$-algebra is provided, by treating the conditional probability at that point as a limit of traditional conditional probabilities where one conditions on smaller and smaller sets? In Section~\ref{sec:BorelCombining} we provide Conjecture~\ref{con:BorelConjecture} that would imply this, but we will then show this conjecture is wrong. If we condition on both a given meridian and a suitably rotated latitude, then two phenomena occur:
\begin{enumerate}
\item the only sub-$\sigma$-algebra that we can provide is the full Borel $\sigma$-algebra and conditioning on the full $\sigma$-algebra leads to no effect and
\item the required limit is undefined as the limit of smaller and smaller meridians takes on a different value than the limit of smaller and smaller rotated latitudes.
\end{enumerate}

Kolmogorov \cite{Kolmogorov33} pointed out that the great circle has zero measure and according to him conditioning on a great circle must not be allowed. Our analysis will concern conditioning on zero sets using measure-theoretic conditional expectations as such conditioning is defined there. The article of Gyenis, Hofer-Szabó and Rédei \cite{Gyenis17} is followed to compute the conditional distributions on the great circle, viewing that circle both as latitude and as meridian. The authors draw the same conclusion as in \cite{Kolmogorov33} but with a far more elaborate explanation. We will take it one step further to also consider the $\sigma$-algebra of both the meridians and latitudes and to consider conditional distributions on rotated latitudes making them coincide with meridians. We will then conclude that once again conditioning on measure zero sets must not be admissible, as it will lead to contradicting results.

After drawing these conclusions, we will rename the Borel-Kolmogorov paradox to the \emph{Borel-Kolmogorov phenomenon}, as it is more an example on why you should not condition on zero sets than it is a paradox.

\section{Conditional expectation}
First we need to define conditional expectations. We use the standard measure-theoretic definitions as given by David Williams \cite{Williams91}.

Let $\Omega$ be an arbitrary sample space and let $\mathcal{F}$ be a $\sigma$-algebra on $\Omega$. The indicator function $\1_A$ on a set $A$ is defined as
\begin{equation}
\1_A(x)=\begin{cases}1,&x\in A,\\0,&x\not\in A.\end{cases}
\end{equation}
Let $\B(A)$ be the $\sigma$-algebra of all Borel-measurable sets on $A\subseteq\R^n$. We will start with the definition of a random variable.

\begin{definition}[Random variable]
Let $\X$ be a measurable space. A function $X\colon\Omega\to\X$ is an \emph{$\X$-valued random variable} if it is $\F$-measurable, thus if $X^{-1}(A)\in\F$ holds for all $A\in\G$ where $\G$ is a $\sigma$-algebra on $\X$.
\end{definition}

We can now define the conditional expectation as definition 9.2 of \cite{Williams91}.

\begin{definition}[Conditional expectation]\label{def:conexp}
Let $X$ be an $\F$-measurable random variable with finite $\E[|X|]$. Let $\G$ be a sub-$\sigma$-algebra of $\F$. There exists a random variable $Y$ such that
\begin{enumerate}
\item $Y$ is $\G$-measurable,
\item $\E[|Y|]$ is finite,
\item for every $G\in\G$ we have
\begin{equation}
\int_G Yd\P=\int_G Xd\P.
\end{equation}
\end{enumerate}
$Y$ is called a \emph{version of the conditional expectation} $\E[X|\G]$ of $X$ given $\G$, written as $Y=\E[X|\G]$ almost surely. Moreover, if $\tilde{Y}$ is another random variable with these properties, then $\tilde{Y}=Y$ equal almost surely. Since two versions of $\E[X|\G]$ coincide almost surely, $Y$ is also called \emph{the} conditional expectation $\E[X|\G]$.
\end{definition}

Note that when $\G=\sigma(Z)$ is the smallest $\sigma$-algebra generated by a set $Z\in\F$, we also write $\E[X|\G]=\E[X|Z]$. This generalizes to $\E[X|\G]=\E[X|Z_1,Z_2,\ldots]$ when $\G=\sigma(Z_1,Z_2,\ldots)$.

Definition~\ref{def:conexp} extends very nicely to the definition of conditional probability. Note that $\E[\1_F]=\P[F]$ holds for all $F\in\F$ and this carries over to conditional probabilities.

\begin{definition}[Conditional probability]
If $\G$ is a sub-$\sigma$-algebra of $\F$ and $F\in\F$, then the \emph{conditional probability} $\P[F|\G]$ is a version of $\E[\1_F|\G]$.
\end{definition}

\subsection{Comparison to traditional definitions}
The traditional definition of traditional density-based conditional expectation and probability is the following: when $X$ and $Y$ are two random variables on $\R$, $f_{X,Y}$ is the joint density function of $X$ and $Y$ and $f_Y$ is the density function of $X$, the conditional expectation $\E[X|Y=y]$ is defined as
\begin{equation}
\E[X|Y=y]=\int_\R x\frac{f_{X,Y}(x,y)}{f_Y(y)}dx.
\end{equation}
Definition~\ref{def:conexp} agrees on this traditional usage although it can be modified on a set of measure zero, as we will see now. Take $\G=\sigma(\{Y=y\})$. The smallest $\sigma$-algebra generated by all $\omega\in\R$ such that $Y(\omega)=y$ and define
\begin{equation}
g(y)=\int_\R x\frac{f_{X,Y}(x,y)}{f_Y(y)}dx,
\end{equation}
then $g(Y)$ is a version of $\E[X|Y]$. The proof and a more general statement can be found in section~9.6 of \cite{Williams91}.

The traditional conditional expectation can also be extended to traditional conditional probability.
\begin{definition}[Traditional conditional probability]
Let $(\Omega,\F, \P)$ be a probability space. Let $F\in\F$ be with positive measure and let $E\in\F$ be measurable. The \emph{traditional conditional probability} of $E$ given $F$ is given by
\begin{equation}
\P[E|F]=\frac{\P[E\cap F]}{\P[F]}.
\end{equation}

If $F$ has measure zero, the traditional conditional probability of $E$ given $F$ is undefined.
\end{definition}

\section{Formal description of the probability space}
\begin{figure}
\centering{
\input{figures/BorelTransform.tikz}
}
\caption{A visualization of coordinate transformation~\eqref{eq:BorelPolar} from Euclidean to spherical coordinates. The rectangle represents the set $S$. The horizontal lines in the rectangle like $C$ parametrize the latitudes. The vertical lines in the rectangle like $M$ parametrize the meridians. Note that the two blue vertical lines of $M$ are distance $\pi$ apart, this is needed to fully parametrize a meridian.}
\label{fig:BorelVis}
\end{figure}

To analyse the Borel-Kolmogorov paradox, we need to formalize our probability space. The following construction is visualized in Figure~\ref{fig:BorelVis}. Let $S$ be the unit sphere. For easier calculations, we equip $S$ with polar coordinates. Define $S=[0,2\pi)\times[0,\pi]$, then $S$ is described in the Euclidean space with the function
\begin{equation}\label{eq:BorelPolar}
S\to\R^3:(\phi,\psi)\mapsto(\cos\phi\sin\psi,\sin\phi\sin\psi,\cos\psi).
\end{equation}
Let $\B=\B(S)$ be the Borel-$\sigma$-algebra on $S$. The uniform distribution on $S$ is defined as
\begin{equation}
\P[B]=\frac{1}{4\pi}\iint_B\sin\psi d\psi d\phi
\end{equation}
for a $B\in\B$. The triple $(S,\B,\P)$ form a probability space.

The set of latitudes is described by
\begin{equation}
\mathcal{C}=\{[0,2\pi)\times\{\psi\}\mid\psi\in[0,\pi]\}
\end{equation}
and will be horizontal lines in the rectangle of Figure~\ref{fig:BorelVis}. The set of meridians is described by
\begin{equation}
\mathcal{M}=\{\{\phi,\phi+\pi\}\times[0,\pi]\mid\phi\in[0,\pi)\}
\end{equation}
and will be the vertical lines in the rectangle of Figure~\ref{fig:BorelVis}.

Note that the function in \eqref{eq:BorelPolar} is not a bijection. The image of $S$ is not one-to-one on the north and south pole, but this is a null set and will not cause any problems in our case. The reason why \eqref{eq:BorelPolar} is not made a formal bijection is that it eases notation.

\section{Conditional distributions}
We will now explore various ways to describe the conditional distribution on a great circle.
\subsection{Traditional conditional probability}\label{sec:BorelNaive}
The first method is the naive method using traditional conditional probability. The probability space here is $(S,\B,\P)$. Let $F\in\B$ be a great circle.

Note that $\P[F]=0$, as a great circle always has zero measure. To be precise, let $f\colon S\to\R^3$ be the coordinate transformation of \eqref{eq:BorelPolar}. All great circles $F'$ have a rotation $O\colon\R^3\to\R^3$ such that $(f^{-1}\circ O\circ f)(F')=[0,2\pi)\times\left\{\frac{\pi}{2}\right\}$. Rotations are orthogonal and have determinant $1$, thus
\begin{align}
\P[F]&=\frac{1}{4\pi}\iint_F\sin\psi d\psi d\phi\\
&=\frac{1}{4\pi}\int_0^{2\pi}\int_{\frac{1}{2}\pi}^{\frac{1}{2}\pi}\sin\psi \det(f^{-1}\circ O\circ f)d\psi d\phi\\
&=\frac{1}{4\pi}\int_0^{2\pi}\int_{\frac{1}{2}\pi}^{\frac{1}{2}\pi}\sin\psi d\psi d\phi=0.
\end{align}
The inverse $f^{-1}$ is well-defined here since $f$ is a bijection locally around the circle $[0,2\pi)\times\left\{\frac{\pi}{2}\right\}$. Let $E\subset F$ be a measurable subset of $F$, then the traditional conditional probability of $E$ given $F$ equals
\begin{equation}
\P[E|F]=\frac{\P[E\cap F]}{\P[F]},
\end{equation}
which is not defined as $\P[F]=0$.

Thus the traditional interpretation of conditional probability will not give an answer. Furthermore, a single great circle does not yield enough information to compute any conditional probability. In terms of Definition~\ref{def:conexp} the sub-$\sigma$-algebra considered here is $\G=\{\emptyset,S,B,S\setminus B\}$, which turns out to be too small.

\subsection{Conditional probability on latitudes}\label{sec:BorelLong}
Since four-element sub-$\sigma$-algebras are too small, we need to condition on larger sub-$\sigma$-algebras. One option is the $\sigma$-algebra of latitudes. Let
\begin{equation}
\mathfrak{C}=\sigma\left(\left\{[0,2\pi)\times A\mid A\in\B([0,\pi])\right\}\right)
\end{equation}
be the $\sigma$-algebra of all measurable subsets of latitudes. We can then calculate the conditional expectation of $\E[X|\mathfrak{C}]$.

\begin{proposition}
Let $X$ be $\B$-measurable. The conditional expectation of $\E[X|\mathfrak{C}]$ is given by
\begin{equation}
\E[X|\mathfrak{C}](\phi,\psi)=\frac{1}{2\pi}\int_0^{2\pi}X(\phi',\psi)d\phi'
\end{equation}
with $(\phi,\psi)\in S$.
\end{proposition}
\begin{proof}
The proof is taken from \cite{Gyenis17}. Take $A\in\B([0,2\pi))$ and consider $C=[0,2\pi)\times A\in\mathfrak{C}$. Since $\P$ is the uniform measure on the surface of the unit sphere, we have
\begin{equation}
\int_C Xd\P=\frac{1}{4\pi}\int_A\int_0^{2\pi}X(\phi,\psi)\sin\psi d\phi d\psi
\end{equation}
by the standard spherical to Euclidean coordinate transformation. We can now apply the same coordinate transformation on the integral of $\E[X|\mathfrak{C}]$:
\begin{equation}
\int_C\E[X|\mathfrak{C}]d\P=\frac{1}{4\pi}\int_A\int_0^{2\pi}\E[X|\mathfrak{C}](\phi,\psi)\sin\psi d\phi d\psi.
\end{equation}
Filling in $\E[X|\mathfrak{C}]$ and rewriting yields
\begin{align}
\int_C\E[X|\mathfrak{C}]d\P&=\frac{1}{4\pi}\int_A\int_0^{2\pi}\E[X|\mathfrak{C}](\phi,\psi)\sin\psi d\phi d\psi\\
&=\frac{1}{4\pi}\int_A\int_0^{2\pi}\frac{1}{2\pi}\left(\int_0^{2\pi}X(\phi',\psi)d\phi'\right)\sin\psi d\phi d\psi\\
&=\frac{1}{4\pi}\int_A\left(\int_0^{2\pi}\frac{1}{2\pi}d\phi\right)\int_0^{2\pi} X(\phi',\psi)\sin\psi d\phi' d\psi\\
&=\frac{1}{4\pi}\int_A\int_0^{2\pi}X(\phi,\psi)\sin\psi d\phi d\psi=\int_C Xd\P.
\end{align}
Note that $\mathfrak{C}$ is generated by sets like $C$, thus $\E[X|\mathfrak{C}]$ is a well-defined version of the $\mathfrak{C}$-conditional expectation of $X$.
\end{proof}

This derivation is slightly different from the one in \cite{Gyenis17}. The corrections on \cite{Gyenis17} are given in Appendix~\ref{app:CorLong}.

As we now have a $\mathfrak{C}$-conditional expectation, we can look at the measure space $(S,\mathfrak{C})$. Let $\psi'\in(0,\pi)$ be arbitrary, then from $\mathfrak{C}$ we can take a latitude $C=[0,2\pi)\times\{\psi'\}$ and a measurable arc $A=[\phi_1,\phi_2]\times\{\psi'\}\subset C$. Let $\P'$ be the probability measure taking $1$ on $C$ and $0$ on $C^c$, then the conditional probability $\bar{\P}$ of points being on $A$ given there is a point on $C$ is
\begin{align}
\bar{\P}[A]&=\int_S\P[A|\mathfrak{C}]d\P'=\frac{1}{2\pi}\int_S\int_0^{2\pi} \1_A(\phi',\psi)d\phi' d\P'(\phi,\psi)\label{eq:BorelLongConProb}\\
&=\frac{1}{2\pi}\left(\int_{S\setminus C}\int_{\phi_1}^{\phi_2}0d\phi' d\P'+\int_{C}\int_{\phi_1}^{\phi_2}1d\phi' d\P' \right)\\
&=\frac{\phi_2-\phi_1}{2\pi}.
\end{align}
Thus the conditional probability distribution on $C$ is uniform, resulting in all latitudes having uniform conditional probability measure. Since the unit sphere itself has a uniform probability measure, this result is as expected.

\subsection{Conditional probability on meridians}\label{sec:BorelMer}
A great circle cannot only be described as a latitude, but also as a meridian. Therefore it is interesting whether describing great circles as meridians yield to the same conditional distribution. Let
\begin{equation}
\mathfrak{M}=\sigma(\{A\times[0,\pi]\mid A\in\B([0,2\pi))\})
\end{equation}
be the $\sigma$-algebra of measurable subsets of meridians. We can now calculate the conditional expectation $\E[X|\mathfrak{M}]$.
\begin{proposition}
Let $X$ be $\B$-measurable. The conditional expectation of $\E[X|\mathfrak{M}]$ is given by
\begin{equation}
\E[X|\mathfrak{M}](\phi,\psi)=\frac{1}{2}\int_0^\pi X(\phi,\psi')\sin\psi'd\psi'
\end{equation}
with $(\phi,\psi)\in S$.
\end{proposition}
\begin{proof}
The proof is largely taken from \cite{Gyenis17}. Let $A\in\B([0,2\pi))$ be measurable and consider $M=A\times[0,\pi]\in\mathfrak{M}$. Coordinate transformation between polar coordinates and the uniform measure on the circle $\P$ and further rewrites yield
\begin{align}
\int_M \E[X|\mathfrak{M}]d\P&=\frac{1}{4\pi}\int_0^\pi\int_A\E[X|\mathfrak{M}](\phi,\psi)\sin\psi d\phi d\psi\\
&=\frac{1}{4\pi}\int_0^\pi\int_A\left(\frac{1}{2}\int_0^{\pi}X(\phi,\psi')\sin\psi'd\psi'\right)\sin\psi d\phi d\psi\\
&=\frac{1}{4\pi}\int_A\int_0^{\pi}X(\phi,\psi')\sin\psi'd\psi'd\phi\\
&=\int_M Xd\P.
\end{align}

Note that $\mathfrak{M}$ is generated by sets like $M$, thus $\E[X|\mathfrak{M}]$ is a well-defined version of the $\mathfrak{M}$-conditional expectation of $X$.
\end{proof}

Note that this representation is different from equations (81) and (112) of \cite{Gyenis17}, where equation 81 is
\begin{equation}
\E[X|\mathfrak{M}](\phi,\psi)=\frac{1}{2}\int_0^{2\pi}X(\phi,\psi')|\sin\psi'|d\psi'
\end{equation}
and equation 112 is
\begin{equation}
\E[X|\mathfrak{M}](\phi,\psi)=\int_0^{\pi}X(\phi,\psi')\sin\psi'd\psi'.
\end{equation}
The corrections on \cite{Gyenis17} are given in Appendix~\ref{app:CorMer}. We can verify that our version is the correct one.\\
Take first the meridian $M=\{\phi',\phi'+\pi\}\times[0,\pi]\in\mathfrak{M}$ with $\phi'\in[0,\pi)$. Let $\psi_1^*,\psi_2^*\in\R$ be arbitrary with $\psi_2^*-2\pi\leq\psi_1^*\leq\psi_2^*$, define the angles $\psi_1=\psi_1^*\mod2\pi$ and $\psi_2=\psi_2^*\mod2\pi$ and define arc $A\subseteq M$ as
\begin{equation}
A=\begin{cases}
\{\phi'\}\times[\psi_1,\psi_2],&\psi_1,\psi_2\leq\pi,\\
\{\phi'\}\times[\psi_1,\pi]\cup\{\phi'+\pi\}\times[\psi_2-\pi,\pi],&\psi_1\leq \pi, \psi_2>\pi,\\
\{\phi'+\pi\}\times[\psi_1-\pi,\psi_2-\pi],&\psi_1,\psi_2>\pi,\\
\{\phi'\}\times[0,\psi_1]\cup\{\phi'+\pi\}\times[0,\psi_2-\pi],&\psi_2\leq\pi,\psi_1>\pi.
\end{cases}
\end{equation}
This definition is exhaustive, yet it provides all possible arcs on a meridian while restricting ourselves to the domain $[0,2\pi)\times[0,\pi]$. Now, analogous to the latitudes, let $\P'$ be the uniform measure taking $1$ on meridian $M$ and $0$ on $M^c$. The conditional probability of $\hat{\P}$ of points being on $A$ with $\psi_1,\psi_2\leq\pi$ given there is a point on $M$ is given by
\begin{align}
\hat{\P}[A]&=\int_S\P[A|\mathfrak{M}]d\P'=\frac{1}{2}\int_S\int_0^\pi\1_A(\phi,\psi')\sin\psi'd\psi'd\P'(\phi,\psi)\\
&=\frac{1}{2}\left(\int_{S\setminus M}\int_{\phi_1}^{\phi_2}0d\psi'd\P'+\int_{M}\1_{\{\phi'\}\times[0,\pi]}\int_{\phi_1}^{\phi_2}\sin\psi'd\psi'd\P'\right)\\
&=\frac{1}{4}\int_{\phi_1}^{\phi_2}\sin\psi'd\psi'd\P'=\frac{\cos\psi_1-\cos\psi_2}{4}
\end{align}
since $\int_{\{\phi'\}\times[0,\pi]}d\P'=\frac{1}{2}$. On the other possible arcs of $M$ the probability $\hat{\P}[A]$ with $\psi_1,\psi_2$ as in the definition of $A$ becomes
\begin{equation}\label{eq:BorelMerConProb}
\hat{\P}[A]=\begin{cases}
\frac{1}{4}\left(\cos\psi_1-\cos\psi_2\right),&\psi_1,\psi_2\leq\pi,\\
\frac{1}{4}\left(2+\cos\psi_1-\cos\psi_2\right),&\psi_1\leq \pi, \psi_2>\pi,\\
\frac{1}{4}\left(\cos\psi_2-\cos\psi_1\right),&\psi_1,\psi_2>\pi,\\
\frac{1}{4}\left(2-\cos\psi_1+\cos\psi_2\right),&\psi_2\leq\pi,\psi_1>\pi.
\end{cases}
\end{equation}
Now one can immediately check that $\hat{\P}$ is well-defined on $M$ as
\begin{equation}
\hat{\P}[M]=\int_S\P[A|\mathfrak{M}]d\P'=\frac{1}{2}\int_M\int_0^\pi\sin\psi'd\psi'd\P'=-\frac{1}{2}\left(\cos\pi-\cos0\right)=1.
\end{equation}

Clearly this conditional distribution on meridians is not uniform. However, one should expect they are, as a meridian is just a rotation of a latitude and the points on the sphere are spread uniformly. An explanation of this difference is given in Section~\ref{sec:BorelExplained}.

\subsection{Combining latitudes and meridians}\label{sec:BorelCombining}
Another question one could ask is the following: if I define $\Sigma=\sigma(\mathfrak{C},\mathfrak{M})$ as the smallest $\sigma$-algebra containing both measurable subsets of meridians and latitudes, what is then the conditional probability distribution on a great circle given $\Sigma$? The answer is that in this approach the distributions in sections~\ref{sec:BorelLong} and~\ref{sec:BorelMer} can be recovered as limiting distributions of a sequence of traditional conditional probabilities defined in Section~\ref{sec:BorelNaive}.

First we'll further analyse the new $\sigma$-algebra $\Sigma$. Consider an arbitrary rectangle $(a,b)\times(c,d)\subset[0,2\pi)\times[0,\pi]$. Since by definition $(a,b)\times[0,\pi]\in\mathfrak{M}$ and $[0,2\pi)\times(c,d)\in\mathfrak{C}$, we have
\begin{equation}
(a,b)\times(c,d)=\left((a,b)\times[0,\pi]\right)\cap\left([0,2\pi)\times(c,d)\right)\in\Sigma.
\end{equation}
Thus all Borel-measurable sets on our sphere are contained in $\Sigma$. Furthermore, as $\mathfrak{C}$ and $\mathfrak{M}$ contain only Borel-measurable sets, $\Sigma=\sigma(\mathfrak{C},\mathfrak{M})$ can only have Borel-measurable sets. Therefore $\Sigma=\B$ is the $\sigma$-algebra of Borel-measurable sets on the sphere.

Now take the following approach. Pick $x\in(0,\pi)$. Define the two rectangles $C_\epsilon=[0,2\pi)\times[x-\epsilon,x+\epsilon]$ and $R_\epsilon=[a,b]\times[x-\epsilon,x+\epsilon]\subseteq C_\epsilon$ for all ${\epsilon\in(0,\min\{\pi-x,x\})}$, then what is the limiting conditional probability of $R_0$ given $C_0$? The conditional probability of $R_0$ given $C_0$ can be modeled as the limit of the sequence $\P[R_\epsilon|C_\epsilon]$ with $\epsilon\to0$, which will take on the uniform distribution on $C_0$ as calculated in Equation~\ref{eq:BorelLongConProb}.
\begin{proposition}\label{prop:BorelLongBayes}
Define the two rectangles $C_\epsilon=[0,2\pi)\times[x-\epsilon,x+\epsilon]$ and $R_\epsilon=[a,b]\times[x-\epsilon,x+\epsilon]\subset C_\epsilon$ for all $\epsilon\in(0,\min\{\pi-x,x\})$ with $x\in(0,\pi)$. The limiting conditional probability of $R_0$ given $C_0$ equals
\begin{equation}
\P[R_0|C_0]=\lim_{\epsilon\downarrow0}\P[R_\epsilon|C_\epsilon]=\frac{b-a}{2\pi}.
\end{equation}
\end{proposition}
\begin{proof}
Let $\epsilon\in(0,\min\{\pi-x,x\})$. Let $C_\epsilon=[0,2\pi)\times[x-\epsilon,x+\epsilon]\in\mathfrak{C}$. The probability $\P[R_\epsilon|C_\epsilon]$ equals
\begin{equation}
\P[R_\epsilon|C_\epsilon]=\frac{\P[R_\epsilon\cap C_\epsilon]}{\P[C_\epsilon]}=\frac{\int_{a}^{b}\int_{x-\epsilon}^{x+\epsilon}\sin\psi d\psi d\phi}{\int_{0}^{2\pi}\int_{x-\epsilon}^{x+\epsilon}\sin\psi d\psi d\phi}=\frac{b-a}{2\pi}.
\end{equation}
Thus $\P[R_\epsilon|C_\epsilon]=\frac{b-a}{2\pi}$ holds for all possible $\epsilon$, resulting in the limiting value
\begin{equation}
\P[R_0|C_0]=\lim_{\epsilon\downarrow0}\P[R_\epsilon|C_\epsilon]=\frac{b-a}{2\pi}.
\end{equation}
\end{proof}

A same proposition can be found for the meridians.

\begin{proposition}\label{prop:BorelMerBayes}
Let $x\in(0,2\pi)$ and $\epsilon\in(0,\min\{2\pi-x,x\})$. Consider $M_\epsilon=[x-\epsilon,x+\epsilon]\times[0,\pi]$ and $R_\epsilon=[x-\epsilon,x+\epsilon]\times[a,b]\subseteq M_\epsilon$, then the limiting conditional probability of $R_0$ given $M_0$ is
\begin{equation}
\P[R_0|M_0]=\lim_{\epsilon\downarrow0}\P[R_\epsilon|M_\epsilon]=\frac{1}{2}(\cos a-\cos b)
\end{equation}
\end{proposition}
\begin{proof}
The conditional probability $\P[R_\epsilon|M_\epsilon]$ equals
\begin{equation}
\P[R_\epsilon|M_\epsilon]=\frac{\P[R_\epsilon\cap M_\epsilon]}{\P[M_\epsilon]}=\frac{\int_{x-\epsilon}^{x+\epsilon}\int_a^b\sin\psi d\psi d\phi}{\int_{x-\epsilon}^{x+\epsilon}\int_0^{\pi}\sin\psi d\psi d\phi}=\frac{1}{2}\left(\cos a-\cos b\right).
\end{equation}
The limit of $\epsilon\downarrow0$ remains $\P[R_0|M_0]=\frac{1}{2}\left(\cos a-\cos b\right)$.
\end{proof}

Note that the probability in Proposition~\ref{prop:BorelMerBayes} has $\frac{1}{2}$ as normalization factor instead of $\frac{1}{4}$, as $M_\epsilon$ converges to only a half meridian. By symmetry the distribution on the whole meridian follows the absolute cosine function.

The conditional probabilities on $\mathfrak{C}$ and $\mathfrak{M}$ therefore can be approached by traditional conditional probabilities on $\B$. This gives rise to the following conjecture.
\begin{conjecture}\label{con:BorelConjecture}
Let $(X,\F,\P)$ be a probability space. Let $F\in\mathcal{F}$ have zero measure and let $E\subseteq F$ be measurable. Let $\G\subset\F$ be a sub-$\sigma$-algebra containing $E$ and $F$ with $\G\neq\F$. Let $\{F_n\}_{n\in\N}\subset\G$ be a sequence converging to $F$ and $\{E_n\}_{n\in\N}\subset\G$ be a sequence converging to $E$ with for all $n\in\N$ the sets $E_n$ and $F_n$ have positive measure, $E_n\subseteq F_n$ holds and the limit $\lim_{n\to\infty}\P[E_n|F_n]$ exists. Then
\begin{equation}
\P[E|F]:=\lim_{n\to\infty}\P[E_n|F_n]=\int_X\E[\1_F|\mathcal{G}]d\P'(E)
\end{equation}
where $\P'$ is the probability measure taking $1$ on $F$ and $\E[\cdot|\G]$ is a version of the conditional expectation on $\G$.
\end{conjecture}

If Conjecture~\ref{con:BorelConjecture} is true, then all conditional probabilities on null sets can be computed by limiting traditional conditional probabilities. It seems to hold as for the Borel-Kolmogorov paradox when considering latitudes we can take $\F=\B$ and $\G=\mathfrak{C}$ and when considering meridians we can take $\F=\B$ and $\G=\mathfrak{M}$. It however is false as the following proposition will point out.

\begin{proposition}\label{prop:BorelConFalse}
Conjecture~\ref{con:BorelConjecture} is false.
\end{proposition}
\begin{proof}
In sections \ref{sec:BorelLong} and \ref{sec:BorelMer} we have seen that the parametrization using latitudes gave the uniform distribution and the parametrization using meridians gave a cosine. However, in Section~\ref{sec:BorelLong} the set $[0,2\pi)\times\left\{\frac{\pi}{2}\right\}$ is considered, the red horizontal line in Figure~\ref{fig:BorelVis}. Section~\ref{sec:BorelMer} treats the set $\{0,\pi\}\times[0,\pi]$, like the blue vertical lines in Figure~\ref{fig:BorelVis}. Those sets differer, however we can find a set which has two different probabilities using a rotation.

Call $f$ the transformation from polar to Euclidean coordinates from Equation~\ref{eq:BorelPolar}. Let $O$ be a rotation such that
\begin{equation}
(f^{-1}\circ O\circ f)\left([0,\pi]\times\left\{\frac{\pi}{2}\right\}\right)=\{\pi\}\times[0,\pi],
\end{equation}
thus where the largest half latitude is rotated to a half meridian. Recall that $\mathfrak{C}$ is the $\sigma$-algebra of latitudes. We now rotate those latitudes to get the following $\sigma$-algebra:
\begin{equation}
\mathfrak{C}'=\left\{F'\in\B\mid F'=\left(f^{-1}\circ O^{-1}\circ f\right)(F),F\in\mathfrak{C}\right\}.
\end{equation}
Now $F=\{\pi\}\times[0,\pi]$ is an element of both $\mathfrak{C}'$ and $\mathfrak{M}$. We will prove that different methods of converging to $F$ yield to different $\P[E|F]$ for a measurable $E$. We will take the set $E=\{\pi\}\times\left[\frac{1}{4}\pi,\frac{3}{4}\pi\right]$ as our example.

First take a look at $\mathfrak{C}'$. Let $\epsilon\in\left(0,\frac{\pi}{2}\right)$ be arbitrary and consider the sets $C_\epsilon=[0,\pi]\times\left[\frac{\pi}{2}-\epsilon,\frac{\pi}{2}+\epsilon\right]$ and $R_\epsilon=\left[\frac{1}{4}\pi,\frac{3}{4}\pi\right]\times\left[\frac{\pi}{2}-\epsilon,\frac{\pi}{2}+\epsilon\right]$. Let $\{R'_{n^{-1}}\}_{n\in\N}$ be with $R'_{n^{-1}}=(f^{-1}\circ O^{-1}\circ f)(R_{n^{-1}})$ and let the sequence $\{C'_{n^{-1}}\}_{n\in\N}$ be with $C'_{n^{-1}}=(f^{-1}\circ O^{-1}\circ f)(C_{n^{-1}})$. Since $R_{n^{-1}},C_{n^{-1}}\in\mathfrak{C}$ holds for all $n\in\N$, we get $\{R'_{n^{-1}}\}_{n\in\N},\{C'_{n^{-1}}\}_{n\in\N}\subset\mathfrak{C'}$. Furthermore, $f^{-1}\circ O^{-1}\circ f$ has determinant $1$ since $O$ is a rotation and $f$ is almost surely a bijection on $F$, resulting to
\begin{align}
\P[R'_\epsilon|C'_\epsilon]&=\frac{\P[R'_\epsilon]}{\P[C'_\epsilon]}=\frac{\iint_{R'_\epsilon}\sin\psi d\psi d\phi}{\iint_{C'_\epsilon} \sin\psi d\psi d\phi}=\frac{\iint_{R_\epsilon}g(\sin\psi)\cdot1 d\psi d\phi}{\iint_{C_\epsilon}g(\sin\psi)\cdot1d\psi d\phi}\\
&=\frac{\int_{\frac{1}{4}\pi}^{\frac{3}{4}\pi}\int_{\frac{\pi}{2}-\epsilon}^{\frac{\pi}{2}+\epsilon}g(\sin\psi)\cdot1 d\psi d\phi}{\int_{0}^{\pi}\int_{\frac{\pi}{2}-\epsilon}^{\frac{\pi}{2}+\epsilon}g(\sin\psi)\cdot1d\psi d\phi}=\frac{\frac{3}{4}\pi-\frac{1}{4}\pi}{\pi}=\frac{1}{2}
\end{align}
where $g(x)$ is the result of the transformation $f^{-1}\circ O^{-1}\circ f$ on the integrand. The function $g$ is not written out explicitly, as the integral can be split up as a multiplication of integrals and the resulting integrals in the numerator en denominator with $g$ in the integrand are equal, thus cancel out. The result is $\P[R'_0|C'_0]=\frac{1}{2}$, as $\P[R'_\epsilon|C'_\epsilon]$ is constant in $\epsilon$. The sequence $\{R'_{n^{-1}}\}_{n\in\N}$ converges to $E$ and the sequence $\{C'_{n^{-1}}\}_{n\in\N}$ converges to $F$, thus we have $\P[E|F]=\frac{1}{2}$ as well.

For $\mathfrak{M}$ we will use Proposition~\ref{prop:BorelMerBayes}. Let $x=\pi$ and $\epsilon\in(0,\pi)$, then we have $M_\epsilon\in\mathfrak{M}$ and $R_\epsilon=[\pi-\epsilon,\pi+\epsilon]\times\left[\frac{1}{4}\pi,\frac{3}{4}\pi\right]\subset M_\epsilon$. Furthermore, the sequence $\{M_{n^{-1}}\}_{n\in\N}$ converges to $F$ and $\{R_{n^{-1}}\}_{n\in\N}$ converges to $E$, thus Proposition~\ref{prop:BorelMerBayes} states that
\begin{equation}
\P[E|F]=\frac{1}{2}\left(\cos\left(\frac{1}{4}\pi\right)-\cos\left(\frac{3}{4}\pi\right)\right)=\frac{\sqrt{2}}{2}.
\end{equation}

We now have both $\P[E|F]=\frac{1}{2}$ and $\P[E|F]=\frac{1}{2}\sqrt{2}$, which are clearly not equal. Conjecture~\ref{con:BorelConjecture} is therefore false.
\end{proof}

This demonstrates that when having an $F\in\F$ with zero measure, one cannot uniquely define $\P[E|F]$. A conditional expectation needs to be accompanied by a sub-$\sigma$-algebra, otherwise contradictory results can arise.

The idea underlying Conjecture~\ref{con:BorelConjecture} is however useful to guess a conditional expectation. The measure-theoretic definition of conditional expectation is only a list of properties, not a constructive definition. In the case of a $\mathfrak{C}$-conditional expectation, looking at Proposition~\ref{prop:BorelLongBayes} and its proof we observe that the resulting probability is $\frac{b-a}{2\pi}$, thus uniform. Furthermore, $\phi$ is the only variable that is integrated, thus one can guess $\phi$ is the only needed variable. Therefore one can suspect that
\begin{equation}
\E\left[\1_{[a,b]\times\left\{\frac{\pi}{2}\right\}}\middle|\mathfrak{C}\right](\phi,\psi)=\frac{1}{2\pi}\int_0^{2\pi}\1_{[a,b]\times\left\{\frac{\pi}{2}\right\}}(\phi',\psi)d\phi'=\frac{b-a}{2\pi}\1_{\left\{\frac{\pi}{2}\right\}}(\psi)
\end{equation}
holds and the guess can be generalized to
\begin{equation}
\E[X|\mathfrak{C}](\phi,\psi)=\frac{1}{2\pi}\int_0^{2\pi}X(\phi',\psi)d\phi'.
\end{equation}
This is in fact the same $\mathfrak{C}$-conditional expectation of $X$ by Proposition~\ref{prop:BorelLongBayes}. The same steps can be taken to guess $\E[X|\mathfrak{M}]$ using Proposition~\ref{prop:BorelMerBayes}.

Thus we can conclude that it is wise to look at a converging sequence of traditional conditional probabilities for a potential conditional expectation when conditioning on zero sets. However, it must be noted that the resulting conditional probability is not uniquely defined, must be checked whether it complies to the actual definition of conditional probability and depends on the chosen sub-$\sigma$-algebra.

\section{The Borel-Kolmogorov paradox explained}\label{sec:BorelExplained}
Following the arguments of \cite{Gyenis17} we will argue that the difference in conditional distribution is no paradox, but a misinterpretation of conditional probability.

A first explanation is quite intuitive. All meridians intersect at the north and south pole of the sphere, whereas latitudes do not intersect. Therefore the $\sigma$-algebras $\mathfrak{M}$ and $\mathfrak{C}$ are vastly different. If points are spread uniformly on the meridians, the distribution of mass on the whole sphere will not be uniform and the density of mass will be highest at the poles. This is simulated by \cite{Weisstein} and his simulations support this statement.

Let $\bar{\P}$ be the conditional probability measure on a latitude, defined by Equation~\ref{eq:BorelLongConProb} and let $\hat{\P}$ be the conditional probability measure on a meridian, defined by Equation~\ref{eq:BorelMerConProb}. If the spaces $(S, \mathfrak{C}, \bar{\P})$ and $(S, \mathfrak{M}, \hat{\P})$ are isomorphic with a measurable bijection, then $\hat{\P}$ and $\bar{\P}$ must have equal distribution and the results of sections~\ref{sec:BorelLong} and \ref{sec:BorelMer} must be paradoxical and contradictory. If there is a measurable bijection from a meridian to a latitude, their conditional probability distributions must agree. This is not the case here.
\begin{theorem}[\cite{Gyenis17}]
Let $f\colon S\to S$ be a measurable bijection with measurable inverse. There is no Boolean algebra isomorphism $h_f\colon\mathfrak{C}\to\mathfrak{M}$ that is determined by $f$.
\end{theorem}
\begin{proof}
The proof can be found in \cite{Gyenis17}, but we will repeat it here. Suppose such isomorphism $h_f$ exists. All latitudes $C$ in $\mathfrak{C}$ are the only atoms of $\mathfrak{C}$, therefore $h_f(C)$ are the only atoms of $\mathfrak{M}$ as well, making $h_f(C)$ meridians. We will now prove that $h_f(C)$ cannot be a meridian.

Let $m_0=\{(0,0), (0,\pi)\}$ be the set of north and south poles. Let $c_0\in\mathfrak{C}$ be such that $h_f(c_0)=m_0$. Then $c_0$ consists of two elements as well, thus we can choose latitude $C$ not on the north or south poles such that $C\cap c_0=\emptyset$. Note that $h_f(C)$ is a meridian, thus $m_0\subset h_f(C)$ as all meridians pass through the north and south poles. Since $h_f$ is a Boolean algebra isomorphism, we have $h_f(C\cap c_0)=h_f(C)\cap h_f(c_0)$. This all can be combined in the following line:
\begin{equation}
\emptyset=h_f(\emptyset)=h_f(C\cap c_0)=h_f(C)\cap h_f(c_0)=h_f(C)\cap m_0=m_0.
\end{equation}
This is clearly a contradiction.

Let $C$ be the north or south pole of the sphere. Since $h_f$ is a bijection, $h_f(C)$ is only a single point as well. Thus $h_f(C)$ cannot be an atom of $\mathfrak{M}$. Therefore there is a contradiction here as well.

Thus no single atom of $\mathfrak{C}$ result into an atom of $\mathfrak{M}$ by $h_f$ and therefore function $h_f$ cannot exist.
\end{proof}

Therefore every measurable bijection between $(S,\mathfrak{C})$ and $(S,\mathfrak{M})$ has no Boolean algebra isomorphism $h_f\colon\mathfrak{C}\to\mathfrak{M}$ such that latitudes in $\mathfrak{C}$ are mapped to meridians on $\mathfrak{M}$. This theorem holds on all subalgebras of $\mathfrak{C}$ and $\mathfrak{M}$ as well, as is proven by \cite{Gyenis17}.

Now it should be clear why the conditional distribution on the latitudes and meridians of the sphere differ, since we are dealing with two entirely different structured spaces. Therefore, the question `why is the conditional distribution on the latitudes different from the conditional distribution on the meridians' is easy to answer; difference in spaces. To verify that two different methods of conditioning on the same set yield to the correct conditional probability, one must ask the following question: `if one models a distribution on the sample space using conditional expectation on a sub-$\sigma$-algebra, does the resulting conditional probability distribution extend to the original distribution on the whole sample space?' As earlier mentioned, Weisstein \cite{Weisstein} demonstrated that the answer to that question is yes. The uniform distribution on latitudes and the cosine on meridians both extend to the uniform distribution on the whole sphere. Thus when dealing with different conditional distributions on measure zero sets, one should rather ask a question like the last one, as the answer to that question must always be yes. Further reading and a more in-depth analysis can be found in \cite{Gyenis17}.


\section{Conclusion}
After analysing the Borel-Kolmogorov paradox, the first and most important conclusion we can take is that when conditioning, especially on a set $F$ of measure zero, one needs to give the accompanying sub-$\sigma$-algebra of the event that is conditioned on. Otherwise the Borel-Kolmogorov phenomenon appears, where one can give different sub-$\sigma$-algebras containing $F$ such that the resulting conditional probability distribution is different.

Secondly, we must accept that conditional probability on sets of measure zero are not uniquely defined. That uniqueness only appears when conditioning on sets of positive measure, as then the classical rule $\P[E|F]=\frac{\P[E\cap F]}{\P[F]}$ gives a version of the conditional probability. If a sub-$\sigma$-algebra can be used to model the entire sample space, for example the sub-$\sigma$-algebra of latitudes with the sphere as sample space, then the conditional probability must be able to extend to the original probability distribution. For example providing the uniform distribution on all latitudes gives back the uniform distribution on the sphere, as well as applying the cosine distribution on the meridians results into the uniform distribution on the sphere.

Thirdly, a conditional distribution on a zero set must be calculated using the measure-theoretic conditional expectation. Conjecture~\ref{con:BorelConjecture} can help with finding the correct conditional expectation, however Proposition~\ref{prop:BorelConFalse} proves that the resulting conditional probability does not need to be unique. Therefore Conjecture~\ref{con:BorelConjecture} cannot be used to calculate a conditional probability and then call it a day, you need to check whether the distribution you found actually satisfies all conditions of conditional probability.

At last, as Kolmogorov \cite{Kolmogorov33} already stated in his work, there is nothing paradoxical going on in the Borel-Kolmogorov paradox. The space of the sphere with the latitudes as $\sigma$-algebra is not homeomorphic with the space of the sphere and the meridians as $\sigma$-algebra. The not-uniqueness of the conditional probability on a zero set is thus as expected and we must give the sub-$\sigma$-algebra when conditioning on sets of measure zero.


\chapter{Safe probability}\label{chap:SafeProp}
Take a look at the following game of dice, devised by Grünwald \cite{Grunwald13}. A player and game master are present and the game master casts a fair die. He peeks at the value of the die and must either state that the value is 4 or lower or state that the value is 3 or higher. The game master is not allowed to lie. Upon hearing the game master's advice, what is the probability the die has landed on a 3?\\
Suppose an alternative game is considered, where the game master can only say that the value is either from 1 to and including 4 or the value is 5 or 6. The question of the probability of the die having 3 becomes easy to answer. When 5 or 6 is revealed, the probability is 0 and when 1 to 4 is revealed, traditional conditional probability gives us that the probability is 0.25.\\
However, when either `4 or lower' or `3 or higher' is stated, the game master can choose his statement when the die lands on a 3 or 4. His strategy on choosing his statement heavily influences the probability of the die landing on 3 upon hearing the game master's statement, making that probability not unique.

What can we say about the probability of the die landing on 3? Traditional conditional probability will not suffice here. We want to condition on sets with positive measure and the versions of conditional expectation then almost surely coincides with traditional conditional probability, thus using measure-theoretic conditional probability will not give more insight than conditional probability.

If we loose our notion of conditional probability, we can resort to \emph{safe probability}, introduced by Grünwald in 2018 \cite{Grunwald18}. Suppose there are two random variables, $U$ and $V$, and we want to use the distribution $U|V$. Suppose however that there is no method of finding this distribution, only you that you know that it is a member of a model of distributions $\Pmod$. One can then create a new conditional distribution, not necessarily one from our model nor necessarily reflecting the true distribution at all, which gives a probability of $U$ given $V$ that on average performs equal for all distributions in our model $\Pmod$ in predicting $U$ given $V$. For example, one notion of safe probability is that we have a distribution $\Psafe$ such that $\E_{\P}[U]=\E_{\P}[\E_{\Psafe}[U|V]]$ holds for all $\P\in\Pmod$. Under this $\Psafe$ the expectation $\E_{\Psafe}[U|V]$ is an unbiased estimator of $U$ for all distributions $\P\in\Pmod$. Thus no matter which strategy the game master has, distribution $\Psafe$ allows the player to estimate $U$ on average correctly.

There are more notions on safety, further restricting the freedom $\Psafe$ has. We will first introduce some notions of safe probability and how all notions are related to each other. The example of the dice game is then continued to illustrate how safe probability can be applied.
\section{Definitions}
Before we will define safe probability, we need to introduce some notation.

\begin{definition}[Range and support]
Let $S\colon\X\to\Y$ be a random variable. The \emph{range} of $S$ is
\begin{equation}
\range(S)=\{s\in\Y\mid s=S(x),x\in\X\}.
\end{equation}
Let $\P$ be a probability distribution on $\X$. The \emph{support} of $S$ under $\P$ is
\begin{equation}
\supp_{\P}(S)=\{s\in \Y\mid\P[S=s]>0\}.
\end{equation}
\end{definition}

Let $U$ and $U'$ be two random variables and suppose there is a function $f$ such that $f(U)=U'$ holds, then we will write $U\stackrel{f}{\rightsquigarrow}U'$. If a function $f$ exists such that $U\stackrel{f}{\rightsquigarrow}V$, we will write $U\rightsquigarrow V$. Random variable $V$ is then called a \emph{coarsening} of $U$ or equivalently we state that $U$ determines $V$.

Let $\Pmod$ be a set of probability measures, then $\Pmod$ is called a \emph{model}.

Lastly, if we keep $U$ and $V$ as random variables, the distribution of $U$ under $\P$ is written as $\P[U]$. The distribution of $U$ given $V$ under $\P$ is written as $\P[U|V]$.

We are now able to define conditional probability. The following definitions and propositions are all taken from \cite{Grunwald18}.

\begin{definition}[Safe probabilities]\label{def:SafeProp}
Let $\Omega$ be a sample space and let $\Pmod$ be a set of distributions on $\Omega$. Let $U$ be a real-valued random variable with finite expectation and let $V$ be a random variable on $\Omega$. Let $\Psafe$ be a probability distribution on $\Omega$. Then $\Psafe$ is \emph{safe} with respect to $\Pmod$ for
\begin{itemize}
    \item $\langle U\rangle|\langle V\rangle$ if $\E_{\P}[U]=\E_{\P}[\E_{\Psafe}[U|V]]$ holds for all $\P\in\Pmod$. This $\Psafe$ is called \emph{unbiased} for $U|V$.
    \item $\langle U\rangle|[V]$ if $\E_{\P}[U]=\E_{\Psafe}[U|V=v]$ holds for all $v\in\supp_{\Psafe}(V)$. This $\Psafe$ is called \emph{marginally valid} for $U|V$.
\end{itemize}
\end{definition}
Since in almost all situations we only consider a single model $\Pmod$, we will from now on omit the statement `with respect to $\Pmod$'.
\begin{definition}[Stronger safety]\label{def:SafeStrongProp}
Let $\Omega,\Pmod,U,V$ and $\Psafe$ as above. Then $\Psafe$ is \emph{safe} for
\begin{itemize}
    \item $U|\langle V\rangle$ if for all real-valued random variables $U'$ on $\Omega$ with $U\rightsquigarrow U'$ distribution $\Psafe$ is safe for $\langle U'\rangle|\langle V\rangle$.
    \item $U|[V]$ if for all real-valued random variables $U'$ on $\Omega$ with $U\rightsquigarrow U'$ distribution $\Psafe$ is safe for $\langle U'\rangle|[V]$.
\end{itemize}
\end{definition}

Both definitions introduce a lot of new notation. In practice, $\langle V\rangle$ implies that $\E_{\Psafe}[U|V]$ must be an unbiased estimator for $U$ for all $\P\in\Pmod$.\\
When $[V]$ is considered, the expected value of $U|V=v$ under $\Psafe$ must equal the expected value of $U$ under $\P$ for all $v\in\supp_{\P}(V)$ and $\P\in\Pmod$. In other words, the outcome of $V$ will not influence the conditional expectation value of $U$ under $\Psafe$ and this expectation will equal the expectation of $U$ under all $\P\in\Pmod$. Note that when $\E_{\P}[U]$ does not remain constant for all $\P\in\Pmod$, safety for $[V]$ is immediately impossible.\\
Lastly, the difference between $\langle U\rangle$ and $U$ is that for $\langle U\rangle$ the requirement for safety does only have to be met for $U$. When $U$ is considered, the requirement must be met for all coarsenings $U'$ of $U$.

When we say that $\Psafe$ is safe for $U|[V]$, we actually mean that `for all $\P\in\Pmod$ we have $\supp_{\P}(V)\subseteq\supp_{\Psafe}(V)$, $\E_{\P}[U]$ is well-defined and finite, $\E_{\Psafe}[U|V=v]$ is well-defined for all $v\in\supp_{\Psafe}(V)$, both expectations are equal and this holds for all $U'$ with $U\rightsquigarrow U'$'. This statement is quite lengthy, therefore we will abbreviate it by stating that $\Psafe$ is safe for $U|[V]$. Such abbreviations are performed for other notions of safety as well.

Definition~\ref{def:SafeStrongProp} is not easy to work with as constructing a $\Psafe$ that is safe for $U|[V]$ requires checking $\Psafe$ against all coarsenings $U'$ of $U$. The following proposition from \cite{Grunwald18} gives us tools to actually create a safe $\Psafe$ for $U|\langle V\rangle$, $U|[V]$ and a few extra notions.

\begin{proposition}\label{prop:SafeProperties}
Let $\Omega$, $\Pmod$, $U$, $V$ and $\Psafe$ be as above. Then
\begin{enumerate}
    \item $\Psafe$ is safe for $U|\langle V\rangle$ if and only if for all $\P\in\Pmod$ there is a distribution $\P'$ on $\Omega$ with $\P'[U=u,V=v]=\Psafe[U=u|V=v]\P[V=v]$ for all $(u,v)\in\range((U,V))$ such that $\P'[U]=\P[U]$.
    \item $\Psafe$ is safe for $\langle U\rangle|V$ if and only if
    \begin{equation}
    \E_{\P}[U|V]=\E_{\Psafe}[U|V]
    \end{equation}
    holds with probability $1$ for all $\P\in\Pmod$. This $\Psafe$ is called \emph{squared error-optimal} for $U|V$.
    \item $\Psafe$ is safe for $U|V$ if and only if
    \begin{equation}
    \P[U|V]=\Psafe[U|V]
    \end{equation}
    holds with probability $1$ for all $\P\in\Pmod$. This $\Psafe$ is called \emph{valid} for $U|V$.
    \item $\Psafe$ is safe for $U|[V]$ if and only if $\P[U]=\Psafe[U|V=v]$ for all $\P\in\Pmod$ and $v\in\supp_{\Psafe}(V)$.
\end{enumerate}
\end{proposition}
\begin{proof}
The proof is in \cite{Grunwald16}, section A.2.
\end{proof}

It is easy to see that safety for $\langle U\rangle|[V]$ implies safety for $\langle U\rangle|\langle V\rangle$. If we have $\E_{\Psafe}[U|V=v]=\E_{\P}[U]$ for all $v\in\supp_{\Psafe}(V)$, then
\begin{equation}
\E_{\P}[\E_{\Psafe}[U|V]]=\E_{\P}[\E_{\P}[U]]=\E_{\P}[U]
\end{equation}
must hold. All implications are stated in the following proposition.

\begin{figure}
\centering{
\input{figures/SafeDiagram.tikz}
}
\caption{A diagram of implications between safe probabilities. If $\Psafe$ is safe for X, then it is safe for all statements that can be reached from X as well.}
\label{fig:SafeDiagram}
\end{figure}

Note that safety for $U|V$ will almost never occur. When a $\Psafe$ is safe for $U|V$, then all probability measures in $\Pmod$ have an almost surely equal distribution on $U|V$. In that case we should not bother ourselves with safe probability and just use one distribution from $\Pmod$ as our probability. Furthermore, if $\Pmod=\{\P\}$ consists of only a single probability measure, then $\P$ is automatically safe for $U|V$. Therefore it is wise to make the model $\Pmod$ large enough when considering safe probabilities, otherwise the safe distribution is prone to overfitting.

\begin{proposition}\label{prop:SafeImply}
Let $U$, $V$ and $\Psafe$ be as above.
\begin{enumerate}
\item If $\Psafe$ is safe for $U|V$, it is safe for $\langle U\rangle|V$ and $U|[V]$.
\item If $\Psafe$ is safe for $U|[V]$, it is safe for $U|\langle V\rangle$ and $\langle U\rangle|[V]$.
\item If $\Psafe$ is safe for $\langle U\rangle|V$, $U|\langle V\rangle$ or $\langle U\rangle|[V]$, it is safe for $\langle U\rangle|\langle V\rangle$.
\end{enumerate}
All relations are visualised in Figure~\ref{fig:SafeDiagram}.
\end{proposition}
\begin{proof}
All implications are found and proven in \cite{Grunwald18}.
\end{proof}

\section{The dice game}\label{sec:SafeDice}
Recall the dice game from the introduction of this chapter, introduced by \cite{Grunwald13}. The game master casts a fair die and observes a value. This value is either in the set $\{1,2,3,4\}$ or in the set $\{3,4,5,6\}$. The game master must reveal one of the two sets to the player and cannot lie. The player must then guess the probability that the die has landed on 3.

It is insufficient to take $\Omega=\{1,2,3,4,5,6\}$ as our sample space. Let $U$ be a random variable denoting the die's value and let $V$ be the statement of the game master, then $\P[U=3|V=\{1,2,3,4\}]$ cannot be calculated. When the die has rolled to a $3$, the game master can choose between $\{1,2,3,4\}$ and $\{3,4,5,6\}$ and this must be taken into account. The smallest $\sigma$-algebra containing both $\{1,2,3,4\}$ and $\{3,4,5,6\}$ is
\begin{equation}
\G=\sigma(\{1,2\},\{3,4\},\{5,6\}),
\end{equation}
thus $\{3\}$ is no member of $\G$ as $\G$ cannot have sets of odd size. We can add $\{3\}$ to $\G$, however we still do need the probability of $\{\{1,2,3,4\},\{3,4,5,6\}\}$. Therefore we cannot condition in $\Omega$ to compute $U=3$ given $V=\{1,2,3,4\}$.

Therefore we need to extend our sample space. We will use the extension introduced in \cite{Grunwald13}. Take $\X=\{1,2,3,4,5,6\}$ and $\Y=\{\{1,2,3,4\},\{3,4,5,6\}\}$ and let our sample space be $\Omega=\X\times\Y$. Let $U$ be an $\X$-valued random variable and let $V$ be a $\Y$-valued random variable. In this space conditioning on $\{1,2,3,4\}$ is valid, as $\G=\sigma(\{3\}\times Y)$ is a strict sub-$\sigma$-algebra of $2^\Omega$ for all subsets $Y\subseteq\Y$.
\subsection{Using traditional conditional probability}
First we will try using traditional conditional probability. Let $\P$ be a probability measure with the uniform distribution on $U$. To model the strategy of the game master, we need $p,q\in[0,1]$ such that
\begin{align}
\P[V=\{3,4,5,6\}\mid U=3]&=p,&\P[V=\{3,4,5,6\}\mid U=4]&=q.
\end{align}

We can now for example calculate the probability of the die landing on $6$ after the game master reveals $\{3,4,5,6\}$. This calculation can be found in equation~2 of \cite{Grunwald13} and it states that
\begin{equation}\label{eq:SafeDiceCon6}
\P[U=6\mid V=\{3,4,5,6\}]=\frac{1}{p+q+2}.
\end{equation}
Thus the conditional probability of rolling $6$ ranges from $\frac{1}{4}$ to $\frac{1}{2}$ depending on the game master's strategy. This should not suffice as answer, as the player does not know the game master's strategy.

\subsection{Using safe probabilities}
Can we create a distribution $\Psafe$ such that the probability of $U=3$ given $V$ is independent of $p$ and $q$ and behaves on average like the dice? The answer is yes and we need to use safe probability. Consider as model
\begin{equation}
\Pmod=\left\{\P\middle|\forall u\in\X:\P[U=u]=\frac{1}{6},\forall v\in\Y:\P[U\in v\mid V=v]=1\right\}.
\end{equation}
We do not know the strategy of the game master when $3$ or $4$ is rolled. However, we do know that the die is fair and that the game master is not able to lie, thus we put this information in our model.

For shorthand purposes, we write $y_1=\{1,2,3,4\}$ and $y_2=\{3,4,5,6\}$ such that $\Y=\{y_1,y_2\}$ from now on.

\begin{proposition}\label{prop:SafeDice}
Let $\X$, $\Y$, $\Omega$, $U$, $V$ and $\Pmod$ be as before. Let
\begin{equation}
\tilde{\mathcal{P}}=\left\{\P\middle|
\begin{array}{l}
\P[U=1\mid V=y_1]=\P[U=2\mid V=y_1],\\
\P[U=3\mid V=y_1]=\frac{1}{2}-5\P[U=1\mid V=y_1],\\
\P[U=5\mid V=y_2]=\P[U=6\mid V=y_2],\\
\P[U=3\mid V=y_2]=3\P[U=5\mid V=y_2]+\frac{1}{2},\\
\P[U=1\mid V=y_1],\P[U=5\mid V=y_1]\in\left[0,\frac{1}{10}\right]
\end{array}
\right\}
\end{equation}
be a set of probability distributions on $\Omega$. Let $\Psafe$ be a probability distribution on $\Omega$ with $\Psafe[U=1|V=y_1]=\Psafe[U=2|V=y_1]$, $\Psafe[U=5|V=y_2]=\Psafe[U=6|V=y_2]$ and $\Psafe[U\in y|V=y]=1$ for all $y\in\Y$. The following are equivalent:
\begin{enumerate}
    \item $\Psafe$ is a member of $\tilde{\mathcal{P}}$.
    \item $\Psafe$ is safe for $\langle U\rangle|[V]$.
    \item $\Psafe$ is safe for $\langle U\rangle|\langle V\rangle$.
\end{enumerate}

Distribution $\Psafe$ is not safe for $U|[V]$.
\end{proposition}
\begin{proof}
Here we will abbreviate $\Psafe[U=u|V=v]$ to $\Psafe[u|v]$ for all $(u,v)\in\Omega$. We will start with the implication from 1 to 2. Take an arbitrary $\Psafe\in\tilde{\mathcal{P}}$. We then have
\begin{equation}
\E_{\P}[U]=\sum_{u=1}^6 u\P[U=u]=\frac{7}{2}.
\end{equation}
Consider $y_1$ first. Writing $\Psafe[u|y_1]$ in terms of $\Psafe[1|y_1]$ for all $u\in\{2,3,4\}$ gives
\begin{align}
\E_{\Psafe}[U|V=y_1]&=\Psafe[1|y_1]+2\Psafe[1|y_1]+3\left(\frac{1}{2}-5\Psafe[1|y_1]\right)+4\left(3\Psafe[1|y_1]+\frac{1}{2}\right)\\
&=\frac{7}{2}+15\Psafe[1|y_1]-15\Psafe[1|y_1]=\frac{7}{2}.
\end{align}
The same calculation holds for $V=y_2$ as well. Therefore we have the equality $\E_{\P}[U]=\E_{\Psafe}[U|V=v]$ for all $\P\in\Pmod$ and $v\in\supp_{\Psafe}(V)$, letting $\Psafe$ fulfil the requirement of safety for $\langle U\rangle|[V]$.

The implication from 2 to 3 follows from Proposition~\ref{prop:SafeImply}.

Lastly, we will prove the implication from 3 to 1. Let $\Psafe$ be safe for $\langle U\rangle|\langle V\rangle$. Let $\P\in\Pmod$ be arbitrary and take $p,q\in[0,1]$ with $\P[V=y_2|U=3]=p$ and $\P[V=y_2|U=4]=q$.\\
Definition~\ref{def:SafeProp} states that we need $\E_{\P}[\E_{\Psafe}[U|V]]=\E_{\P}[U]$. The right-hand side is already computed as $\E_{\P}[U]=\frac{7}{2}$. For $\E_{\P}[\E_{\Psafe}[U|V]]$, we first focus on $V=y_1$. Conditioning on $U$ yields
\begin{equation}
\P[V=y_1]=\sum_{u=1}^6\P[V=y_1|U=u]\P[U=u]=\frac{1}{6}\sum_{u=1}^6\P[V=y_1|U=u].
\end{equation}
The game master cannot lie, thus $\P[V=y_1|U=1]=\P[V=y_1|U=2]=1$ and $\P[V=y_1|U=5]=\P[V=y_1|U=6]=0$ immediately hold. We further have $\P[V=y_2|U=3]=p$ and $\P[V=y_2|U=4]=q$, thus the value of $\P[V=y_1]$ is
\begin{equation}
\P[V=y_1]=\frac{1}{6}\sum_{u=1}^6\P[V=y_1|U=u]=\frac{2}{3}-\frac{p+q}{6}.
\end{equation}
Since $\Y$ only has two elements, $\P[V=y_2]=\frac{1}{3}+\frac{p+q}{6}$ follows. We can now write out $\E_{\P}[\E_{\Psafe}[U|V]]$ to
\begin{align}
\E_{\P}[\E_{\Psafe}[U|V]]&=\E_{\Psafe}[U|V=y_1]\P[V=y_1]+\E_{\Psafe}[U|V=y_2]\P[V=y_2]\\
&=\left(\Psafe[1|y_1]+2\Psafe[2|y_1]+3\Psafe[3|y_1]+4\Psafe[4|y_1]\right)\left(\frac{2}{3}-\frac{p+q}{6}\right)\nonumber\\
&\phantom{=}+\left(3\Psafe[3|y_2]+4\Psafe[4|y_2]+5\Psafe[5|y_2]+6\Psafe[6|y_2]\right)\left(\frac{1}{3}+\frac{p+q}{6}\right).
\end{align}
This collapes to
\begin{align}
\E_{\P}[\E_{\Psafe}[U|V]]&=\frac{p+q}{6}\left(\sum_{u=3}^{6}u\Psafe[u|y_2]-\sum_{u=1}^4u\Psafe[u|y_1]\right)+\sum_{u=1}^4\frac{2u}{3}\Psafe[u|y_1]\nonumber\\
&\phantom{=}+\sum_{u=3}^6\frac{u}{3}\Psafe[u|y_2].
\end{align}
As we have $\E_{\P}[U]=\frac{7}{2}$, we need to get rid of the dependence on $p+q$. This results into the condition
\begin{equation}
\sum_{u=3}^{6}u\Psafe[u|y_2]=\sum_{u=1}^4u\Psafe[u|y_1].
\end{equation}
When this condition is satisfied, we need
\begin{equation}
\sum_{u=1}^4\frac{2u}{3}\Psafe[u|y_1]+\sum_{u=3}^6\frac{u}{3}\Psafe[u|y_2]=\frac{7}{2}
\end{equation}
for $\Psafe$ to be safe for $\langle U\rangle|\langle V\rangle$. We impose one further assumption on our safe probability to reduce the amount of possible safe probabilities. Suppose the die shows $5$ or $6$, the game master has to tell $y_2$. Thus it is logical to assume that $\Psafe[5|y_2]=\Psafe[6|y_2]$ and $\Psafe[1|y_1]=\Psafe[2|y_1]$, as when an $y_2$ is revealed there is no reason why $5$ is preferred more than $6$. As the game master cannot lie,
\begin{equation}
\Psafe[5|y_1]=\Psafe[6|y_1]=\Psafe[1|y_2]=\Psafe[2|y_2]=0
\end{equation}
can be assumed. Luckily, these assumptions are made mandatory by the proposition. This all results into the following system of equations:
\begin{equation}\label{eq:SafeDiceSystem}
\begin{pmatrix}
\frac{2}{3}&\frac{4}{3}&2&\frac{8}{3}&1&\frac{4}{3}&\frac{5}{3}&2\\
-1&-2&-3&-4&3&4&5&6\\
1&-1&0&0&0&0&0&0\\
0&0&0&0&0&0&1&-1\\
1&1&1&1&0&0&0&0\\
0&0&0&0&1&1&1&1
\end{pmatrix}\begin{pmatrix}
\Psafe[1|y_1]\\\Psafe[2|y_1]\\\Psafe[3|y_1]\\\Psafe[4|y_1]\\
\Psafe[3|y_2]\\\Psafe[4|y_2]\\\Psafe[5|y_2]\\\Psafe[6|y_2]
\end{pmatrix}=\begin{pmatrix}
\frac{7}{2}\\0\\0\\0\\1\\1
\end{pmatrix}.
\end{equation}
The set $\tilde{\mathcal{P}}$ is the set of all probability distributions that are solution to this system. As $\Psafe\in\tilde{\mathcal{P}}$ needs to be a valid probability distribution, we need to have $\Psafe[u|v]\in[0,1]$ for all $(u,v)\in\Omega$. Solving \eqref{eq:SafeDiceSystem} gives
\begin{align}
\Psafe[3|y_1]&=3\Psafe[1|y_1]+\frac{1}{2},\\
\Psafe[4|y_1]&=5\Psafe[1|y_1]-\frac{1}{2},
\end{align}
thus $\Psafe[3|y_1]\in[0,1]$ holds when $\Psafe[1|y_1]\in\left[0,\frac{1}{6}\right]$ and $\Psafe[4|y_1]\in[0,1]$ holds when $\Psafe[1|y_1]\in\left[0,\frac{1}{10}\right]$. Without loss of generality $\Psafe[5|y_2]\in\left[0,\frac{1}{10}\right]$ must hold as well. This proves the last requirement $\Psafe[1|y_2],\Psafe[5|y_2]\in\left[0,\frac{1}{10}\right]$ from $\tilde{\mathcal{P}}$ and completes our proof that if a distribution $\Psafe$ is safe for $\langle U\rangle|\langle V\rangle$ with the requirements in the proposition, it is a member of $\tilde{\mathcal{P}}$.

Lastly we turn to safety for $U|[V]$. Pick probability measure $\Psafe$ on $\Omega$ arbitrarily with $\Psafe[1|y_1]=\Psafe[2|y_1]$, $\Psafe[5|y_2]=\Psafe[6|y_2]$ and $\Psafe[U\in y|V=y]=1$ for all $y\in\Y$. Proposition~\ref{prop:SafeProperties} implies $\Psafe[u|y_1]=\frac{1}{6}$ for all $u\in\X$, which is a clear contradiction to $\Psafe[U\in y|V=y]=1$. Thus there is no probability measure $\Psafe$ with the requirements in the proposition that is safe for $U|[V]$.
\end{proof}

The original question of the dice game did not concern an overall safe probability distribution for the whole die, but rather the probability of rolling $3$. Proposition~\ref{prop:DiscDiceSafe} states that a distribution $\Psafe$ is safe for $\langle\DieInd\rangle|\langle V\rangle$ as well as $\DieInd|[V]$ if and only if $\Psafe[U=3|V=v]=\frac{1}{6}$ holds for all $v\in\Y$. It is therefore safe to ignore the statement of the game master when guessing the probability of the die rolling to a $3$ and safe to state that the probability of rolling to a $3$ remains $\frac{1}{6}$.

A safe distribution for a statement of $\langle\1_{\{U=1\}}\rangle|\langle V\rangle$ cannot exist, as the following proposition will prove.

\begin{proposition}
There is no probability distribution $\Psafe$ on $\Omega$ that is safe for $\langle\1_{\{U=u\}}\rangle|\langle V\rangle$ with $u\in\{1,2,5,6\}$ when $\Psafe[U\in v|V=v]=1$ is required for all $v\in\Y$.
\end{proposition}
\begin{proof}
Pick $u=1$ and suppose $\Psafe$ is safe for $\langle\1_{\{U=1\}}\rangle|\langle V\rangle$. Let $p,q\in[0,1]$ be as in the proof of Proposition~\ref{prop:SafeDice}. As $V=y_1$ is the only possible option when rolling $1$, we have
\begin{align}
\E_{\P}[\E_{\Psafe}[\1_{\{U=1\}}|V]]&=\Psafe[U=1|V=y_1]\P[V=y_1]\\
&=\Psafe[U=1|V=y_1]\left(\frac{2}{3}-\frac{p+q}{6}\right).
\end{align}
We need $\E_{\P}[\E_{\Psafe}[\1_{\{U=1\}}|V]]=\P[U=1]=\frac{1}{6}$, but there is no possible value for $\Psafe[U=1|V=y_1]$ such that
\begin{equation}
\Psafe[U=1|V=y_1]\left(\frac{2}{3}-\frac{p+q}{6}\right)=\frac{1}{6}
\end{equation}
holds for all $p,q\in[0,1]$. This only happens when $p+q=1$, so there is a contradiction. Therefore $\Psafe$ cannot be safe for $\langle\1_{\{U=1\}}\rangle|\langle V\rangle$.

This proof applies to all $v\in\{1,2,5,6\}$, where in the case of $v\in\{5,6\}$ we need to condition on $V=y_2$ instead of $V=y_1$.
\end{proof}

\subsection{Conclusion}
To conclude, in the example of the dice game, we cannot compute a unique conditional distribution for $U|V$. However, we were able to create a set of probability distributions that are all unbiased for $U|V$. When only considering the probability of the die rolling to a specific value, we can create a safe distribution for the values 3 or 4, which will be done in Proposition~\ref{prop:DiscDiceSafe}. A safe distribution for the values $1$, $2$, $5$ and $6$ does not exist.

\chapter{Discrete conditional paradoxes}\label{chap:DiscPara}
Consider the following three problems:

\paragraph{The Monty Hall problem}
There are three doors. Two doors have a goat behind and one door a car. The player initially chooses a door, say he chooses door $a$. The game master then opens either door $b$ or door $c$, however he never opens the door with the car. After opening a door, the player is asked if he should switch. He ultimately wins the contents behind the door he has chosen. Should the player switch to the other door?


\paragraph{The boy or girl problem}
Suppose you encounter a stranger in a bar and you two get in conversation. Suddenly, the stranger states that he has two children and at least one of them is a girl. What is the probability he has two daughters?

\paragraph{The dice game}
This game is already introduced in Section~\ref{sec:SafeDice}, but here is a repeat. A die is rolled. Only the game master is able to observe the die's value. He then tells you whether the value of the die is in the set $\{1,2,3,4\}$ or in the set $\{3,4,5,6\}$. What is the probability of the die landing on a $3$ given the game master's statement?

\paragraph{}
All three problems essentially have the same structure. Firstly, there is a finite set of outcomes in each problem. Monty Hall's problem has three doors, the boy or girl problem has three distinct family compositions and there are six values on a die. Secondly, the game master must reveal some information where it is essential that at least one outcome exists remaining possible no matter what the game master reveals. For that outcome the game master is free to choose his revelation. If in Monty Hall's problem door $a$ has the car, the game master can choose to either open door $a$ or door $b$. If for the boy or girl problem the stranger has one son and one daughter, he is free to choose whether he tells at least one child is a boy or at least one is a girl. If the die rolled 3 in the dice game, the game master is free to choose to reveal $\{1,2,3,4\}$ or $\{3,4,5,6\}$.\\
Since there is at least one outcome remaining possible no matter which revelation the game master makes, traditional conditional probability does not suffice. This is seen for example in the dice game in Section~\ref{sec:SafeDice}, where Equation~\ref{eq:SafeDiceCon6} states that the probability of rolling $6$ given $\{3,4,5,6\}$ dilates from $\frac{1}{4}$ to $\frac{1}{2}$. Measure-theoretic conditional probability is not sufficient as well, as the smallest sub-$\sigma$-algebra of $\{1,2,3,4,5,6\}$ containing the subset $\{\{1,2,3,4\},\{3,4,5,6\}\}$ does not contain the set $\{3\}$. When a larger sub-$\sigma$-algebra is chosen that does contain $\{3\}$, a version of the measure-theoretic conditional expectation cannot be found as the problem does not state the probability of for example revealing $\{1,2,3,4\}$ when a $3$ is rolled.

All three problems can be analysed using the same methods; they are essentially equal. The game master has a choice and therefore is able to employ a strategy. To counteract such strategies we need to first model all possible probability distributions. We can then create a pragmatic probability distribution using safe probability where the decision maker can act on. This distribution performs for predicting the distribution on the outcome space on average as well as all probability distributions in the model.

In this chapter we first introduce Theorem~\ref{thm:DiscMainThm} to create safe probability distributions in the setting of the three introduced problems. Then each problem is treated individually where Theorem~\ref{thm:DiscMainThm} is applied and we will discuss the results. The dice game will be treated in Section~\ref{sec:DiscDice}, the Monty Hall problem will be treated in Section~\ref{sec:DiscMonty} and the boy or girl problem will be treated in Section~\ref{sec:DiscChildren}. We will conclude with Section~\ref{sec:DiscConcl} by stating that there is nothing paradoxical going on with the three problems. The paradoxical statements are just misapplications of conditional probability.

\section{The main theorem}\label{sec:DiscMain}
In the general setting we consider a set $\X$ of all possible outcomes called the \emph{outcome space} and a set $\Y$ of observations the player can make called the \emph{observation space}. Our sample space then becomes $\Omega=\X\times\Y$. Let $U$ be an $\X$-valued random variable denoting the outcome of the game, e.g.~the door containing the car in the Monty Hall problem or the family composition in the boy or girl problem. Let $V$ be a $\Y$-valued random variable denoting the statement of the game master, e.g.~the opening of door $b$ in the Monty Hall problem. Using safe probability we will for all $u\in\X$ create a safe distribution for $\1_{\{U=u\}}|[V]$.

\begin{theorem}\label{thm:DiscMainThm}
Let $\X$ be countable and $\Y$ be finite. Let $U$ be an $\X$-valued random variable and $V$ be a $\Y$-valued random variable. Let $\{p_u\}_{u\in\X}\subset[0,1]$ with $\sum_{u\in\X}p_u=1$. Let
\begin{equation}\label{eq:DiscMainMod}
\Pmod\subseteq\{\P\mid\forall u\in\X:\P[U=u]=p_u\}
\end{equation}
be our model of probability distributions on $\X\times\Y$ where $|\Y|$ distributions $\P_1,\ldots,\P_{|\Y|}\in\Pmod$ impose $|\Y|$ linearly independent vectors $(\P_i[V=v])_{v\in\Y}$ with $i\in\{1,\ldots,|\Y|\}$. Let $u\in\X$ be arbitrary and let $\Psafe$ be a distribution on $\X\times\Y$ with full support on $V$, then the following are equivalent:
\begin{enumerate}
    \item For all $v\in\Y$ we have $\Psafe[U=u|V=v]=p_{u}$.
    \item $\Psafe$ is safe for $\GeneralInd|[V]$.
    \item $\Psafe$ is safe for $\langle\GeneralInd\rangle|\langle V\rangle$.
\end{enumerate}
\end{theorem}
\begin{proof}
The implication from 1 to 2 is satisfied by Proposition~\ref{prop:SafeProperties}. Let $v\in\Y$ and $\P\in\Pmod$ be arbitrary, then we have
\begin{equation}
\Psafe[U=u|V=v]=p_{u}=\P[U=u].
\end{equation}
Proposition~\ref{prop:SafeProperties} states that $\Psafe$ is safe for $\GeneralInd|[V]$.

The implication from 2 to 3 is by Proposition~\ref{prop:SafeImply}.

Consider lastly the implication from 3 to 1. Safety for $\langle\GeneralInd\rangle|\langle V\rangle$ implies
\begin{equation}
\E_{\P}[\GeneralInd]=\E_{\P}[\E_{\Psafe}[\GeneralInd|V]]
\end{equation}
for all $\P\in\Pmod$. We will construct a sufficient $\Psafe$ from this requirement and prove that $\Psafe[U=u|V=v]=p_{u}$ for all $v\in\Y$ is necessary.\\
Let $\P\in\Pmod$ be arbitrary. Take a first look at $\E_{\P}[\GeneralInd]$, then
\begin{equation}
\E_{\P}[\GeneralInd]=\P[U=u]=p_{u}.
\end{equation}
Let $\Psafe$ be a arbitrary distribution on $\X\times\Y$ that is safe for $\langle\GeneralInd\rangle|\langle V\rangle$ and let $v\in\Y$ be arbitrary, then we can write out
\begin{equation}
\E_{\Psafe}[\GeneralInd|V=v]=\Psafe[U=u|V=v].
\end{equation}
The value $\Psafe[U=u|V=v]$ exists since $\Psafe$ has full support on $V$. The expectation $\E_{\P}[\E_{\Psafe}[\GeneralInd|V]]$ can now be expanded to
\begin{align}
\E_{\P}[\E_{\Psafe}[\GeneralInd|V]]&=\sum_{v\in\supp_{\P}(V)}\E_{\Psafe}[\GeneralInd|V=v]\P[V=v]\\
&=\sum_{v\in\supp_{\P}(V)}\Psafe[U=u|V=v]\P[V=v].
\end{align}
We now need to abbreviate our notation. From now on we write $\Psafe[u|v]$ instead of $\Psafe[U=u|V=v]$ for all $(u,v)\in\X\times\Y$. For safety for $\langle\GeneralInd\rangle|\langle V\rangle$ we require
\begin{equation}
p_{u}=\E_{\P}[\E_{\Psafe}[\GeneralInd|V]]=\sum_{v\in\supp_{\P}(V)}\Psafe[u|v]\P[V=v].\label{eq:DiscSafeCondition}
\end{equation}
We will also abbreviate the index of the sum to $v\in\Y$ instead of $v\in\supp_{\P}(V)$, as $\P[V=v]=0$ will be zero for every $v\in\Y\setminus\supp_{\P}(V)$ and this will have no impact on the summation.\\
Note that equation~\ref{eq:DiscSafeCondition} is a linear combination of the vectors $(\Psafe[u|v])_{v\in\Y}$ and $(\P[V=v])_{v\in\Y}$ and the values of the latter vector are known, thus the equation $\sum_{v\in\Y}\Psafe[u|v]\P[V=v]=p_{u}$ is linear. Since $\Pmod$ has $|\Y|$ distributions $\P_1,\ldots,\P_{|\Y|}$ that have linearly independent vectors $(\P_i[V=v])_{v\in\Y}$ with $i\in\{1,\ldots,|\Y|\}$, we can create a system of $|\Y|$ linearly independent equations
\begin{equation}
\sum_{v\in\Y}\Psafe[u|v]\P_i[V=v]=p_{u},\qquad i\in\{1,\ldots,|\Y|\}.
\end{equation}
Since we have a system of $|\Y|$ linearly independent equations with $|\Y|$ unknowns $\Psafe[u|v_1],\ldots,\Psafe[u|v_{|\Y|}]$, there is a unique solution. The coefficients $\P[V=v]$ with sum up to~$1$, thus $\Psafe[u|v]=p_{u}$ is the unique solution to this system.\\
Let now $\P\in\Pmod$ again be arbitrary, then the requirement in Equation~\ref{eq:DiscSafeCondition} still holds as
\begin{equation}
\E_{\P}[\E_{\Psafe}[\GeneralInd|V]]=\sum_{v\in\supp_{\P}(V)}\Psafe[u|v]\P[V=v]=p_{u}\sum_{v\in\supp_{\P}(V)}\P[V=v]=p_{u}.
\end{equation}
Therefore $\Psafe[u|v]=p_{u}$ for all $v\in\Y$ is required for $\Psafe$ when $\Psafe$ is safe for $\langle\GeneralInd\rangle|\langle V\rangle$, thus 3 implies 1.
\end{proof}

It looks like Theorem~\ref{thm:DiscMainThm} can only be applied in a few circumstances. However, the restriction on model $\Pmod$ is in many cases quickly satisfied, as in most cases $\Pmod$ is not a strict subset of the set in Equation~\ref{eq:DiscMainMod}. If $\Pmod$ is equal to the set in Equation~\ref{eq:DiscMainMod}, then the distributions $\P_i$ with $\P_i[V=v_j]=\delta_{ij}$ for all $i,j\in\{1,\ldots,|\Y|\}$, with $\delta$ the Kronecker delta, form a sequence of $|\Y|$ linearly independent unit vectors imposed from $|\Y|$ distributions of $\Pmod$. In other cases when excluding the unit vectors, if for all $v\in\Y$ there is a $\P\in\Pmod$ with $v\in\supp_{\P}(V)$, then finding $|\Y|$ different distributions that impose $|\Y|$ linearly independent marginal probabilities on $V$ is not a hard task; otherwise the model $\Pmod$ is simply too small. This leads to the following lemma that is helpful when checking whether the model is large enough to apply Theorem~\ref{thm:DiscMainThm}.
\begin{lemma}\label{lem:DiscMainReq}
Let $\X$, $\Y$, $U$, $V$, $\{p_u\}_{u\in\X}$ be as in Theorem~\ref{thm:DiscMainThm}.  Let
\begin{equation}
\Pmod\subseteq\{\P\mid\forall u\in\X:\P[U=u]=p_u\}.
\end{equation}
It is necessary that $\bigcup_{\P\in\Pmod}\supp_{\P}(V)=\Y$ holds for $\Pmod$ to fulfil the requirements of Theorem~\ref{thm:DiscMainThm}.
\end{lemma}
\begin{proof}
Suppose $\bigcup_{\P\in\Pmod}\supp_{\P}(V)\neq\Y$, then there is a $v'\in\Y$ with $\P[V=v']=0$ for all $\P\in\Pmod$. Take this $v'$ and let $\P_1,\ldots,\P_{|\Y|}\in\Pmod$ be an arbitrary sequence of distributions. Then the vectors $(\P_1[V=v])_{v\in\Y},\ldots,(\P_{|\Y|}[V=v])_{v\in\Y}$ are not linearly independent as the vectors are of size $|\Y|$ as well and the entry of $v'$ is always zero.
\end{proof}

Furthermore, Theorem~\ref{thm:DiscMainThm} implies that a safe probability for $\GeneralInd|[V]$ can be created for all $u\in\X$. However, earlier in the introduction of Section~\ref{sec:DiscMain} we specifically discussed a special $u'\in\X$ that is supported by $U|V=v$ for all $v\in\supp_{\P}(V)$ and $\P\in\Pmod$.\\
Take for example the dice game. There either $3$ or $4$ can be picked as $u'$ as those values are still possible after the game master's statement that the value of the die is either in $\{1,2,3,4\}$ or in $\{3,4,5,6\}$. According to Theorem~\ref{thm:DiscMainThm} we can pick $u'=1$ as well to create a safe distribution $\Psafe$ for $\1_{\{U=1\}}|[V]$, however this implies
\begin{equation}
\Psafe[U=1|V=\{3,4,5,6\}]=\frac{1}{6}.
\end{equation}
Thus according to safe probability we need to assume that the game master lies with probability $\frac{1}{6}$ when he tells the die has rolled three or higher, while in the problem we specifically assume the game master is not able to lie. This solution or distribution should therefore not be regarded as admissible, while it is still mathematically valid. When calculating a safe distribution $\Psafe$ for $\DieInd|[V]$, as is done in Proposition~\ref{prop:DiscDiceSafe}, we obtain $\Psafe[U=3|V=v]=\frac{1}{6}$ for all $v\in\Y$. Since for all $v\in\Y$ a $\P\in\Pmod$ exists with $\P[U=3|V=v]>0$, putting a positive probability on $U=3$ given any value of $V$ is a wise thing to do.\\
Therefore, while Theorem~\ref{thm:DiscMainThm} can be applied in many cases, it is wise to only apply it on $\GeneralInd|V$ when firstly $\P[U=u]=p_u>0$ holds for all $\P\in\Pmod$ and secondly when this $u$ is a member of the set
\begin{equation}\label{eq:DiscMainUReq}
\bigcap_{\P\in\Pmod}\bigcap_{v\in\supp_{\P}(V)}\range(U|V=v).
\end{equation}
Explaining the second requirement, since the event $\{U=u\}$ has positive and equal probability for all $\P\in\Pmod$ and since we have $\bigcup_{\P\in\Pmod}\supp_{\P}(V)=\Y$ by Lemma~\ref{lem:DiscMainReq}, for each $v\in\Y$ a $\P\in\Pmod$ must exist with $\P[U=u|V=v]>0$ when $u$ is a member of the set in Equation~\ref{eq:DiscMainUReq}, making it sensible to put $\Psafe[U=u|V=v]=\P[U=u]>0$.

The requirement $\Y=\bigcup_{\P\in\Pmod}\supp_{\P}(V)$ is however restrictive. The following proposition drops this requirement, but the equivalence in Theorem~\ref{thm:DiscMainThm} disappears as well leaving only the implications from 1 to 2 and from 2 to 3.

\begin{proposition}\label{prop:DiscSafeMargGen}
Let $\X$, $\Y$, $U$, $V$ and $\{p_{u}\}_{u\in\X}$ be as before. Let
\begin{equation}
\Pmod\subseteq\{\P|\forall u\in\X:\P[U=u]=p_u\}
\end{equation}
be non-empty and let $\Psafe$ be a distribution on $\X\times\Y$. Let $u\in\X$, then $\Psafe$ is safe for $\GeneralInd|[V]$ if $\Psafe[U=u|V=v]=p_{u}$ holds for all $v\in\Y$. This $\Psafe$ is safe for $\langle\GeneralInd\rangle|\langle V\rangle$ as well.
\end{proposition}
\begin{proof}
Let $\P\in\Pmod$ and $v\in\Y$ be arbitrary, then we have
\begin{equation}
\Psafe[U=u|V=v]=p_{u}=\P[U=u].
\end{equation}
Proposition~\ref{prop:SafeProperties} states that this $\Psafe$ is safe for $\GeneralInd|[V]$.

Safety for $\langle\GeneralInd\rangle|\langle V\rangle$ now immediately follows for $\Psafe$ by Proposition~\ref{prop:SafeImply}.
\end{proof}

Note that from the proof of Proposition~\ref{prop:DiscSafeMargGen} one can deduce that the elaborate set-up in Theorem~\ref{thm:DiscMainThm} is not necessarily needed and that Proposition~\ref{prop:DiscSafeMargGen} is nothing more than an applied restatement of the fourth property of Proposition~\ref{prop:SafeProperties}. However, in the case of Proposition~\ref{prop:DiscSafeMargGen}, you do not know whether distributions exist that are safe for $\langle \GeneralInd\rangle|\langle V\rangle$ but not for $\GeneralInd|[V]$. In the case of Theorem~\ref{thm:DiscMainThm}, safety for $\langle \GeneralInd\rangle|\langle V\rangle$ and $\GeneralInd|[V]$ are equivalent. Finding a safe distribution for $\GeneralInd|[V]$ is easy when the distribution on $U$ in $\Pmod$ is known, however for knowing that only these distributions are unbiased for $U$ we need Theorem~\ref{thm:DiscMainThm}.

Theorem~\ref{thm:DiscMainThm} only considers single $u\in\X$. We can construct safe probability distributions for $\GeneralGenInd|V$ for larger $\X'\subset\X$ as well in the following corollary.
\begin{corollary}\label{cor:DiscSafeGeneral}
Let $\X$, $\Y$, $U$, $V$, $\{p_u\}_{u\in\Y}$ and $\Pmod$ be as in Theorem~\ref{thm:DiscMainThm}. Let $\X'\subseteq\X$ be non-empty. Let $\Psafe$ be a distribution on $\X\times\Y$ with full support on $V$, then the following are equivalent:
\begin{enumerate}
    \item For all $u\in\X'$ and $v\in\Y$ we have $\Psafe[U=u|V=v]=p_{u}$.
    \item $\Psafe$ is safe for $\GeneralGenInd|[V]$.
    \item $\Psafe$ is safe for $\langle\GeneralGenInd\rangle|\langle V\rangle$.
\end{enumerate}
\end{corollary}
\begin{proof}
The proof is in essence a repetition of the proof of Theorem~\ref{thm:DiscMainThm} where $\GeneralGenInd=\max_{u\in\X'}\GeneralInd=\sum_{u\in\X'}\GeneralInd$ must be used.
\end{proof}

\subsection{Accuracy}
Suppose you are in a situation where you need to guess $\GeneralGenInd$ for an $\X'\subset\X$. One example is the Monty Hall game where on live television you need to guess whether your door $a$ has the car behind, thus whether $\1_{\{U=a\}}=1$ holds given the opened door $V$. To probability of guessing correctly is called the \emph{accuracy}.

\begin{definition}[Accuracy]\label{def:DiscAccuracy}
Let $\mathcal{Z}$ be a countable set. Let $X$ and $Y$ be $\mathcal{Z}$-valued random variables. Let $\Pmod$ be a set of probability measures on $\mathcal{Z}$ and let $\P'$ be an arbitrary probability measure on $\mathcal{Z}$ denoting the distribution of $X$. The \emph{accuracy of $X$ for guessing $Y$ distributed by $\P$} is defined by
\begin{equation}
\acc_Y^{\P}(X)=\sum_{k\in\mathcal{Z}}\P'[X=k]\P[Y=k].
\end{equation}
When $\acc_Y^{\P}(X)$ is constant for all $\P\in\Pmod$, this value is called the \emph{accuracy of $X$ for guessing $Y$} and is denoted by $\acc_Y(X)$. If from context it is clear we want to guess $Y$, we write \emph{the accuracy of $X$} and denote this by $\acc(X)$.
\end{definition}

The next theorem optimizes the accuracy of a random variable $\GeneralGenInd^*$ for guessing $\GeneralGenInd$ against all $\P\in\Pmod$.
\begin{theorem}\label{thm:DiscAccOpt}
Let $\X$, $\Y$, $U$, $V$, $\{p_u\}_{u\in\Y}$ and $\Pmod$ be as in Proposition~\ref{prop:DiscSafeMargGen} and let $\X'\subseteq\X$ be non-empty. Let $\GeneralGenInd^*$ be a binary-valued random variable on $\X\times\Y$ with probability measure $\P'$ such that $\GeneralGenInd^*$ is distributed as
\begin{equation}\
\GeneralGenInd^*\sim\begin{cases}
1,&\sum_{u\in\X'}p_u>\frac{1}{2},\\
0,&\sum_{u\in\X'}p_u<\frac{1}{2},\\
\mathrm{Ber}(p),&\sum_{u\in\X'}p_u=\frac{1}{2},p\in[0,1]
\end{cases}
\end{equation}
where $\mathrm{Ber}(p)$ is the Bernoulli distribution with parameter $p\in[0,1]$. This distribution guesses $\GeneralGenInd$ correctly with probability
\begin{equation}
\acc^{\P}\left(\GeneralGenInd^*\right)=\max\left\{\sum_{u\in\X'}p_u,1-\sum_{u\in\X'}p_u\right\}.
\end{equation}

Any other binary random variable $W$ has a lower accuracy than $\GeneralGenInd^*$.
\end{theorem}
\begin{proof}
Let $\P\in\Pmod$ be arbitrary and let $W$ be an arbitrary $\{0,1\}$-valued random variable on $\X\times\Y$. Let $\hat{\P}$ be an arbitrary probability measure on $\X\times\Y$ which we will apply on $W$. We will first prove that $\acc^{\P}(W)$ is constant for all $\P\in\Pmod$ and then prove that $W=\GeneralGenInd^*$ maximizes the accuracy of $W$.

By Definition~\ref{def:DiscAccuracy} and the fact that $\P\in\Pmod$ we have
\begin{align}
\acc_{\P}(W)&=\hat{\P}[W=0]\sum_{u\in\X\setminus\X'}\P[U=u]+\hat{\P}[W=1]\sum_{u\in\X'}\P[U=u]\\
&=\hat{\P}[W=0]\left(1-\sum_{u\in\X'}p_u\right)+\hat{\P}[W=1]\sum_{u\in\X'}p_u,
\end{align}
thus $\acc^{\P}(W)$ is constant for all $\P\in\Pmod$. Abbreviate the terms $\sum_{u\in\X'}p_u=x$ and $\hat{\P}[W=1]=p$. We now need to maximize
\begin{equation}
f(p):=px+(1-p)(1-x)=p(2x-1)+1-x.
\end{equation}
Note that both $x,p\in[0,1]$. Consider the following different cases for $x$.
\begin{itemize}
    \item[$x>\frac{1}{2}$:] When $x>\frac{1}{2}$ holds, the function $f$ is strictly increasing in $p$. Its maximum is then achieved at $p=1$, which is $p$. Thus always guessing $W=1$ maximizes its accuracy.
    \item[$x<\frac{1}{2}$:] When $x<\frac{1}{2}$ holds, the function $f$ is strictly decreasing in $p$. Its maximum is then achieved at $p=0$, which is $1-x$. Thus always guessing $W=0$ maximizes its accuracy.
    \item[$x=\frac{1}{2}$:] When $x=\frac{1}{2}$ holds, the function $f$ is constant. Its value is $f(p)=\frac{1}{2}=x$ for all $p\in[0,1]$. Therefore if $W$ is made the Bernoulli distribution with parameter $p$, the accuracy of $W$ is maximized.
\end{itemize}
Therefore $W$ has maximal accuracy when $W=\GeneralGenInd^*$ and the accuracy of $\GeneralGenInd^*$ is
\begin{equation}
\acc\left(\GeneralGenInd^*\right)=\max\left\{\sum_{u\in\X'}p_u,1-\sum_{u\in\X'}p_u\right\}.
\end{equation}
\end{proof}

Suppose the player applies a safe distribution $\Psafe$ on his guess $\GeneralGenInd^*$ for $\GeneralGenInd$, what will the accuracy be? The following proposition answers this question.

\begin{proposition}\label{prop:DiscAccSafe}
Let $\X$, $\X'$, $\Y$, $U$, $V$, $\{p_u\}_{u\in\Y}$ and $\Pmod$ be as in Corollary~\ref{cor:DiscSafeGeneral}. Let $\Psafe$ be a safe distribution for $\GeneralGenInd|\langle V\rangle$. Let $\GeneralGenIndSafe$ be a $\{0,1\}$-valued random variable and employ distribution $\P'$ on $\GeneralGenIndSafe$ such that
\begin{equation}
\P'\left[\GeneralGenIndSafe=1\right]=\Psafe[\GeneralGenInd=1|V=v]=\sum_{u\in\X'}p_{u}
\end{equation}
holds for all $v\in\Y$. The accuracy of $\GeneralGenIndSafe$ is
\begin{equation}
\acc^{\P}\left(\GeneralGenIndSafe\right)=\left(\sum_{u\in\X'}p_{u}\right)^2+\left(1-\sum_{u\in\X'}p_{u}\right)^2
\end{equation}
for all $\P\in\Pmod$.
\end{proposition}
\begin{proof}
Let $\P\in\Pmod$ be arbitrary. By Corollary~\ref{cor:DiscSafeGeneral} and Definition~\ref{def:DiscAccuracy} we have
\begin{align}
\acc^{\P}\left(\GeneralGenIndSafe\right)&=\sum_{k=0}^1\P'\left[\GeneralGenIndSafe=k\right]\P[\GeneralGenInd=k]\\
&=\P'[\GeneralGenInd=0]\left(1-\sum_{u\in\X'}p_u\right)+\P'[\GeneralGenInd=1]\sum_{u\in\X'}p_u.
\end{align}
Since $\P[\GeneralGenInd=1]=\sum_{u\in\X'}p_u$ holds for all $\P\in\Pmod$, we can conclude that
\begin{equation}
\acc\left(\GeneralGenIndSafe\right)=\left(\sum_{u\in\X'}p_{u}\right)^2+\left(1-\sum_{u\in\X'}p_{u}\right)^2.
\end{equation}
\end{proof}

Now we know when a safe distribution $\Psafe$ for $\GeneralGenInd|[V]$ results into being the most accurate guess for $\GeneralGenInd$ as well.

\begin{corollary}
Let $\X$, $\X'$, $\Y$, $U$, $V$, $\{p_u\}_{u\in\Y}$ and $\Pmod$ be as in Corollary~\ref{cor:DiscSafeGeneral}. Let $\GeneralGenInd^*$ be as in Theorem~\ref{thm:DiscAccOpt}. Let $\Psafe$ be safe for $\GeneralGenInd|[V]$ and let $\GeneralGenIndSafe$ be as in Proposition~\ref{prop:DiscAccSafe}. The accuracy of $\GeneralGenIndSafe$ for guessing $\GeneralGenInd$ is only optimal when
\begin{equation}
\sum_{u\in\X'}p_u\in\left\{0,\frac{1}{2},1\right\}.
\end{equation}
\end{corollary}
\begin{proof}
Let $\P\in\Pmod$ be arbitrary. According to Proposition~\ref{prop:DiscAccSafe} the accuracy of $\GeneralGenIndSafe$ is
\begin{equation}
\acc\left(\GeneralGenIndSafe\right)=\left(\sum_{u\in\X'}p_{u}\right)^2+\left(1-\sum_{u\in\X'}p_{u}\right)^2.
\end{equation}
Theorem~\ref{thm:DiscAccOpt} states that the optimal accuracy for predicting $\GeneralGenInd$ is
\begin{equation}
\acc\left(\GeneralGenInd^*\right)=\max\left\{\sum_{u\in\X'}p_u,1-\sum_{u\in\X'}p_u\right\}.
\end{equation}

Note that $\GeneralGenIndSafe$ and $\GeneralGenInd^*$ are only equal when $\sum_{u\in\X'}p_u\in\{0,1\}$ holds or when $\sum_{u\in\X'}p_u=\frac{1}{2}$ and $\GeneralGenInd^*=\mathrm{Ber}\left(\frac{1}{2}\right)$ hold. The first case is quite trivial as when $\sum_{u\in\X'}p_u\in\{0,1\}$ we have $\acc\left(\GeneralGenIndSafe\right)=1$ as result. When $\sum_{u\in\X'}p_u=\frac{1}{2}$ holds, we have $\P[\GeneralGenIndSafe=1]=\frac{1}{2}$, resulting into $\GeneralGenIndSafe=\mathrm{Ber}\left(\frac{1}{2}\right)$. Since $\GeneralGenInd^*=\mathrm{Ber}\left(\frac{1}{2}\right)$ gives optimal accuracy for $\sum_{u\in\X'}p_u=\frac{1}{2}$ by Theorem~\ref{thm:DiscAccOpt}, the accuracy of $\GeneralGenIndSafe$ is in this case optimal with $\acc\left(\GeneralGenIndSafe\right)=\frac{1}{2}$.
\end{proof}

Knowing this, one must keep in mind that safe probability for $\GeneralGenInd|[V]$ gives in almost no case a prediction for $\GeneralGenInd|V$ with optimal accuracy. Safe probability merely simulates the distribution of $\GeneralGenInd$, where in the setting of Theorem~\ref{thm:DiscMainThm} the revelation of the game master is in no cases of influence. A safe probability distribution must therefore in this setting not directly be used to make predictions for $\GeneralGenInd$, but it can be used to create a different random variable that does predict $\GeneralGenInd$ with optimal accuracy. In the Monty Hall game, you should not switch with probability $\frac{2}{3}$, as then the probability of winning the car is $\frac{5}{9}$. If the player observes that the safe distribution in the Monty Hall game puts a probability of $\frac{1}{3}$ door $a$, then never choosing door $a$ yields a probability of winning the car of $\frac{2}{3}$, which is optimal by Theorem~\ref{thm:DiscAccOpt}.

\section{Dice game}\label{sec:DiscDice}
With the main theorems stated, we can apply them to some well-known paradoxes. We will first continue our example of the dice game, started in Section~\ref{sec:SafeDice}. Recall that a die is cast with values in $\X=\{1,2,3,4,5,6\}$ and the game master is, after observing the die's value, only able to reveal a member of the set $\Y=\{\{1,2,3,4\},\{3,4,5,6\}\}=:\{y_1,y_2\}$. Our sample space is $\Omega=\X\times\Y$ with its power set $\Sigma=2^\Omega$ as $\sigma$-algebra. Let $U$ be an $\X$-valued random variable and $V$ be a $\Y$-valued random variable. The game master is not allowed to lie and the die is fair, thus any probability distribution for this game must be a member of \begin{equation}
\Pmod=\left\{\P\middle|\forall u\in\X:\P[U=u]=\frac{1}{6},\forall y\in\Y:\P[U\in y|Y=y]=1\right\}.
\end{equation}

\subsubsection{Safe probability}
Proposition~\ref{prop:SafeDice} gives a set $\tilde{\mathcal{P}}$ of distributions that are all safe for $\langle U\rangle|[V]$. However, in the original problem we are not interested in the whole distribution of $U$ given $V$, but only want to know the probability of rolling $3$ after the game master's statement. Therefore finding safe distributions for $\DieInd|[V]$ is sufficient.

\begin{proposition}\label{prop:DiscDiceSafe}
Let $\X$, $\Y$, $\Omega$, $U$, $V$ and $\Pmod$ be as in the dice game. Let $\Psafe$ be a distribution on $\Omega$ with full support on $V$. Let $u\in\X$, then the following statements are equivalent:
\begin{enumerate}
\item For all $v\in\Y$ we have $\Psafe[U=u|V=v]=\frac{1}{6}$.
\item $\Psafe$ is safe for $\langle \1_{\{U=u\}}\rangle|\langle V\rangle$.
\item $\Psafe$ is safe for $\1_{\{U=u\}}|[V]$.
\end{enumerate}
\end{proposition}
\begin{proof}
This proposition is a direct application of Theorem~\ref{thm:DiscMainThm}. The set $\X$ is of size $6$ and therefore countable and the set $\Y$ is of size $2$, which makes it finite. $U$ is a random variable on $\X$ and $V$ is a random variable on $\Y$. In this dice game we have $p_u=\frac{1}{6}$ as $\P\in\Pmod$ implies $\P[U=u]=\frac{1}{6}$ for all $u\in\X$. Lastly, the set $\Pmod$ is a subset of $\{\P|\forall u\in\X:\P[U=u]=p_u\}$.

Take $\P_1,\P_2\in\Pmod$ with $\P_i[V=y_i|U=3]=\P_i[V=y_i|U=4]=1$. Let $i\in\{1,2\}$ be arbitrary, then
\begin{align}
\P_i[V=y_i]&=\sum_{u=1}^6\P_i[V=y_i|U=u]\P_i[U=u]\\
&=\frac{1}{6}\left(4\cdot1+2\cdot0\right)=\frac{2}{3}.
\end{align}
Thus the vectors $\left(\P_i[V=v]\right)_{v\in\Y}$ become $\left(\frac{1}{3},\frac{2}{3}\right)$ and $\left(\frac{2}{3},\frac{1}{3}\right)$, which are linearly independent.

Now we can directly apply Theorem~\ref{thm:DiscMainThm} to conclude the proof.
\end{proof}
\subsubsection{Accuracy}
Suppose you want to bet on this game and want to know whether you must put money on rolling $3$. As the following proposition will state, after observing the game master's statement, always stating that the die has not rolled to a $3$ has a $\frac{5}{6}$ chance of being correct independently on the game master's strategy and is the optimal probability.

\begin{proposition}
Let $\X$, $\Y$, $U$, $V$ and $\Pmod$ be as in the dice game. Consider the random variable $\DieInd^*\sim0$ distributed as the singular distribution on $0$, then this $\DieInd^*$ has accuracy
\begin{equation}
\acc^{\P}\left(\DieInd^*\right)=\frac{5}{6}
\end{equation}
for all $\P\in\Pmod$. There is no random variable $W$ with $\acc^{\P}(W)>\acc^{\P}(\DieInd^*)$ for a $\P\in\Pmod$.
\end{proposition}
\begin{proof}
We want to apply Theorem~\ref{thm:DiscAccOpt}. Firstly in this case $\X'=\{3\}\subset\X$ is non-empty. Secondly, we have $\sum_{u\in\X'}p_u=p_3=\frac{1}{6}<\frac{1}{2}$. Then Theorem~\ref{thm:DiscAccOpt} states that $\DieInd^*\sim0$ optimizes the accuracy for guessing $\DieInd$ with
\begin{equation}
\acc\left(\DieInd^*\right)=\max\left\{\frac{1}{6},\frac{5}{6}\right\}=\frac{5}{6}.
\end{equation}
\end{proof}

We now observe that using the information given by the game master does not lead to a higher probability of guessing $\DieInd$ correct. When always stating that the die has not rolled $3$ you maximize the probability of having a correct guess, which is $5$ out of $6$. The information revealed by the game master can therefore be ignored as it will not yield to a higher probability of guessing correctly.

\subsubsection{Final remarks}
We have seen that the conditional probability of rolling $3$ given the game master's statement is not uniquely defined; it dilates from $0$ to $\frac{1}{4}$ depending on the to the player unknown strategy of the game master. However, when playing like the probability of rolling $3$ is always $\frac{1}{6}$ disregarding the game master's statement, you are able to simulate the probability distribution of $\DieInd$. Furthermore, when always stating that the die has not rolled $3$, you are correct in five out of six games, which is the maximal fraction of games you can be correct on.

The paradoxical nature of this problem is that most people treat this problem with sample space $\Omega=\{1,2,3,4,5,6\}$ and condition on for example the information $\{3,4,5,6\}$. However, as we have seen in Section~\ref{sec:SafeDice}, we also need to condition on the possibility $\{1,2,3,4\}$ and those two sets cannot form a partition of $\Omega$. Therefore the sample space $\Omega$ is insufficient for solving this problem, resulting in the paradoxical statements.

This underlines the argument that when conditioning the accompanying sub-$\sigma$-algebra must always be given, as then it is easily seen that conditioning on a sub-$\sigma$-algebra containing $\sigma(\{\{1,2,3,4\},\{3,4,5,6\}\})\subset2^\Omega$ is not possible.

\section{Monty Hall}\label{sec:DiscMonty}
One of the most classic paradoxes in probability theory is Monty Hall's three door problem. The problem is already explained in the introduction of this chapter, but we will repeat it here.\footnote{Geschiedenis en bronnenonderzoek toevoegen.}

There are three doors called $a$, $b$ and $c$.  Two doors have a goat behind and one door has a car. The player chooses one door, where after the game master opens one of the remaining doors. The game master does not open the door with the car. The player is then asked whether he wants to switch to the remaining door. The player wins the contents of the door he ultimately chooses.

A logical question, and the centre of this paradox, is whether the player should switch when a door is opened. This question can be answered with multiple viewpoints. Throughout the whole analysis we assume that initially the car is placed behind a door with equal probability. Without loss of generality we now assume the player has chosen door $a$, as the initial choice of door has become independent of the question whether the player should switch.

The most naive viewpoint is the following. Say door $c$ is opened by the game master, then either door $a$ or door $b$ has a car with equal probability $\frac{1}{2}$. Since there is a 50-50 chance, switching does not increase your chances. This viewpoint is widely disputed.

Another viewpoint using classic conditional probability states the following. In the beginning there is a $\frac{1}{3}$-chance that door $a$ has a car. Assume after choosing door $a$ the game master reveals door $c$. There was a chance of $\frac{2}{3}$ that the car was behind door $b$ or $c$, leaving a $\frac{2}{3}$-chance that the car is behind door $b$. Therefore switching is advised, doubling your chances of winning the car. This viewpoint is however disputed as well.

Grünwald and Halpern \cite{Grunwald03} pointed out that the probability of the car being behind door $a$ is anything between $0$ and $\frac{1}{2}$. When the car is behind door~$a$, the game master is free to choose between doors $b$ and $c$. The game master's strategy influences the probability of the car being behind the other door.

Let us start with a formal statement of the problem. Let $\X=\{a,b,c\}$ be our outcome space and $\Y=\{b,c\}$ be our observation space. Let $\Omega=\X\times\Y$ be our sample space with $\Sigma=2^\Omega$ as $\sigma$-algebra. Let $U$ be an $\X$-valued random variable denoting the placement of the car and let $V$ be a $\Y$-valued random variable on $\Y$ denoting the opening of a door.\\
Note that the doors are called $a$, $b$ and $c$ and not $1$, $2$ and $3$, as in the latter case the expectation $\E[U]$ suddenly can be given a meaning. There is no such thing as the `average door', as the labels on the doors are nothing more than names, not aspects indicating any value. Therefore we choose to name the doors $a$, $b$ and $c$ to not give rise to any confusion.\\
We assume that the car is initially distributed with equal probability and the game master cannot open a door with a car. A probability distribution must therefore be a member of the set
\begin{equation}
\Pmod=\left\{\P\middle|\forall u\in\X:\P[U=u]=\frac{1}{3},\forall v\in\Y:\P[V=v|U=v]=0\right\}.
\end{equation}

In this section we first give a repetition of the arguments of \cite{Grunwald13} as they view the Monty Hall problem in the viewpoint of traditional probability. Then we apply safe probability and Theorem~\ref{thm:DiscMainThm} to the Monty Hall problem, with as result that it is safe to state that the car is behind door $a$ with probability~$\frac{1}{3}$.


\subsubsection{Traditional conditional probability}
Let us start with the viewpoint that result in a probability of $\frac{2}{3}$ of obtaining the car after switching. This viewpoint takes $\Omega'=\{a,b,c\}$ as sample space. Let $U'$ be an $\Omega'$-valued random variable denoting the cars location. Equip $\Omega'$ with the uniform distribution $\P$ such that $\P[U'=u]=\frac{1}{3}$. Assume lastly that $\P[U'\in\{a,b\}|U'=a]=\frac{1}{2}$, thus that the game master chooses a door with equal probability when he has free choice. Traditional conditional probability and Bayes' rule then give
\begin{align}
\P[U'=a|U'\in\{a,b\}]&=\frac{\P[U'\in\{a,b\}|U'=a]\P[U'=a]}{\sum_{u\in\Omega}\P[U'\in\{a,b\}|U'=u]\P[U'=u]}\\
&=\frac{\frac{1}{2}\cdot\frac{1}{3}}{\frac{1}{3}\left(\frac{1}{2}+0+1\right)}=\frac{1}{3}.
\end{align}
It is clear that the argument above needs to make assumptions on $\P$ in order to be able to perform the calculation, as following the problem's statement we cannot put a direct value on $\P[U'\in\{a,b\}|U'=a]$. We thus need to make a reasonable assumption for this argument to hold.\\
Let now $p\in[0,1]$ be such that $\P[U'\in\{a,b\}|U'=a]=p$, then we have
\begin{equation}\label{eq:DiscMonty}
\P[U'=a|U'\in\{a,b\}]=\frac{\P[U'\in\{a,b\}|U'=a]\P[U'=a]}{\sum_{u\in\Omega}\P[U'\in\{a,b\}|U'=u]\P[U'=u]}=\frac{p}{p+1}.
\end{equation}
Thus the probability of door $a$ having the car after opening door $b$ dilates from $0$ to $\frac{1}{2}$, as \cite{Grunwald13} also pointed out in their work.\\
To create a probability of $\frac{1}{2}$ of our initial door having the car, we need to pick $p=1$. We thus need to assume that when we initially chose the correct door, the game master \emph{always} opens door $b$. This also debunks the argument that there are two doors left, thus there is a probability of $\frac{1}{2}$ that door $a$ has the car. The information that door $b$ has no car heavily influences the conditional probability.


Even more is wrong with the above reasoning. Suppose door $a$ has the car. The game master is now able to choose between doors $b$ and $c$. If door $b$ is opened, the resulting set of possibilities is $\{a,b\}$ and when door $c$ is opened, the resulting set of possibilities is $\{a,c\}$. We need to condition on both the possibilities $\{a,b\}$ and $\{a,c\}$, however both sets do not form a partition. Furthermore, the smallest $\sigma$-algebra containing both sets is
\begin{equation}
\G=\sigma(\{a,b\},\{a,c\})=2^{\{a,b,c\}}=2^{\Omega'},
\end{equation}
our original $\sigma$-algebra. As stated by \cite{Williams91} and also easy to prove, we have $\P[F|\G]=\P[F]$ for all $F\in\G$ when $\G=2^{\Omega'}$ is our original $\sigma$-algebra. We are therefore simply not able to use measure-theoretic conditional probability, let alone traditional conditional probability.

Can we say nothing sensible at all about the probability of winning the car after switching? Consider the $\Omega$, $U$ and $V$ from the formal statement in the introduction of this section. Now we have $\Omega=\X\times\Y$, thus $\Omega$ is split up in outcome space $\X=\{a,b,c\}$ and observation space $\Y=\{b,c\}$. Now we can condition on all possibilities of open doors, as $\sigma(\{a\}\times\Y)$ is a strict sub-$\sigma$-algebra of $2^\Omega$.\\
The resulting conditional probabilities come in the form of Equation~\ref{eq:DiscMonty}. Let $\P\in\Pmod$, thus such that $\P$ is uniform distributed on $U$ and a door with a car cannot be opened. Then a $p\in[0,1]$ exists such that $\P[V=b|U=a]=p$. This results into
\begin{align}
\P[U=a|V=b]=\frac{\P[V=b|U=a]\P[U=a]}{\sum_{u\in\Omega}\P[V=b|U=u]\P[U=u]}=\frac{p}{p+1},\label{eq:DiscMontyDilate}\\
\P[U=a|V=c]=\frac{\P[V=c|U=a]\P[U=a]}{\sum_{u\in\Omega}\P[V=c|U=u]\P[U=u]}=\frac{1-p}{2-p}.
\end{align}
In both cases the probability of door $a$ having the car dilates from $0$ to $\frac{1}{2}$. Therefore, you are advised to switch no matter the strategy of the game master. However, we cannot pin down a single probability of door $a$ having the car given the game master's statement. We can put a prior on $\P[V=b|U=a]$, however we do need more information to apply such prior wisely.

This subsection shows another example of why when doing conditional probability one always needs to provide the accompanying sub-$\sigma$-algebra. Unlike the Borel-Kolmogorov paradox in Chapter~\ref{chap:BorelKolmogorov}, here the measure-theoretic conditional expectation defines a unique probability measure. However, most use $\Omega=\{a,b,c\}$ as sample space and without taking the accompanying $\sigma$-algebra in account when conditioning, one should find no reason not to do this. Only when correctly applying conditional probability and noticing that both $\{a,b\}$ and $\{a,c\}$ are possible options, one finds out that $\Omega=\{a,b,c\}$ is insufficient as sample space and paradoxical results will rise.

\subsubsection{Safe probability}
Using safe probability it is possible to find a pragmatic distribution $\Psafe$ on $\Omega$ that is safe against all $\P\in\Pmod$. We only need to apply Theorem~\ref{thm:DiscMainThm}.

\begin{proposition}\label{prop:DiscMontySafe}
Let $\X$, $\Y$, $\Omega$, $U$, $V$ and $\Pmod$ be as in the Monty Hall problem. Let $\Psafe$ be a distribution on $\Omega$ with full support on $V$. Let $u\in\X$, then the following statements are equivalent:
\begin{enumerate}
\item For all $v\in\Y$ we have $\Psafe[U=u|V=v]=\frac{1}{3}$.
\item $\Psafe$ is safe for $\langle \1_{\{U=u\}}\rangle|\langle V\rangle$.
\item $\Psafe$ is safe for $\1_{\{U=u\}}|[V]$.
\end{enumerate}
\end{proposition}
\begin{proof}
This proposition is a direct application of Theorem~\ref{thm:DiscMainThm} and its proof is equal to the proof of Proposition~\ref{prop:DiscDiceSafe}. The set $\X$ is of size $3$ and therefore countable and the set $\Y$ is of size $2$, which makes it finite. $U$ is a random variable on $\X$ and $V$ is a random variable on $\Y$. In this Monty Hall problem we have $p_u=\frac{1}{3}$ as $\P\in\Pmod$ implies $\P[U=u]=\frac{1}{3}$ for all $u\in\X$. Lastly, the set $\Pmod$ is a subset of $\{\P|\forall u\in\X:\P[U=u]=p_u\}$.

Take $\P_b,\P_c\in\Pmod$ with $\P_i[V=i|U=a]=1$. Let $i\in\{b,c\}$ be arbitrary, then
\begin{align}
\P_i[V=i]&=\sum_{u=1}^3\P_i[V=i|U=u]\P_i[U=u]\\
&=\frac{1}{3}\left(2\cdot1+0\right)=\frac{2}{3}.
\end{align}
Thus the vectors $\left(\P_i[V=v]\right)_{v\in\Y}$ become $\left(\frac{1}{3},\frac{2}{3}\right)$ and $\left(\frac{2}{3},\frac{1}{3}\right)$, which are linearly independent.

Now we can directly apply Theorem~\ref{thm:DiscMainThm} to conclude the proof.
\end{proof}

Thus the distribution stating that door $a$ has probability $\frac{1}{3}$ of having the car is safe for $\MontyInd|[V]$, in other words marginally valid. In this case safety for $\MontyInd|[V]$ implies a few other results with \emph{pivotal safety}. Before we can introduce pivotal safety, we first need to introduce the \emph{pivot}. This definition is taken from \cite{Grunwald18}.

\begin{definition}[Discrete pivot]\label{def:DiscPivot}
Let $U$ and $V$ be random variables on $\Omega$. Assume $\Omega$ is countable. A random variable $U'$ is a \emph{discrete pivot} for $U|V$ if
\begin{enumerate}
    \item $(U,V)\rightsquigarrow U'$ holds, thus there is a function $f$ with $U'=f(U,V)$.
    \item For each fixed $v\in\range(V)$ the function
    \begin{equation}
    f_v\colon\range(U|V=v)\to\range(U'),\qquad u\mapsto f(u,v)
    \end{equation}
    is injective.
    \item All $\P\in\Pmod$ agree on $U'$, thus for all $\P_1,\P_2\in\Pmod$ we have $\P_1(U')=\P_2(U')$.
\end{enumerate}
Pivot $U'$ is \emph{simple} if $f_v$ is a bijection for all $v\in\range(V)$.
\end{definition}

Since we will not consider continuous pivots in this thesis, we just state that $U'$ is a \emph{pivot} for $U|V$. Now we can define pivotal safety, where the definition is taken from \cite{Grunwald18}.

\begin{definition}[Pivotal safety]\label{def:DiscPivotSafe}
Let $U$ and $V$ be as in Definition~\ref{def:DiscPivot} and let $\Psafe$ be an arbitrary distribution on $\Omega$. If $V$ has full support under $\Psafe$, thus $\supp_{\Psafe}(V)=\range(V)$, and $U'$ is a discrete pivot such that $\Psafe$ is safe for $U'|[V]$, then $\Psafe$ is \emph{pivotally safe for $U|V$ with pivot $U'$}.
\end{definition}

Now we can prove that $\MontyInd$ is a pivot for $U|V$ and then $\Psafe$ from Proposition~\ref{prop:DiscMontySafe} being safe for $U|V$ with pivot $\MontyInd$ immediately follows.

\begin{proposition}\label{prop:DiscMontyPivSafe}
Let $\X$, $\Y$, $\Omega$, $U$, $V$, $\Pmod$ and $\Psafe$ be as in Proposition~\ref{prop:DiscMontySafe}. The random variable $\MontyInd$ is a pivot for $U|V$ and $\Psafe$ is pivotally safe for $U|V$ with pivot $\MontyInd$.
\end{proposition}
\begin{proof}
The proof is a mere check of Definitions~\ref{def:DiscPivot} and \ref{def:DiscPivotSafe}. We will start with $\MontyInd$ being a pivot for $U|V$ by checking the three requirements of Definition~\ref{def:DiscPivot}.
\begin{enumerate}
    \item Take as function $f(U,V)=\MontyInd$. This is a well-defined function, therefore $(U,V)\rightsquigarrow U'$.
    \item Note that $\range(V)=\{b,c\}$. Take $v=b$, then $\range(U|V=b)=\{a,c\}$. We have $f_b(a)=f(a,b)=1$ and $f_b(c)=f(c,b)=0$, thus $f_b$ is a bijection. Taking $v=c$ we get $f_c(a)=1$ and $f_c(b)=0$, thus $f_c$ is a bijection as well.
    \item Take $\P_1,\P_2\in\Pmod$ arbitrarily. Note that $\range(\MontyInd)=\{0,1\}$. Therefore
    \begin{align}
        \P_1[U\neq a]&=\P_1[U\in\{2,3\}]=\frac{2}{3}=\P_2[U\in\{2,3\}]=\P_2[U\neq a],\\
        \P_1[U=a]&=\P_1[U=1]=\frac{1}{3}=\P_2[U=1]=\P_2[U=a],
    \end{align}
    thus we have $\P_1[\MontyInd]=\P_2[\MontyInd]$.
\end{enumerate}
Since we have proven that $f_v$ is a bijection for all $v\in \range(V)$, the pivot $\MontyInd$ is a simple pivot for $U|V$.

Theorem~\ref{thm:DiscMainThm} states that $\Psafe$ with $\Psafe[U=a|V=v]=\frac{1}{3}$ for all $v\in\Y$ is safe for $\MontyInd|[V]$. This $\Psafe$ has full support under $V$, as for all $v\in\Y$ the statement $\Psafe[U=a|V=v]>0$ implies $\Psafe[V=v]>0$ by definition of traditional conditional probability. Therefore by Definition~\ref{def:DiscPivotSafe} probability measure $\Psafe$ is pivotally safe for $U|V$ with pivot $\MontyInd$.
\end{proof}

Pivotal safety comes with a nice result. Following \cite{Grunwald18}, introduce the random variable $\tilde{p}(U|V)$ by
\begin{equation}
\tilde{p}(U|V)(\omega)=\Psafe[U=U(\omega)|V=V(\omega)]
\end{equation}
for all $\omega\in\Omega$. This random variable maps $\omega\in\Omega$ to the probability of a single outcome $\Psafe[U=U(\omega)|V=V(\omega)]$. Now \cite{Grunwald18} stated the following theorem on pivotal safety.
\begin{theorem}\label{thm:PivotSafe}
Let $\Omega$ be countable and $U,V$ be random variables on $\Omega$. Let $\Psafe$ be an arbitrary distribution on $\Omega$. Suppose that for all $v\in\range(V)$ there are no two $u_1,u_2\in\range(U|V=v)$ with $\Psafe[U=u_1|V=v]=\Psafe[U=u_2|V=v]$. The following statements are equivalent:
\begin{enumerate}
    \item $\Psafe$ is safe for $\tilde{p}(U|V)|[V]$.
    \item $\Psafe$ is pivotally safe for $U|V$ with simple pivot $U'=\tilde{p}(U|V)|[V]$.
    \item $\Psafe$ is pivotally safe for $U|V$ for some simple pivot $U''$.
\end{enumerate}
\end{theorem}
\begin{proof}
The proof can be found in \cite{Grunwald16}.
\end{proof}

Let in our case $\Psafe$ be as in Proposition~\ref{prop:DiscMontyPivSafe}. We only defined $\Psafe[U=a|V=v]$ for all $v\in\Y$, not $\Psafe[U=u|V=v]$ with $(u,v)\in\{b,c\}\times\Y$. Thus to actually write down the outcomes of $\tilde{p}(U|V)$ with their respective probabilities, we need to put $p_u^v\in\left[0,\frac{2}{3}\right]\setminus\left\{\frac{1}{3}\right\}$ with $p_b^v+p_c^v=\frac{2}{3}$ for all $(u,v)\in\{b,c\}\times\Y$ and apply
\begin{equation}
\Psafe[U=u|V=v]=p_u^v.
\end{equation}
Now $\Psafe[U=a|V=v]$ is fixed to be $\frac{1}{3}$. No $u\in\{b,c\}$ has $\Psafe[U=u|V=v]=\frac{1}{3}$ as well, since we excluded $\frac{1}{3}$ from the set $p_u^v$ could be picked from. Since $\Psafe$ is pivotally safe for $U|V$ with pivot $\MontyInd$, Theorem~\ref{thm:PivotSafe} states that $\Psafe$ is pivotally safe for $U|V$ with simple pivot $\tilde{p}(U|V)$ as well.

Summarizing, since $\Psafe$ is pivotally safe for $\MontyInd$ with simple pivot $\MontyInd$ and since we can create $\tilde{p}(U|V)$ to be a simple pivot for $U|V$ as well, we immediately obtain pivotal safety for $U|V$ with simple pivot $\tilde{p}(U|V)$. We also obtain an infinite family of simple pivots $\tilde{p}(U|V)$ for which $\Psafe$ is safe, as for example $\Psafe[U=b|V=c]$ is not uniquely defined. We have seen that it is safe to assume that the car is behind door $a$ with a probability of $\frac{1}{3}$ and by some special properties of the Monty Hall game, specifically that $\MontyInd$ is a simple pivot for $U|V$, we see that $\Psafe$ is safe for $U'|[V]$ with $U'=\tilde{p}(U|V)$ being another simple pivot constructed by $\Psafe$.


\subsubsection{Accuracy}
Suppose you are playing the Monty Hall game, which strategy optimizes the probability of winning the car? The answer is that you must always switch for a probability of $\frac{2}{3}$ to win the car, which follows from applying Theorem~\ref{thm:DiscAccOpt}.

\begin{proposition}
Let $\X$, $\Y$, $U$, $V$ and $\Pmod$ be as in the dice game. Consider the random variable $\MontyInd^*\sim0$, then this $\MontyInd^*$ has accuracy
\begin{equation}
\acc^{\P}\left(\MontyInd^*\right)=\frac{2}{3}
\end{equation}
for all $\P\in\Pmod$. There is no random variable $W$ with $\acc^{\P}(W)>\acc^{\P}(\MontyInd^*)$ for a $\P\in\Pmod$.
\end{proposition}
\begin{proof}
We want to apply Theorem~\ref{thm:DiscAccOpt}. Firstly in this case $\X'=\{a\}\subset\X$ is non-empty. Secondly, we have $\sum_{u\in\X'}p_u=p_a=\frac{1}{3}<\frac{1}{2}$. Theorem~\ref{thm:DiscAccOpt} states that when $\MontyInd^*$ is distributed as $\MontyInd^*\sim0$, the accuracy for guessing $\MontyInd$ is optimized with value
\begin{equation}
\acc\left(\MontyInd^*\right)=\max\left\{\frac{1}{3},\frac{2}{3}\right\}=\frac{2}{3}.
\end{equation}
\end{proof}

As in the dice game, the information of the game master does not lead to a higher probability of winning the car. When always switching doors, the probability of winning the car becomes $\frac{2}{3}$ and this is the optimal probability you can have.

\subsubsection{Final remarks}
The Monty Hall problem applied Theorems~\ref{thm:DiscMainThm} and \ref{thm:DiscAccOpt} in the same manner as the dice game. In the setting of the Monty Hall problem, it is safe to say that the car has probability $\frac{1}{3}$ to be behind the originally chosen door. Always switching therefore yields to an optimal probability of $\frac{2}{3}$ for winning the car.

Since in the case of the Monty Hall problem the random variable $\MontyInd$ is a simple pivot for $U|V$, we can pick $\Psafe$ to construct a family of other simple pivots $U'$ that are safe for $U'|[V]$. This is not possible in the dice game, as there $f_v$ as in Definition~\ref{def:DiscPivot} with $v\in\{\{1,2,3,4\},\{3,4,5,6\}\}$ is not injective.

When pivots are not considered, the Monty Hall problem is essentially equal to the dice game. Here the paradoxical nature of the Monty Hall problem stems from the fact that most use $\Omega=\{a,b,c\}$ when first trying to solve the problem. However, in that case we cannot create a partition to apply traditional conditional probability or a $\sigma$-algebra for measure-theoretic conditional probability. This problem can only be spotted when performing conditional probability correctly, thus with stating the accompanying sub-$\sigma$-algebra. Then it becomes clear that $\Omega$ must be extended with an observation space $\Y=\{b,c\}$. This makes the Monty Hall problem yet another argument as in why the $\sigma$-algebra must be given when performing conditional probability.

\section{Boy or girl problem}\label{sec:DiscChildren}
The last problem we will study in this chapter is the boy or girl problem\footnote{Bronnen invoeren}. Suppose you are approached by a stranger and you two get in conversation. The stranger tells you that he has two children and at least one of them is a girl. You want to know what the probability is that he has two daughters.

The paradox arises when one misinterprets the setting. Suppose you ask the stranger if he has at least one girl. If he says `yes', the probability of him having two girls is $\frac{1}{3}$, as he can also have a boy and a girl and you do not know whether the earlier mentioned girl is his oldest child. This calculation is not controversial, as his answer `yes' implies the set of possibilities $\{bg, gb, gg\}$ and is answer `no' implies the set of possibilities $\{bb\}$. These sets do not overlap, thus traditional probability theory can be applied without any problems.\\
Suppose now the stranger tells you out of the blue that he has two children and at least one of them is a girl. Now the setting changes, as he could also have told you that at least one of his children is a boy. If he said that he has a girl, the set of possibilities is $\{bg, gb, gg\}$ and if he said that he has a boy, the set of possibilities is $\{bg, gb, bb\}$. Now there is an overlap of $\{bg, gb\}$ and traditional probability theory cannot be applied any-more. The probability of the stranger having two girls given he has at least one is now dilated between~$\frac{1}{3}$ and $1$, depending on the willingness of the stranger to reveal he has a girl. This dilation can be calculated in the same manner as is done for the Monty Hall problem in Equation~\ref{eq:DiscMontyDilate}.

We will now construct our model. Let $\X=\{bb,bg,gg\}$ be our outcome space and let $\Y=\{b,g\}$ be our observation space. Then $\Omega=\X\times\Y$ becomes our sample space with $2^\Omega$ as its accompanying $\sigma$-algebra. We do not care about whether the girl is older than the boy in the event that the stranger has a boy and a girl, thus we remove the outcome $gb$. Let $U$ be a random variable on $\X$ denoting the children of the stranger and $V$ be a random variable on $\Y$ denoting whether the stranger told you he as at least one boy, event $\{V=b\}$, or at least one girl, event $\{V=g\}$. All probabilities $\P$ on $\Omega$ must be a member of
\begin{equation}
\Pmod=\left\{\P\middle|\begin{array}{l}
\P[U=bb]=\frac{1}{4},\P[U=bg]=\frac{1}{2},\\
\P[V=g|U=bb]=\P[V=b|U=gg]=0
\end{array}
\right\}.
\end{equation}

\subsubsection{Traditional conditional probability}
The analysis of the problem using traditional conditional probability will be very short here, as it is essentially the same analysis as in sections~\ref{sec:DiscDice} and \ref{sec:DiscMonty}. Let $\P\in\Pmod$ be arbitrary, then there is a $p\in[0,1]$ with $\P[V=g|U=bg]=p$. Using Bayes' rule we get
\begin{align}
\P[U=bg|V=g]&=\frac{\P[V=g|U=bg]\P[U=bg]}{\sum_{u\in\X}\P[V=g|U=u]\P[U=u]}\\
&=\frac{p\cdot\frac{1}{2}}{0\cdot\frac{1}{4}+p\cdot\frac{1}{2}+1\cdot\frac{1}{4}}=\frac{2p}{2p+1},
\end{align}
thus the probability of him having two girls given the stranger told you he has at least one daughter dilates from $\frac{1}{3}$ to $1$. Therefore traditional conditional probability does not give a single answer.

\subsubsection{Safe probability}


Since $U$ is not real-valued, we cannot calculate $\E_{\P}[U]$ for any $\P\in\Pmod$. Thus there is no notion of safety for $U|V$. We can speak of safety for $\ChildInd|V$, as the event $\{U=bg\}$ arises both in conditioning on $\{V=b\}$ and on $\{V=g\}$.
\begin{proposition}\label{prop:DiscChildSafe}
Let $\X$, $\Y$, $\Omega$, $U$, $V$ and $\Pmod$ be as in the boy or girl problem. Let $\Psafe$ be a distribution on $\Omega$ with full support on $V$. Let $u\in\X$, then the following are equivalent:
\begin{enumerate}
    \item For all $v\in\Y$ we have $\Psafe[U=bg|V=v]=\frac{1}{2}$ in the case of $u=bg$ and $\Psafe[U=u|V=v]=\frac{1}{4}$ when $u\in\{bb,gg\}$.
    \item $\Psafe$ is safe for $\langle\1_{\{U=u\}}\rangle|\langle V\rangle$.
    \item $\Psafe$ is safe for $\1_{\{U=u\}}|[V]$.
\end{enumerate}
\end{proposition}
\begin{proof}
The proof is a direct application of Theorem~\ref{thm:DiscMainThm} and an almost direct copy of the proof of Proposition~\ref{prop:DiscMontySafe}. We will nevertheless state the full proof here.

The set $\X$ is of size $3$ and therefore countable and the set $\Y$ is of size $2$, which makes it finite. $U$ is a random variable on $\X$ and $V$ is a random variable on $\Y$. In this boy or girl problem we have $p_{bg}=\frac{1}{2}$ and $p_{bb}=p_{gg}=\frac{1}{4}$ by $\P\in\Pmod$. Lastly, the set $\Pmod$ is a subset of $\{\P|\forall u\in\X:\P[U=u]=p_u\}$.

Take $\P_{b},\P_{g}\in\Pmod$ with $\P_i[V=i|U=bg]=\frac{3}{4}$. Let $i\in\{b,g\}$ be arbitrary, then
\begin{align}
\P_i[V=i]&=\sum_{u\in\X}\P_i[V=i|U=u]\P_i[U=u]\\
&=\frac{1}{2}\cdot\frac{3}{4}+\frac{1}{4}\cdot\frac{1}{4}+0\cdot\frac{1}{4}=\frac{7}{16}.
\end{align}
Thus the vectors $\left(\P_i[V=v]\right)_{v\in\Y}$ become $\left(\frac{7}{16},\frac{9}{16}\right)$ and $\left(\frac{9}{16},\frac{7}{16}\right)$, which are linearly independent.

Now we can directly apply Theorem~\ref{thm:DiscMainThm} to conclude the proof.
\end{proof}

Therefore the distribution, for which the probability is $\frac{1}{2}$ that the stranger has two girls after stating he has at least one girl, is safe for $\ChildInd|[V]$. Moreover, $\Psafe$ from Proposition~\ref{prop:DiscChildSafe} is pivotally safe for $U|V$ with pivot $\ChildInd$.
\begin{proposition}
Let $\X$, $\Y$, $\Omega$, $U$, $V$, $\Pmod$ and $\Psafe$ be as in Proposition~\ref{prop:DiscChildSafe}. The random variable $\ChildInd$ is a pivot for $U|V$ and $\Psafe$ is pivotally safe for $U|V$ with pivot $\ChildInd$.
\end{proposition}
\begin{proof}
The proof is equal to the proof of Proposition~\ref{prop:DiscMontyPivSafe}.
\end{proof}

We will not dive deeper in pivots here, as it will become be a repetition of Section~\ref{sec:DiscMonty}. The problem is equal to the Monty Hall problem apart from the distribution of $U$ in $\Pmod$, thus for a more thorough analysis the reader is referred to Section~\ref{sec:DiscMonty}.

\subsubsection{Accuracy}
In this problem the optimal accuracy for guessing $\ChildInd$ correctly becomes interesting. When playing this game multiple times, it does not matter the frequency of guessing that he has a boy against having a girl. According to Proposition~\ref{prop:DiscChildSafe} distribution $\Psafe$ with $\Psafe[U=bg|V=v]=\frac{1}{2}$ for all $v\in\Y$ is safe for $\ChildInd|[V]$, thus Theorem~\ref{thm:DiscAccOpt} gives us that random variable $\ChildInd^*$ distributed like $\ChildInd^*\sim\mathrm{Ber}(p)$ optimizes the accuracy of guessing $\ChildInd$ correctly.
\begin{proposition}
Let $\X$, $\Y$, $U$, $V$ and $\Pmod$ be as in the boy or girl problem. Consider the random variable $\ChildInd^*\sim\mathrm{Ber}(p)$ distributed as the Bernoulli distribution with parameter $p\in[0,1]$, then this $\ChildInd^*$ has accuracy
\begin{equation}
\acc^{\P}\left(\ChildInd^*\right)=\frac{1}{2}
\end{equation}
for all $\P\in\Pmod$. There is no random variable $W$ with $\acc^{\P}(W)>\acc^{\P}(\ChildInd^*)$ for a $\P\in\Pmod$.
\end{proposition}
\begin{proof}
We want to apply Theorem~\ref{thm:DiscAccOpt}. Firstly in this case $\X'=\{bg\}\subset\X$ is non-empty. Secondly, we have $\sum_{u\in\X'}p_u=p_{bg}=\frac{1}{2}$. Then Theorem~\ref{thm:DiscAccOpt} states that $\ChildInd^*\sim\mathrm{Ber}(p)$ with $p\in[0,1]$ arbitrary optimizes the accuracy for guessing $\ChildInd$ with
\begin{equation}
\acc\left(\ChildInd^*\right)=\max\left\{\frac{1}{2},\frac{1}{2}\right\}=\frac{1}{2}.
\end{equation}
\end{proof}

We can therefore just guess randomly whether the stranger has a boy and girl or not. On average we will be correct 50\% of the times we find ourselves in this situation, which is the best we can do.

\subsection{Boy or girl problem 2.0}
There is a second variant of the boy or girl problem stated in a lecture by Peter Grünwald \cite{Grunwald19}. He stated a revised boy or girl problem as such:
\begin{enumerate}
    \item A person is picked uniformly at random from a population and a conversation is started.
    \item You ask if at least one of his children is a boy. Suppose his answer is `yes', then the probability of two boys is $\frac{1}{3}$. As stated in section~\ref{sec:DiscChildren}, this is not controversial.
    \item You ask if he can give you the name of his son. He can choose which son if he has two. The answer is `Martin'.
    \item You ask if Martin is his youngest child.
    \begin{itemize}
        \item[Yes:] If he answered `yes', then his youngest child is a boy and the probability of two boys is now $\frac{1}{2}$.
        \item[No:] If he answered `no', then his oldest child is a boy and the probability of two boys is now $\frac{1}{2}$.
    \end{itemize}
\end{enumerate}

The paradoxical nature of this problem is that after learning the name of a son of the stranger, the probability of him having two boys shifts from $\frac{1}{3}$ to $\frac{1}{2}$. However, as the stranger can state any string as name, just learning the name after knowing he has at least a boy must not influence the probability of the stranger having two boys.

This problem is stated more elaborately, but the underlying foundation is equal to the Monty Hall or the original boy or girl problem. The outcome space after the stranger answering `yes' is $\{gb,bb\}$ and the outcome space after the stranger answering `no' is $\{bg, bb\}$. Now there is an overlap of $bb$. Furthermore, asking a boy's name and then asking if he is the youngest is essentially the same as asking whether his youngest child is a boy.

Therefore we can adapt our model to this situation. Let $\X=\{bg,gb,bb\}$ be the outcome space, let $\Y=\{y,o\}$ be the observation space and take $\Omega=\X\times\Y$ as sample space. Now we have both $bg$ and $gb$ in $\X$ as we now do care about whether the boy is the oldest of the children. The outcome $gg$ is not included in $\X$ as we assume he answered `yes' on the question whether he has at least one boy. Let $U$ be a random variable on $\X$ denoting the family composition of the stranger, where $\{U=bg\}$ is the event that his oldest child is a boy. Let $V$ be a random variable on $\Y$ denoting which of the children is a boy for sure, where $\{V=y\}$ is the event that the youngest child is a boy and $\{V=o\}$ is the event that the oldest child is a boy. Assume lastly that the stranger does not lie. All probability distributions $\P$ on $\X\times\Y$ must lie in
\begin{equation}
\Pmod=\left\{\P\middle|\forall u\in\X:\P[U=u]=\frac{1}{3},\P[V=bg|Y=y]=\P[V=gb|Y=o]=0\right\}.
\end{equation}
For safe probability we can now look at safety for $\ChildTwoInd$ as $bb$ is an element of the intersection of the outcome spaces conditioned on $\{V=y\}$ or $\{V=o\}$.
\begin{proposition}
Let $\X$, $\Y$, $\Omega$, $U$, $V$ and $\Pmod$ be as in the boy or girl problem 2.0. Let $\Psafe$ be a distribution on $\Omega$. Let $u\in\X$, then the following are equivalent:
\begin{enumerate}
    \item For all $v\in\Y$ we have $\Psafe[U=u|V=v]=\frac{1}{3}$.
    \item $\Psafe$ is safe for $\langle\1_{\{U=u\}}\rangle|\langle V\rangle$.
    \item $\Psafe$ is safe for $\1_{\{U=u\}}|[V]$.
\end{enumerate}
\end{proposition}
\begin{proof}
This proof is equal to the proof of Proposition~\ref{prop:DiscMontySafe}, the model in the boy or girl problem 2.0 is equal to the model in the Monty Hall problem.
\end{proof}

For this problem we can talk about pivotal safety and accuracy, but as the proof above already stated, this revised boy or girl problem is in essence equal to the Monty Hall problem and the original boy or girl problem. Therefore if the reader wants to dive further in this subject, he is kindly referred to Section~\ref{sec:DiscMonty}.

\subsection{Final remarks on both problems}
Both versions of the boy or girl problem are in essence equal to the dice game and the Monty Hall problem. When in both versions of the boy or girl problem $\Omega=\{bb,bg,gb,gg\}$ is chosen as sample space, then in the first version the conditioned sample spaces become $\{bg, gb, bb\}$ and $\{bg, gb, gg\}$ and in the second version the conditioned sample spaces become $\{bg, bb\}$ and $\{gb, bb\}$. In both versions the conditioned sample spaces cannot form a partition as there is an overlap in the sets, thus traditional conditional probability cannot be applied. The sample space must be extended, which can only be noticed when performing conditional probability correctly, thus with taking the accompanying $\sigma$-algebras into account.

In both versions there is no probability of the stranger either having two girls or having two boys. In the first version the probability of having two girls dilates from $\frac{1}{3}$ to $1$, in the second version the probability of him having two boys dilates from $0$ to $\frac{1}{2}$. The latter can be proven by following the reasoning in Equation~\ref{eq:DiscMontyDilate}.

When Theorem~\ref{thm:DiscMainThm} is applied, we find that the first version has a safe distribution stating the probability of having a boy and a girl is $\frac{1}{2}$. In the second version, we found out that the safe distribution puts a probability of $\frac{1}{3}$ on him having two boys.

Most importantly, the second version of the paradox is practically equal to the Monty Hall problem. The first version can also be solved using the same techniques as the only difference being the model of probability distributions.

\section{Conclusion}\label{sec:DiscConcl}
After going through the dice game, the Monty Hall problem and the boy or girl problem, we see that Theorem~\ref{thm:DiscMainThm} can be applied nicely. When a problem is founded upon a sample space $\Omega=\X\times\Y$ where $\X$ is the countable space of all possible outcomes, $\Y$ is the finite space of all statements the game master can make to the player and the distribution on $\X$ is fixed, we can apply Theorem~\ref{thm:DiscMainThm} to find safe distributions for single probabilities. The model of probability distributions must be large enough and fulfil an important requirement, however this requirement is almost always fulfilled when $\Pmod$ has $|\Y|$ distinct distributions. When $\Pmod$ has fewer than $|\Y|$ distributions, then you should at first ask yourself whether $\Pmod$ is not too restrictive, making the safe distribution prone for overfit. Taking $\Pmod=\{\P\}$ as a single distribution makes this $\P\in\Pmod$ even safe for $U|V$, however this result is not quite helpful.

Furthermore, seemly distinct problems like the boy or girl problem and the Monty Hall problem are in essence equal. Therefore the studies on both of these problems can be combined, but with care as both problems do have different probability models.

The last and most important observation of this chapter is that the paradoxical results people find in the Monty Hall problem or the boy or girl problem all arise when $\Omega=\X$, thus when the outcome space is taken as sample space. In this case traditional conditional probability cannot be applied as the resulting outcome spaces after conditioning on the observed events do not form a partition.\\
This can be seen when the $\sigma$-algebra $2^{\Omega}$ is taken into account. Using loose notation, take $y_1,y_2\in\Y$ and suppose $x\in\X$ is present in both conditioned spaces $\X|y_1$ and $\X|y_2$. Then for computing the conditional probability of $x$ you need to condition on $\{\{y_1\},\{y_2\}\}$, which is either not a element of $2^\Omega$ or the probability on $\{\{y_1\},\{y_2\}\}$ is not known. Thus a sub-$\sigma$-algebra needed for conditioning cannot be found.\\
This mistake is easily spotted when taking the $\sigma$-algebra into account when performing conditional probability. Therefore these problems are more examples of why when applying conditional probability the accompanying $\sigma$-algebras must always be provided.

\chapter{The two envelopes problem}\label{chap:TwoEnvelope}
The last paradox we will consider is the two envelope problem. This problem is first stated in 1953 by Kraitchik \cite{Kraitchik53} as the necktie problem. In this problem each person claims to have the finer necktie. A judge must make a decision, where the winner has to give his necktie to the loser. The argument of each contestant is: `I know what my tie is worth. I may lose it, but I may also win a better one, so the game is to my advantage.' However, a game that is favourable for both players cannot exist. Furthermore, the game is symmetrical in terms of the contestants, thus \cite{Kraitchik53} states that the chance of winning is actually fifty-fifty.

However, \cite{Kraitchik53} only provides a discussion and no rigorous proofs. In 1989 Nalebuff \cite{Nalebuff89} states the two envelope problem with many variants and provides a wide discussion from various sources. We will study one of the variants, in my opinion the one with the most interesting results, of the paradox and show how all paradoxical statements are incorrect. The reasoning will stay valid for various extensions to the problem. Those extensions will be treated briefly in Section~\ref{sec:EnvelopeAli}.

Pick the following version of the two envelope problem from \cite{Nalebuff89}. There are two envelopes called $A$ and $B$. Envelope~$A$ contains a fixed amount of money and envelope~$B$ contains either value $\frac{1}{2}A$ or value $2A$. The player can choose between envelope~$A$ and $B$ and let us say without loss of generality that he chooses envelope~$A$. After choosing, the player is given the choice whether he wants to switch. Reasoning that envelope~$B$ contains $\frac{1}{2}A$ with probability $\frac{1}{2}$ and contains $2A$ with probability $\frac{1}{2}$, he computes the expected value of envelope~$B$ to be
\begin{equation}\label{eq:EnvelopeIntroWrong}
\E[B]=\frac{1}{2}\cdot\frac{1}{2}A+\frac{1}{2}\cdot2A=\frac{5}{4}A.
\end{equation}
Thus the player always wants to switch when initially picking envelope~$A$. However, by symmetry, if the player chose envelope~$B$, then to his knowledge $A$ contains either $\frac{1}{2}B$ or $2B$, thus he wants to switch as well. It is however not possible to have a greater expected value in the other envelope in all cases, as the total amount of money in the whole game is fixed. Therefore this result is called the \emph{two envelope paradox}. Some even reason that if the player possesses no memory, he wants to switch infinitely many times, believing to gain infinite money.

First we will provide a naive solution that corrects the calculation in Equation~\ref{eq:EnvelopeIntroWrong}. That solution will however be incomplete, as the formalized problem in Section~\ref{sec:EnvelopeFormal} will point out. In Section~\ref{sec:EnvelopePrior} we will investigate the prior on the lowest value of both envelopes, as that value will remain constant during the game. Safe probability will be applied in Section~\ref{sec:EnvelopeSafe}, which gives a safe probability distribution on whether to switch or not. This will however not lead to satisfactory results. Section~\ref{sec:EnvelopeSwitching} introduces Cover switching, which provides a switching strategy that does on average improve the amount of money won. Lastly, an alternative version called the Ali~Baba problem will be introduced in Section~\ref{sec:EnvelopeAli} and shortly discussed with many other variants of the two envelope problem. Eventually we will wrap up in Section~\ref{sec:EnvelopeConcl} giving concluding remarks.

\section{The naive solution}\label{sec:EnvelopeNaive}
First we need to find the flaw in the reasoning of the two envelope paradox. The biggest flaw is in Equation~\ref{eq:EnvelopeIntroWrong}. This calculation is performed using incorrect probability measures. An in-depth discussion is in 2014 given by O'Brien and Mitchell \cite{Brien14}. Here we only discuss the main solution of the problem.

Let $A$ and $B$ the random variables denoting the values of respectively envelopes $A$ and $B$. Let $x=\min\{A,B\}$ be the lowest value of the envelopes. The envelopes can only obtain two values: $x$ and $2x$. The probability of $A$ having $x$ is $\P[A=x]=\frac{1}{2}$, thus the probability space is
\begin{equation}
\left(\Omega=\{(x,2x),(2x,x)\},\Omega=2^\X,\P\right)
\end{equation}
with $\P$ a probability measure such that $\P[\{(x,2x)\}]=\P[\{(2x,x)\}]=\frac{1}{2}$. The calculation of $\E[B]$ in the statement of the two envelope problem is the following:
\begin{equation}
\E[B]=\frac{A}{2}\P\left[B=\frac{A}{2}\right]+2A\P[B=2A].
\end{equation}

The flaw here as discussed by \cite{WikiEnvelope} is that symbol $A$ is used with two different meanings. In $\P\left[B=\frac{A}{2}\right]$ the $A$ is actually the expected value of envelope~$A$ given that envelope~$A$ contains less than envelope~$B$. In $\P[B=2A]$ the opposite happens, where actually the expected value of $A$ given that envelope~$A$ contains more than envelope~$B$ is calculated. Equation~\ref{eq:EnvelopeIntroWrong} must therefore be rewritten to
\begin{align}
\E[B]&=\E[B|A<B]\P[A<B]+\E[B|A>B]\P[A>B]\\
&=\frac{1}{2}\left(\E[2A|A<B]+\E\left[\frac{1}{2}A\middle|A>B\right]\right)\\
&=\E[A|A<B]+\frac{1}{4}\E[A|A>B].
\end{align}
Now we clearly see that the expectation of $A$ in both cases are different and we are therefore unable to relate $\E[B]$ to $\E[A]$. The following calculation inspired by \cite{Schwitzgebel08} and \cite{Brien14} is correct:
\begin{align}
\E[B]&=\E[\E[B|A]]=\E[B|A=x]\P[A=x]+\E[B|A=2x]\P[A=2x]\\
&=\frac{1}{2}\left(2x\P[B=2x|A=x]\right)+\frac{1}{2}\left(x\P[B=x|A=2x]\right)\\
&=\frac{1}{2}\cdot2x+\frac{1}{2}x=\frac{3}{2}x,
\end{align}
We can calculate using the same method that $\E[A]=\frac{3}{2}x$, thus the expected amount of money in either envelope is equal. Switching therefore does not increase one's chances of getting more money.

So why is this section called `The naive solution'? The problem is that we do not know the value of $x$. When a player observes the contents of his envelope, he does not know whether he has value $x$ or $2x$. He cannot put equal probability on having $x$ or $2x$, as that will result in a uniform distribution on an infinite set as will be pointed out in Section~\ref{sec:EnvelopePrior}. We therefore need to find a method that takes the possible values of $x$ into account.

\section{The problem formalized}\label{sec:EnvelopeFormal}
The discussion in the previous section does not completely resolve the two envelope paradox. Two immediate flaws can be found in the discussion of Section~\ref{sec:EnvelopeNaive}:
\begin{enumerate}
\item How is the value $x$ picked? If the value $x$ is drawn from a probability distribution $\P$ on an unbounded set $U$, then it is not possible for all $x\in U$ that $\P[B=2x|A=x]=\P\left[B=\frac{1}{2}x\middle|A=x\right]=\frac{1}{2}$ holds as that would imply $\P$ being the uniform distribution on $U$ \cite{Christensen92,Christensen93b,Navara17,Tzur18}. It is clear that uniform distributions on unbounded sets do not exist.
\item If $x$ is drawn from a probability distribution with $\E[B]=\E[A]=\infty$, then $\E[B]=\E[\E[B|A]]$ is in some cases not valid any-more \cite{Tzur18}.
\end{enumerate}
Thus we need to not only model which envelope has the higher value, we must also model the lower value of the envelopes. In this section we will formally create the probability space describing the two envelope problem fully. This probability space will be used through the rest of this chapter.

Let $\X=(0,\infty)$ be the space containing all possible lowest values $x$ of the envelopes. Equip $\X$ with $\Sigma_{\X}=\B((0,\infty))$, the Borel $\sigma$-algebra on $(0,\infty)$. Let $\Y=\left\{(x,2x),(2x,x)\in(0,\infty)^2\middle|x\in\X\right\}$ be all possible values in the envelopes. The set $\Y$ is equipped with $\sigma$-algebra $\Sigma_{\Y}=\B\left(\Y\right)$, the Borel-$\sigma$-algebra of the lines $x\mapsto2x$ and $x\mapsto\frac{1}{2}x$. Let $\Omega=\X\times\Y$ be our sample space equipped with $\Sigma=\Sigma_{\X}\times\Sigma_{\Y}$ as $\sigma$-algebra.

Let $X$ be an $\X$-valued continuous random variable denoting the lowest value of the envelopes and $Y$ be a $\Y$-valued random variable denoting the actual values. All probability distributions $\P$ on $(\Omega,\Sigma)$ must be a member of
\begin{equation}
\Pmod=\left\{\P\middle|\P[Y=(x,2x)|X=x]=\P[Y=(2x,x)|X=x]=\frac{1}{2},\E_{\P}[X]<\infty\right\}.
\end{equation}
Let $\pi_i\colon\R^2\to\R$ with $i\in\{1,2\}$ be the projection on the $i$-th coordinate. Let $A=\pi_1(Y)$ be the value in envelope~$A$ and $B=\pi_2(Y)$ be the value in envelope~$B$. Assume that without loss of generality the player initially chooses envelope~$A$, then we would like to know the distribution of $B|A$.

The reason why we demand finite expectation, is that in the case of infinite expectation the two envelope problem starts to behave like the St.~Petersburg problem \cite{Brams95,Broome95,Tzur18}. This problem concerns a game where the coin is flipped until it gives heads. Suppose the coin is flipped $n$ times, then \$$2^n$ is paid out. The expected value of the amount of money paid out is infinite while there is a probability of 87,5\% of a payout of only \$7, which was viewed as paradoxical. This problem does not concern conditional probability and will therefore not be treated in this thesis. Interested readers are referred to William Feller, who described in 1950 the problem with an accessible discussion and solution \cite{Feller50} and provided in 1971 a general theorem for similar problems \cite{Feller71}.\\
In our case, a prior with infinite expectation value on $X$ will lead to the paradoxical result of always having to switch, as will be shown in Section~\ref{sec:EnvelopePriorInfluence}. This is another reason to leave such priors out of $\Pmod$.

Note that all $\P\in\Pmod$ are fixed on $Y$ when the value of $X$ is known. Thus $\Pmod$ is essentially implied by all the probability distributions on $\X$ where $X$ has finite expectation. In the next section we will dive deeper into the distributions $\P$ on $\Omega$ and their influence to the problem.

\section{Prior on envelope values}\label{sec:EnvelopePrior}
Recall that all probability distributions usable in the two envelope problem must be of the set
\begin{equation}
\Pmod=\left\{\P\middle|\P[Y=(x,2x)|X=x]=\P[Y=(2x,x)|X=x]=\frac{1}{2},\E_{\P}[X]<\infty\right\}.
\end{equation}
As we now do not have more information on the problem, any distribution from $\Pmod$ can be the correct one. However, a player playing the two envelope game probably has a suspicion on how $X$ is distributed. This suspicion can be modelled as either a single distribution $\P\in\Pmod$ or a subset $P\subset\Pmod$ of distributions. Therefore, we can introduce the following definition of a prior.

\begin{definition}[Prior]
A distribution $\P\in\Pmod$ is called a \emph{prior} on the envelope values and set $P\subset\Pmod$ is called a set of priors. The density function of prior $\P\in\Pmod$ on $\X$, the lowest value of the envelopes, will be denoted by $f\colon\X\to[0,\infty)$.
\end{definition}

Note that, as mentioned in Section~\ref{sec:EnvelopeFormal}, there are no two $\P_1,\P_2\in\Pmod$ that are almost surely equally distributed on $\X$ but differently on $\Y$, as the conditional distribution $Y|X$ is fixed in $\Pmod$. Thus the distribution on $\Omega$ of two $\P$'s in $\Pmod$ are only almost surely equal when those $\P$'s are almost surely equal on $\X$.


\subsection{Prior with no information}
First consider the setting where no information on $\Pmod$ is known. An exhaustive analysis of this case is done by Albers, Kooi and Schaafsma \cite{Albers05}. They give three noteworthy examples for trying to solve the two envelope problem while nothing is known about prior $f$, however they conclude that the paradox is just hopeless to tackle without being giving more information.

\begin{example}[Conditional expectation]
Let $\P\in\Pmod$ be arbitrary and suppose $\P[A>B|A=a]=p\in[0,1]$ holds, thus the probability of receiving the higher envelope given you observed $A=a$ equals $p$. The expected value of $B$ given $A=a$ becomes
\begin{align}
\E_{\P}[B|A=a]&=\frac{a}{2}\P\left[B=\frac{a}{2}\middle|A=a\right]+2a\P[B=2a|A=a]\\
&=\frac{a}{2}p+2a(1-p)=a\left(2-\frac{3}{2}p\right).
\end{align}
Therefore $\E_{\P}[B|A=a]<a$ holds when $p>\frac{2}{3}$. Thus when it is likely that you have the higher envelope, switching is not advised.

However, note that
\begin{equation}
\P[A>B|A=a]=\E\left[\1_{\{A>B\}}\middle|A=a\right]
\end{equation}
holds. Following \cite{Albers05}, the estimation of $\P[A>B|A=a]$ is replaced by the prediction of $\1_{\{A>B\}}$, which is not possible without having more information on $\P$.
\end{example}
\begin{example}[Entropy analysis]
Another route is to estimate the entropy of the distribution on the other envelope. If we can maximize this entropy, an estimated prior will follow giving us advice on whether we want to switch.

Let $\mu\in(0,\infty)$ be arbitrary and let $P\subset\Pmod$ be such that $\E_{\P}[B]=\mu$ holds for all $\P\in P$. This will be the only assumption we will make on the prior. We can now construct an estimate $f'$ for the prior $f$ such that
\begin{equation}
H(f')=\begin{cases}
-\sum_{y=1}^\infty f'(y)\log f'(y),&X\text{ discrete},\\
-\int_{y=0}^\infty f'(y)\log f'(y),&X\text{ continuous},
\end{cases}
\end{equation}
is maximized with $\E[B]=\mu$ as restriction.

Following this route \cite{Albers05} found that in the discrete case, the envelope must be swapped for odd $a\in\N\setminus2\N$ and not swapped for even $a\in2\N$. In the continuous case, the player must always swap.

This answer raises a lot of questions, such as why the player should in the discrete case favour values $1001$ and $1003$ and discard value $1002$. No one playing the two envelope problem would be convinced that this is a working strategy. Furthermore, as we will see in Section~\ref{sec:EnvelopeSwitching}, in the continuous case switching strategies exist yielding higher gain for all priors $f$ than always switching the envelope. Thus the continuous strategy using entropy can be called insufficient, as strategies exist that outperform `always switching'.
\end{example}

There is a third game-theoretic example given by \cite{Albers05}, however even Albers et alii state that this perspective is unnecessarily complicated and will not be helpful.

The overall conclusion of \cite{Albers05} is that if no information on the prior is known, a mathematician must be satisfied with the fact that he just cannot solve the problem. There is not enough relevant information to make justified decisions or create useful strategies.


\subsection{Investigating different priors}\label{sec:EnvelopePriorInfluence}
Take a distribution $\P$ on $\Omega$ and let $f$ be its accompanying prior. We will take a look at various variations of $f$. We will observe that for certain priors switching will always be advised, but the expectation $\E[X]$ will be infinite as well. When $\E[X]$ is finite, then useful switching strategies will arise.

\begin{example}[Navara and Šindelár (2017)]\label{ex:EnvelopePriorGain}
The following example is taken from \cite{Navara17}. Assume that $f$ is a discrete prior and $\P$ its accompanying distribution on $\Omega$. We want to know how much we expect to gain by switching given value $a$ is in envelope $A$. Define the gain $G=B-A$. It is easy to see that
\begin{equation}
\E_{\P}[G]=\E_{\P}[B]-\E_{\P}[A]=\frac{3}{2}\E_{\P}[X]-\frac{3}{2}\E_{\P}[X]=0.
\end{equation}
The possible values of the gain given $A=a$ are $G=a$ or $G=-\frac{a}{2}$. The probability distribution of $G|A=a$ is according to \cite{Navara17} given by
\begin{equation}
\P[G=g|A=a]=\begin{cases}
\frac{f(a)}{f(a)+f\left(\frac{a}{2}\right)},&g=a,\\
\frac{f\left(\frac{a}{2}\right)}{f(a)+f\left(\frac{a}{2}\right)},&g=-\frac{a}{2}.
\end{cases}
\end{equation}
The expectation value of $G|A=a$ is then given by
\begin{equation}
\E_{\P}[G|A=a]=\frac{af(a)-\frac{a}{2}f\left(\frac{a}{2}\right)}{f(a)+f\left(\frac{a}{2}\right)}.
\end{equation}
Consider now the prior $f(2^t)=\frac{q^t}{1-q}$, then three different cases can be distinguished:
\begin{enumerate}
    \item[$q<\frac{1}{2}$:] Take $q<\frac{1}{2}$, then $\E_{\P}[X]$ exists and is equal to $\E_{\P}[X]=(1-q)^{-1}(1-2q)^{-1}$. In this case we have
    \begin{equation}
    \E_{\P}\left[G\middle|A=2^t\right]=\begin{cases}2^{t-1}\frac{2q-1}{q+1},&t\in\N_{\geq 1}\\1,&t=0.\end{cases}
    \end{equation}
    Therefore with this prior switching is only recommended when one observes a value of $1$ in his envelope, as $\E_{\P}[G|A=2^t]<0$ is negative for all $t\in\N_{\geq 1}$.
    \item[$q=\frac{1}{2}$:] Take $q=\frac{1}{2}$, then $\E_{\P}[X]$ does not exist any-more. The expected gain now simplifies to $\E\left[G\middle|A=2^t\right]=\1_{\{0\}}(t)$, thus there is only gain on switching when $A=1$.
    \item[$q>\frac{1}{2}$:] Take $q>\frac{1}{2}$, then $\E_{\P}[X]$ does not exist as well. The conditional gain $G|A=2^t$ is still valid and equals
    \begin{equation}
    \E_{\P}\left[G\middle|A=2^t\right]=\begin{cases}2^{t-1}\frac{2q-1}{q+1},&t\in\N_{\geq 1},\\1,&t=0,\end{cases}
    \end{equation}
    which is strictly positive for all $t\in\N$. Thus the player is motivated to always switch, which is a paradoxical result.
\end{enumerate}

The $q$ controlling the prior $f$ can lead to various results, from non-paradoxical advise to only switch when obtaining the smallest value $1$ knowing the other envelope must contain $2$, to the original paradox of always having to switch no matter the contents of $A$. The difference with the original paradox is that the paradoxical result of this example is supported by a prior on $X$, not by wrongly performing the calculations involved with the problem.
\end{example}

\begin{example}[Broome (1995)]
This example is taken from \cite{Broome95} and is given by many as a lighting example of when a prior on $X$ can have infinite expectation. Consider first the discrete case. Let $f(2^n)=\frac{2^n}{3^{n+1}}$ with $n\in\N_{\geq 0}$ be a prior. We now want to know the expected value in envelope $B$. The trivial case is $\E[B|A=1]=2$, as the only possible value in envelope $B$ is $2$ when observing $1$.\\
Suppose we observe a value $a\neq1$. Then $B=2a$ is possible if and only if $X=A=a$. When observing envelope $A=a$, then either $X=a$ or $X=\frac{a}{2}$ can hold. Therefore following \cite{Broome95}
\begin{align}
\P[B=2a|A=a]&=\P\left[X=a\middle|X=a\lor X=\frac{a}{2}\right]\\
&=\frac{\frac{2^n}{3^{n+1}}}{\frac{2^n}{3^{n+1}}+\frac{2^{n-1}}{3^{n}}}=\frac{2}{5}.
\end{align}
We have $\P\left[B=\frac{a}{2}\middle|A=a\right]=1-\P[B=2a|A=a]=\frac{3}{5}$ as well, giving an expected value of envelope $B$ of
\begin{equation}
\E[B|A=a]=\frac{2}{5}\cdot2a+\frac{3}{5}\cdot\frac{a}{2}=\frac{11}{10}a.
\end{equation}
The paradoxical conclusion is that the player must always switch, no matter the contents of his envelope. The reason why $\E[B|A=a]>a$ for all $a=2^n$ with $n\in\N$ is possible, is that $\E[X]=\sum_{n=1}^\infty\left(\frac{4}{3}\right)^n=\infty$ is infinite.

Until now we have only considered discrete distributions, but paradoxical conclusions can result from continuous distributions as well. Let $f$ be a continuous prior on $X$, then the conditional expectation on $B|A=a$ is
\begin{equation}
\E[B|A=a]=a\frac{8f(a)+f\left(\frac{a}{2}\right)}{4f(x)+2f\left(\frac{a}{2}\right)}
\end{equation}
as is derived by \cite{Broome95}. Take density function $f(x)=(x+1)^{-2}$ with $x\in(0,\infty)$, then the conditional expectation of $B|A=a$ becomes
\begin{equation}
\E[B|A=a]=a\frac{2(a+2)^2+(a+1)^2}{(a+2)^2+2(a+1)^2}>a
\end{equation}
for all $a\in(0,\infty)$. Here the situation that switching is advised arises as well. Note that the expectation value of the prior $\E[X]=\int_0^\infty \frac{x}{(x+1)^2}dx=\infty$ is infinite, explaining why $\E[B|A=a]>a$ for all $a\in(0,\infty)$ is again possible.
\end{example}

Take another look at the gain $G$ given $A=a$, defined in Example~\ref{ex:EnvelopePriorGain}. When considering the conditional expectation $\E[G|A=a]$, one can quantify when a distribution yields to paradoxical results. For discrete priors, $\E[G|A=a]$ equals \cite{Navara17,Tzur18}
\begin{equation}
\E[G|A=a]=\frac{af(a)-\frac{a}{2}f\left(\frac{a}{2}\right)}{f(a)+f\left(\frac{a}{2}\right)}
\end{equation}
and where it gives rise to the following definition.
\begin{definition}[Discrete paradoxical distribution]
A discrete prior $f$ on $X$ is called \emph{paradoxical} if $f(x)>\frac{1}{2}f\left(\frac{x}{2}\right)$ holds for all $x\in\supp_{\P}(X)$.
\end{definition}
\begin{lemma}
Let $f$ be a discrete paradoxical prior on $X$, then the expectation value $\E[X]=\infty$ is infinite.
\end{lemma}
\begin{proof}
This proof is taken from \cite{Tzur18}. Let $x$ be a possible realization of $X$, then $2^k x$ with $k\in\N$ are possible realizations of $X$ as well by the setting of the two envelope problem. Note that $2^{k+1}xf(2^{k+1} x)>2^k xf(2^kx)$ holds for all $x\in\N$, implying an unbounded $\E[X]=\sum_{k=0}^\infty k f(k)>\sum_{k=0}^\infty 2^k xf(2^k x)$ as all terms $2^kxf(2^kx)$ will increase in $k$.
\end{proof}

The requirement for a continuous paradoxical distribution is slightly different. Brams, Kilgour and Blachman \cite{Brams95,Christensen96} calculated when the conditional expectation $\E[B|A=a]>a$ holds for continuous priors.

\begin{definition}[Continuous paradoxical distribution]
A continuous prior $f$ on $X$ is called \emph{paradoxical} if $f(x)>\frac{1}{4}f\left(\frac{x}{2}\right)$ holds for all $x\in\supp_{\P}(X)$.
\end{definition}

As mentioned in Section~\ref{sec:EnvelopeFormal}, we will only consider non-paradoxical distributions from now on. It is now clear that, when having full information, paradoxical distributions still yield unexpected results. This is contributed to the expectation value of the prior being undefined, not to a wrong interpretation of the problem. When having full information non-paradoxical priors yield well-defined and useful switching strategies.


\subsection{Optimal solution}
Suppose a non-paradoxical prior on $X$ is known, does an optimal switching strategy exist? This question is asked and answered by \cite{Christensen92} and further discussed by \cite{Christensen93a,Christensen93b,Christensen94,Christensen96}. Originally, \cite{Christensen92} proposed a solution for all general priors, however \cite{Christensen96} pointed out this is incorrect for continuous distributions. Here we will combine the discussion and provide a resolution.

\subsubsection{Discrete priors}
Let $f$ be a discrete prior on $X$ with distribution $\P\in\Pmod$, then \cite{Christensen92} states that
\begin{align}
\P\left[X=a\middle|A=a\right]&=\frac{\P[A=a|X=a]f(a)}{\P[A=a|X=a]f(a)+\P\left[A=a\middle|X=\frac{a}{2}\right]f\left(\frac{a}{2}\right)}\\
&=\frac{f(a)}{f(a)+f\left(\frac{a}{2}\right)},\\
\P\left[X=\frac{a}{2}\middle|A=a\right]&=\frac{\P\left[A=a\middle|X=\frac{a}{2}\right]f\left(\frac{a}{2}\right)}{\P[A=a|X=a]f(a)+\P[A=a|X=2a]f(2a)}\\
&=\frac{f\left(\frac{a}{2}\right)}{f(a)+f\left(\frac{a}{2}\right)}.
\end{align}
We can now compute $\E[B|A=a]$ to be
\begin{align}
\E[B|A=a]&=\frac{a}{2}\P\left[X=\frac{a}{2}\middle|A=a\right]+2a\P\left[X=a\middle|A=a\right]\\
&=\frac{af\left(\frac{a}{2}\right)+4af(a)}{2f(a)+2f\left(\frac{a}{2}\right)}.
\end{align}
Obviously when $\E[B|A=a]>a$ holds, switching is advised. This happens when $f\left(\frac{a}{2}\right)<2f(a)$.

Does a discrete prior $f$ exist for which the requirement $\E[B|A=a]\leq a$ holds for all $a\in\supp_{\P}(A)$, thus where the player must never switch? The answer is no, as the following proposition from \cite{Brams95} points out.
\begin{proposition}[Brams and Kilgour (1995)]
There is no discrete prior $f$ on $X$ for which $\E[B|A=a]\leq a$ holds for all $a\in\supp_{\P}(A)$.
\end{proposition}
\begin{proof}
The proof is taken from \cite{Brams95}. Assume $f$ is a prior with $\E[B|A=a]\leq a$ for all $a\in\supp_{\P}(A)$. In order for $\E[B|A=a]\leq a$ we must have $f\left(\frac{a}{2}\right)\geq2f(a)$. Let $a\in\supp_{\P}(A)$ be such that $f(a)>0$, then $f\left(a\right)\geq 2^{n}f(2^na)$ holds for all $n\in\Z$, leading to $f(a)\to0$ as $n\to-\infty$. We cannot have $f(a)$ being arbitrarily close to zero and strictly positive at the same time, rendering the assumption of the existence of $f$ false.
\end{proof}

On the contrary, does a discrete prior $f$ exist with $\E[B|A=a]>a$ for all $a\in\supp_{\P}(A)$? Then $f\left(\frac{a}{2}\right)>f(a)$ must hold for all $a\in\supp_{\P}(A)$, which is achieved for all paradoxical distributions since $\supp_{\P}(X)\subset\supp_{\P}(A)$. Various examples can be found in \cite{Christensen93a,Linzer94,Broome95} and previously in Section~\ref{sec:EnvelopePriorInfluence}, with $f(2^n)=\frac{2^n}{3^{n+1}}$ as the most common one. In this case a new paradox arises, where switching is always advised.\\
Note that Christensen and Utts do not agree with this occurrence as being a paradox as stated in \cite{Christensen93a}, as $\E[B|A=a]$ is still finite and can be compared with $a$.

\subsubsection{Continuous case}
Let $f$ be a continuous prior on $X$ with distribution $\P\in\Pmod$. First \cite{Christensen92} states that
\begin{equation}
\E[B|A=a]=\frac{af\left(\frac{a}{2}\right)+4af(a)}{2f(a)+2f\left(\frac{a}{2}\right)}
\end{equation}
holds for continuous priors as well, however \cite{Christensen96} points out this is not correct.

Take a look at the following analysis from \cite{Brams95}. Let $Y=\frac{X}{2}$ and let $g$ be a probability density function on $Y$. Then we have $\P[X\leq x]=\P\left[Y\leq \frac{x}{2}\right]$, thus $F(x)=G\left(\frac{x}{2}\right)$ where $F$ and $G$ are the cumulative density functions of $X$ and $Y$ respectively. Differentiating for the density functions yields $f(x)=\frac{1}{2}g\left(\frac{x}{2}\right)$. Now, analogous to the discrete case, we have
\begin{align}
\P[X=a|A=a]&=\frac{f(x)}{f(x)+g(x)}=\frac{f(x)}{f(x)+\frac{1}{2}f\left(\frac{x}{2}\right)},\\
\P\left[X=\frac{a}{2}\middle|A=a\right]&=\frac{g(x)}{f(x)+g(x)}=\frac{\frac{1}{2}f\left(\frac{x}{2}\right)}{f(x)+\frac{1}{2}f\left(\frac{x}{2}\right)}.
\end{align}
The expectation of $B|A=a$ now becomes
\begin{align}
\E[B|A=a]&=\frac{a}{2}\P\left[X=\frac{a}{2}\middle|A=a\right]+2a\P\left[X=a\middle|A=a\right]\\
&=\frac{af\left(\frac{a}{2}\right)+8af(a)}{4f(a)+2f\left(\frac{a}{2}\right)}.
\end{align}
This expectation value is different from the version in \cite{Christensen96}, as they made a mistake mixing up the probabilities while calculating the expectation value. Nevertheless their conclusion that now $4f(a)>f\left(\frac{a}{2}\right)$ must hold in order to get $\E[B|A=a]>a$ is still correct.

The same proposition as in the discrete case that $\E[B|A=a]>a$ must happen for at least one $a\in\supp_{\P}(A)$ is valid here as well.
\begin{proposition}[Brams and Kilgour (1995)]
There is no continuous prior $f$ on $X$ for which $\E[B|A=a]\leq a$ holds for all $a\in\supp_{\P}(A)$.
\end{proposition}
\begin{proof}
This proposition is stated and proven as Theorem 2 in \cite{Brams95}.
\end{proof}

Examples for which $\E[B|A=a]>a$ holds for all $a\in\supp_{\P}(A)$ can be found in \cite{Christensen96,Broome95,Brams95} and previously in Section~\ref{sec:EnvelopePriorInfluence}, with $f(a)=(a+1)^{-2}$ for $a\in(0,\infty)$ being one of the most common example \cite{Broome95}.

\subsubsection{Summarizing switching strategies}
To summarize, let $f$ be a non-paradoxical prior on $X$ with distribution $\P\in\Pmod$. Suppose the player observes $a\in\supp_{\P}(A)$. The following strategies optimize the values won by the player:
\begin{itemize}
\item[Discrete:] When $f$ is discrete, the player must switch his envelope when \begin{equation}
f(a)>\frac{1}{2}f\left(\frac{a}{2}\right).
\end{equation}
\item[Continuous:] When $f$ is continuous, the player must switch his envelope when
\begin{equation}
f(a)>\frac{1}{4}f\left(\frac{a}{2}\right).
\end{equation}
\end{itemize}

\section{Safe probability}\label{sec:EnvelopeSafe}
Consider now applying safe probability to the two envelope problem. If there is a safe distribution for $\EnvInd|A$, we can use this distribution to see whether we want to switch and when. The random variable $\EnvInd$ describes whether the second envelope has twice the observed value. The following proposition gives a safe distribution for $\EnvInd$.
\begin{proposition}\label{prop:EnvelopeIndSafe}
A distribution $\Psafe$ on $\Omega$ is safe for $\langle\EnvInd\rangle|\langle A\rangle$ with model $\Pmod$ if
\begin{equation}
\int_0^\infty \Psafe[B=2A|A=a]f_A(a)da=\frac{1}{2}
\end{equation}
holds where $f_A$ is the probability density function of $A$. Furthermore, the following statements are equivalent:
\begin{enumerate}
\item For all $a\in\supp_{\Psafe}(A)$ we have $\Psafe[B=2A|A=a]=\frac{1}{2}$.
\item $\Psafe$ is safe for $\EnvInd|[A]$.
\item $\Psafe$ is safe for $\langle\EnvInd\rangle|[A]$.
\end{enumerate}
\end{proposition}
\begin{proof}
We begin with proving the first statement. Let $\Psafe$ be an arbitrary distribution on $\Omega$ that is safe for $\langle\EnvInd\rangle|\langle A\rangle$. Let $\P\in\Pmod$ be arbitrary and let $f_X$ be the accompanying prior on $X$. Firstly we have
\begin{align}
\E_{\P}\left[\EnvInd\right]&=\P[B=2A]=\int_0^\infty\P[B=2X|X=x]f_X(x)dx\\
&=\frac{1}{2}\int_0^\infty f_X(x)dx=\frac{1}{2},
\end{align}
as $B=2A$ only happens when $A=X$ and $\P[B=2X|X=x]=\frac{1}{2}$ is dictated by our model $\Pmod$. Let $a\in\supp_{\Psafe}(A)$ be arbitrary, then
\begin{equation}
\E_{\Psafe}\left[\EnvInd\middle|A=a\right]=\Psafe[B=2A|A=a]
\end{equation}
must hold. Therefore we have
\begin{equation}
\E_{\P}\left[\E_{\Psafe}\left[\EnvInd\middle|A=a\right]\right]=\int_0^\infty\Psafe[B=2A|A=a]f_A(a)da.
\end{equation}
The density $f_A$ of $A$ is unknown. Since $\Psafe$ must be safe for $\langle\EnvInd\rangle|\langle A\rangle$, we need $\E_{\P}\left[\E_{\Psafe}\left[\EnvInd\middle|A=a\right]\right]=\E_{\P}\left[\EnvInd\right]$ by definition~\ref{def:SafeProp}. This results to the requirement
\begin{equation}
\int_0^\infty\Psafe[B=2A|A=a]f_A(a)da=\frac{1}{2}.
\end{equation}

Now we will move our focus to the equivalence. First consider the implication from 1 to 2. Let $\Psafe$ be a distribution on $\Omega$ with $\Psafe[B=2A|A=a]=\frac{1}{2}$ for all $a\in\supp_{\Psafe}(A)$. Let $\P\in\Pmod$ and $a\in\supp_{\Psafe}(A)$ be arbitrary, then
\begin{equation}
\Psafe[B=2A|A=a]=\frac{1}{2}=\P[B=2A].
\end{equation}
Thus $\Psafe$ is safe for $\EnvInd|[A]$ by Proposition~\ref{prop:SafeProperties}.

The implication from 2 to 3 is stated in Proposition~\ref{prop:SafeImply}.

Lastly, we will turn to the implication from 3 to 1. Let $\Psafe$ be a distribution on $\Omega$ that is safe for $\langle\EnvInd\rangle|[A]$ for all $\P\in\Pmod$. Let $\P\in\Pmod$ be arbitrary and let $a\in\supp_{\Psafe}(A)$, then safety for $\langle\EnvInd\rangle|[A]$ implies
\begin{equation}
\E_{\P}[\EnvInd]=\E_{\Psafe}[\EnvInd|A=a].
\end{equation}
Expanding this requirement gives
\begin{equation}
\E_{\P}[\EnvInd]=\frac{1}{2}=\E_{\Psafe}[\EnvInd|A=a]=\Psafe[B=2A|A=a],
\end{equation}
which gives the result that $\Psafe[B=2A|A=a]=\frac{1}{2}$ must hold for all $a\in\supp_{\Psafe}(A)$.
\end{proof}

Note that in this case Theorem~\ref{thm:DiscMainThm} cannot be applied, as this theorem dictates that the sample space $\Omega$ is split up in $\Omega=\X'\times\Y'$, where $\X'$ is countable and $\Y'$ is finite. In our case we do have $\Omega=\X\times\Y$, however both $\X$ and $\Y$ are uncountably infinite of size.

Therefore while not knowing how $\EnvInd|A$ is distributed, we can pick a safe distribution $\Psafe$ from Proposition~\ref{prop:EnvelopeIndSafe}. When we only need an unbiased distribution for $\EnvInd$ given $A$, it is sufficient to pick a $\Psafe$ with
\begin{equation}
\int_0^\infty\Psafe[B=2A|A=a]f_A(a)da=\frac{1}{2}.
\end{equation}
For marginal validity we need $\Psafe[B=2A|A=a]=\frac{1}{2}$ for all $a\in\supp_{\Psafe}(A)$.

Now note that safe probability will not provide more insight. Considering marginal validity first, let $\Psafe$ be marginally valid for $\EnvInd|A$. Then according to Proposition~\ref{prop:EnvelopeIndSafe} $\Psafe[B=2A|A=a]=\frac{1}{2}$ is required for all $a\in\supp_{\Psafe}(A)$. When $\supp_{\Psafe}(A)$ is of infinite size, distribution $\Psafe$ cannot exist as is earlier pointed out in Section~\ref{sec:EnvelopeFormal} and in \cite{Christensen92,Christensen93b,Navara17,Tzur18}.\\
When $\Psafe$ is an unbiased for $\EnvInd|A$, we have the requirement
\begin{equation}
\int_0^\infty\Psafe[B=2A|A=a]f_A(a)da=\frac{1}{2}.
\end{equation}
Here the probability density function $f_A$ of $A$ is not known and if it is, then a vast array of distributions $\Psafe$ will satisfy this requirement. Thus unbiased distribution for $\EnvInd|A$ will not give more insight here.

Suppose $\EnvInd$ is predicted by a random variable $\EnvInd^*$, not taking $A$ into account. Let $\P\in\Pmod$ be the actual probability distribution on $\Omega$ and let $\EnvInd^*\sim\mathrm{Ber}(p)$ be Bernoulli distributed with parameter $p\in[0,1]$. Let $\P'$ be the probability distribution of $\EnvInd^*$, then
\begin{equation}
\acc(\EnvInd)=\sum_{k\in\{0,1\}}\P'[\EnvInd^*=k]\P[\EnvInd=k]=\frac{1}{2}(p+1-p)=\frac{1}{2}.
\end{equation}
Therefore it looks like no matter in which frequency the person switches after an observed $A=a$, the probability of receiving the higher envelope stays equal. The average value the player wins will be $\frac{3}{2}\E_{\P}[X]$ and this cannot be improved without taking $A$ into account.

Safe probability cannot take into account the probability observing $A=a$. Either a marginally valid distributions arises which erases the influence of $A$ or an unbiased distribution arises where there is too less information for the distribution to be convincing. A probability measure $\Psafe$ from Proposition~\ref{prop:EnvelopeIndSafe} must be safe against all $\P\in\Pmod$ and those $\P$'s all impose vastly different distributions on $A$. Therefore we can say that model $\Pmod$ is simply too large to apply safe probability. We need to either put ill-founded assumptions on our model or try another strategy. We will do the latter in the next section.

\section{Cover's switching strategy}\label{sec:EnvelopeSwitching}
If we  adapt our probability of switching to the observation $A=a$, we can obtain on average higher results than $\frac{3}{2}\E_{\P}[X]$. The technique of switching smartly is first devised by Cover and in 2003 personlly communicated to McDonnell and Abbott \cite{McDonnell09}, who published this technique with numerous examples \cite{McDonnell09,Abbott10,McDonnell11}. The techniques used were already lightly touched upon by Christensen and Utts in 1992 \cite{Christensen92} and by Ross in 1994 \cite{Christensen94} as response on the article of Christensen and Utts. Since McDonell and Abbott fleshed out the switching strategy and describes it in more detail, we will use their articles as foundation.

In short, Cover's switching strategy devises a function $P\colon(0,\infty)\to[0,1]$ which picks an observed $a\in(0,\infty)$ and assigns a probability $P(a)\in[0,1]$ to it. The player then switches his envelope with probability $P(a)$. Note that, in contrary to what many initially assume, the function $P$ does not need to integrate to $1$; it is not a probability density function. It implies after observing an $a\in(0,\infty)$ a probability distribution of whether or not to switch the envelopes.

\begin{definition}[Switching strategy]
A function $P\colon(0,\infty)\to[0,1]$ is called a \emph{switching strategy}.
\end{definition}

Assume that the prior $f$ on $X$ is \emph{continuous} with finite expectation value and let $\P\in\Pmod$ be its accompanying distribution on $\Omega$. The function $P$ can be picked in such a way that, while not knowing the distribution $\P\in\Pmod$, we can always on average get a higher result than $\frac{3}{2}\E_{\P}[X]$.

Consider for a short while a more general problem where envelope $A$ receives $2X$ with probability $1-p$ and receives $X$ with probability $p\in[0,1]$. The original problem can then be retrieved by putting $p=\frac{1}{2}$. After observing value $A=a$, the player randomly chooses envelope~$B$ with probability $P(a)$. Let $R$ be the value returned to the player at the end of the game, then the probability distribution of $R|X=x$ is given by
\begin{align}
\P[R=x|X=x]&=\P[A=x|X=x](1-P(x))+\P[A=2x|X=x]P(2x)\\
&=p(1-P(x))+(1-p)P(2x),\\
\P[R=2x|X=x]&=\P[A=2x|X=x](1-P(2x))+\P[A=x|X=x]P(x)\\
&=(1-p)(1-P(2x))+pP(x).
\end{align}
Therefore the conditional expectation of the return given $X=x$ is
\begin{align}
\E[R|X=x]&=x\P[R=x|X=x]+2x\P[R=2x|X=x]\\
&=x(2-p)+pxP(x)-x(1-p)P(2x)).
\end{align}
Following \cite{McDonnell09}, we get
\begin{align}
\E[R]=\E[\E[R|X]]&=\int_0^\infty f(x)\E[R|X=x]dx\\
&=(2-p)\E[X]+\int_0^\infty xf(x)(pP(x)-(1-p)P(2x))dx.
\end{align}
When the player never or always switches, thus $P\equiv0$ or $P\equiv1$, his expected return is $(2-p)\E[X]$. Define $G=\int_0^\infty xf(x)(pP(x)-(1-p)P(2x))dx$ as the players gain of his switching strategy. One can immediately see that for all $x$ the requirement $pP(x)\geq(1-p)P(2x)$ is a sufficient condition for a non-negative gain. The gain can be rewritten as
\begin{align}
G&=\int_0^\infty xf(x)(pP(x)-(1-p)P(2x))dx\\
&=\int_0^\infty xP(x)\left(pf(x)-\frac{1-p}{4}f\left(\frac{x}{2}\right)\right)dx,
\end{align}
where both representations will become useful in many different ways. This will be summarized in the following definition.
\begin{definition}
Let $f$ be a continuous prior on $X$ with finite expectation value. Let $P$ be a switching strategy. The \emph{gain} of a player is defined by
\begin{align}
G&=\int_0^\infty xf(x)(pP(x)-(1-p)P(2x))dx\label{eq:EnvelopeGainP}\\
&=\int_0^\infty xP(x)\left(pf(x)-\frac{1-p}{4}f\left(\frac{x}{2}\right)\right)dx.\label{eq:EnvelopeGainF}
\end{align}
\end{definition}
Equation~\ref{eq:EnvelopeGainF} immediately gives us the optimal switching strategy.
\begin{theorem}[McDonnell, Abbott \cite{McDonnell09}]\label{thm:switchopt}
The optimal switching strategy $P^*(x)$ is
\begin{equation}
P^*(x)=\1_{(0,\infty)}\left(pf(x)-\frac{1-p}{4}f\left(\frac{x}{2}\right)\right).\end{equation}
\end{theorem}
\begin{proof}
We can split the integrand of \eqref{eq:EnvelopeGainF} in two functions: $x\mapsto P(x)$ and $x\mapsto x\left(pf(x)-\frac{1-p}{4}f\left(\frac{x}{2}\right)\right)$. Function $P$ can be chosen at will, but the image must lie in $[0,1]$. The integration in \eqref{eq:EnvelopeGainF} is therefore maximized when $P(x)=1$ is chosen if $x\left(pf(x)-\frac{1-p}{4}f\left(\frac{x}{2}\right)\right)>0$ is positive and $P(x)=0$ otherwise. Since $x\mapsto x$ is positive for all $x\in(0,\infty)$, it is sufficient to require that the function $x\mapsto pf(x)-\frac{1-p}{4}f\left(\frac{y}{2}\right)$ must be positive when $P(x)=1$. Switching strategy $P^*$ implements this strategy.
\end{proof}

From now on we will put $p=\frac{1}{2}$ as in our model an envelope is  distributed to the player uniformly. In this case Equation~\ref{eq:EnvelopeGainP} leads to $P(x)\geq P(2x)$ for all $x\in(0,\infty)$ being sufficient for non-negative gain. We will now look at two example strategies, namely Cover switching and threshold switching. More examples, comparisons between the examples and simulations of the examples can be found in \cite{McDonnell09,McDonnell11}.

\begin{example}[Cover switching]
This example is taken from \cite{McDonnell09,Abbott10}. Let $a\in(0,\infty]$ be arbitrary and put $P(x)=e^{-ax}$. This $P$ is called \emph{Cover switching}. The inequality $P(x)\geq P(2x)$ is automatically satisfied as the requirement $e^{-ax}>e^{-2ax}$ holds for all positive $x$.

Suppose that $X\sim\mathrm{Exp}(c)$ is exponentially distributed. Let $R_C$ be the random variable of the return when Cover switching is used. Switching using Cover's strategy is maximized for $a=\left(\frac{1}{3}\sqrt[3]{2}+\frac{1}{6}\sqrt[3]{4}-\frac{1}{3}\right)c$, with a return of $\E[R_C]=\frac{3}{2c}\left(2-2\sqrt[3]{2}+\sqrt[3]{4}\right)\approx\frac{1.6013}{c}$. The return of this prior for never or always switching strategy is $\E[R]=\frac{3}{2}\E[X]=\frac{3}{2c}$, thus Cover switching does improve on never or always switching.
\end{example}

\begin{example}[Threshold switching]
This example is taken from \cite{McDonnell09}. Let $b\in(0,\infty)$ be arbitrary and define $P(a)=\1_{(0,b]}(a)$. This strategy is called \emph{threshold switching}. The player tries to switch all the low values he gets, but always holds on high values. Of course, if the prior on $X$ is unknown, no advice on which $b$ to choose can be given. However, as $P(a)\geq P(2a)$ always holds, this strategy has non-negative gain for all possible values $b$ independent of the prior $f$.

Let $X\sim\text{Exp}(c)$ be exponentially distributed. Looking at Equation~\ref{eq:EnvelopeGainF}, we want that $P(x)=1$ when $f(x)\geq\frac{1}{4}f\left(\frac{x}{2}\right)$ holds, thus when $ce^{-cx}\geq\frac{1}{4}ce^{-\frac{c}{2}x}$ holds. This is satisfied when $x<\frac{4\ln(2)}{c}$ holds, thus take $b=\frac{4\ln(2)}{c}$. Let $R_T$ be the value returned to the player when using threshold switching. The expected return will be $\E[R_T]=\frac{51+4\ln(2)}{32c}\approx\frac{1.6804}{c}$, which is higher than Cover switching's $\E[R_C]=\frac{1.6013}{c}$ and the $\E[R]=\frac{3}{2c}$ of never or always switching. Threshold switching is in fact the optimal switching function here, as $f(x)=\frac{1}{4}f\left(\frac{x}{2}\right)$ is obtained for a unique $x=\frac{4\ln(2)}{c}$ and $P^*$ from Theorem~\ref{thm:switchopt} then becomes threshold switching.
\end{example}
\subsection{Optimizing Cover's switching strategy}
Having two strategies, namely Cover and threshold switching, we would like to know how to optimize them while knowing as little of the distribution on $X$ as possible. McDonnell et alii~\cite{McDonnell11} considered various cases and here we will take a look at the ones with the least information on the prior of $X$. Assume for the rest of this section that the prior $f$ on $X$ is absolutely continuous and differentiable on $(0,\infty)$.

\subsubsection{Cover switching optimized}
This example is taken from \cite{McDonnell11}. Let $a\in[0,\infty]$ and consider Cover's switching strategy, $P(x)=e^{-ax}$. The gain as a function of $a$ can be written as
\begin{equation}
G(a)=\int_0^\infty pxf(x)e^{-ax}-(1-p)xf(x)e^{-2ax}dx.
\end{equation}
The optimal value $a^*$ solves the functional equation
\begin{equation}
\int_0^\infty e^{-a^*t}x^2f(x)dx=\frac{2(1-p)}{p}\int_0^\infty e^{-2a^*t}x^2f(x)dx,
\end{equation}
where $\int_0^\infty e^{-at}x^2f(x)dx$ is the Laplace transform of $x\mapsto x^2f(x)$ with parameter $a$. This leads to the following lemma:
\begin{lemma}[McDonnell et al.~(2011)]
Let $p\in[0,1]$ be the probability the lowest envelope is given to the player. Let $P$ be Cover's switching strategy with parameter $a$. The following cases must be distinguished for the optimal value $a^*$ of $G(a^*)$:
\begin{itemize}
    \item[{$p\in\left[0,\frac{1}{5}\right)$:}]
    The optimal value is $a^*=\infty$, thus never switching is the optimal strategy. The optimal gain is $G(\infty)=0$.
    \item[{$p\in\left[\frac{1}{5},\frac{2}{3}\right)$:}]
    If the function $x\mapsto pf(x)-\frac{1-p}{4}f\left(\frac{x}{2}\right)$ has a unique sign change, then $a\mapsto G(a)$ has a unique stationary point $a^*\in[0,\infty)$. This $a^*$ maximizes $a\mapsto G(a)$.
    \item[{$p\in\left[\frac{2}{3},1\right]$:}]
    The optimal value is $a^*=0$, thus always switching is the best strategy. The optimal gain is $G(0)=(2p-1)\E[X]$.
\end{itemize}
\end{lemma}
\begin{proof}
The proof can be found in \cite{McDonnell11}.
\end{proof}
Do note that there is an asymmetry in the previous lemma. When the probability of receiving the envelope with the lowest value is below $\frac{1}{5}$, never switching is the best strategy. However, when the probability is above $\frac{2}{3}$, always switching is the best strategy. One should expect the turning points to lie symmetric around $\frac{1}{2}$ such that they are $\frac{1}{3}$ and $\frac{2}{3}$ or $\frac{1}{5}$ and $\frac{4}{5}$. This phenomenon is widely studied in \cite{McDonnell11}.


\subsubsection{Threshold switching optimized}
The first part of this example is taken from \cite{McDonnell11}. Let $b\in[0,\infty]$ and consider threshold switching, $P(x)=\1_{[0,b]}(x)$. The gain as a function of $b$ can be written as
\begin{equation}
G(b)=\int_0^\infty pxf(x)\1_{[0,b]}(x)-(1-p)xf(x)\1_{\left[0,\frac{b}{2}\right]}(x)dx.
\end{equation}
Taking the derivative yields $G'(b)=b\left(pf(b)-\frac{1-p}{4}f(b)\right)$, resulting to a possible set of optimal values. Let $B=\{b\in[0,\infty)|G'(b)=0\}$ and take $b^*\in B$, then differentiating $G$ twice yields
\begin{equation}
G''(b^*)=b^*\left(pf'(b^*)-\frac{1-p}{8}f'\left(\frac{b^*}{2}\right)\right),\
\end{equation}which must be negative for $b^*$ to be a local maximum. This results to the condition
\begin{equation}
\frac{8p}{1-p}f'(b^*)< f'\left(\frac{b^*}{2}\right).
\end{equation}
Note that \cite{McDonnell11} does not have a strict inequality, but the second derivative test is inconclusive when $G''(b^*)=0$. Thus it is still possible for $b^*$ to be a saddle or a minimum in case of $G''(b^*)=0$, which is why we write a strict inequality here. This all results into the following lemma:
\begin{lemma}
Let $p\in[0,1]$ be such that the probability of receiving the lower envelope is $p$. Let $P$ be the threshold switching strategy. The set
\begin{equation}
B=\left\{b\in[0,\infty]\middle|pf(b)=\frac{1-p}{4}f\left(\frac{b}{2}\right)\land\frac{8p}{1-p}f''(b)<f'\left(\frac{b}{2}\right)\right\}\cup\{0,\infty\}
\end{equation}
is the set of all $b$ that locally maximize $b\mapsto G(b)$.
\end{lemma}
\begin{proof}
The proof can be found in \cite{McDonnell11}.
\end{proof}

This example however requires full knowledge on $f$. Can we optimize $P$ with as little knowledge as possible? The answer is yes and is given by \cite{Egozcue15}. Rephrase the gain as
\begin{equation}
G(b)=\frac{1}{2}\E[XP(X)-XP(2X)]=\frac{1}{2}\E\left[X\1_{\left(\frac{b}{2},b\right]}(X)\right],
\end{equation}
then we can derive a lower bound of $G$ when knowing only $\E[X]$ and $\V[X]$.
\begin{theorem}[Egozcue and García (2015)]\label{thm:EnvelopeSwitchBound}
Let $X$ be a continuous random variable with $\E[X]=\mu$ and $\V[X]=\sigma^2$. Let $m=\mu^2+\sigma^2$. Let $P$ be the threshold strategy with parameter $b\in(0,\infty)$.
\begin{enumerate}
    \item The gain has lower bound

       \begin{equation}
    G(b)\geq\frac{3+2\sqrt{2}}{b}\left(\frac{3}{2}b\mu-\frac{1}{2}b^2-m\right).
    \end{equation}
    \item If $\mu^2\geq 8\sigma^2$ holds, then $b^*=\sqrt{2m}$ is the optimal threshold strategy with gain
        \begin{equation}
    G(b^*)\geq(3+2\sqrt{2})\left(\frac{3}{2}\mu-\sqrt{2m}\right)\geq0.
    \end{equation}
    The gain is strictly positive when $\mu^2>8\sigma^2$.
\end{enumerate}
\end{theorem}
\begin{proof}
The proof can be found in \cite{Egozcue15}.
\end{proof}
Thus if $\E[X]^2\geq8\V[X]$ holds, we can find an optimal $b^*$ which always results in non-negative gain. The next question is whether there is a $b\in(0,\infty)$ which guarantees us a strictly positive gain for all priors on $X$. This is not possible, as the following theorem will point out.
\begin{theorem}[Egozcue and García (2015)]
Let $b\in(0,\infty)$. A random variable $X$ with $\E[X]^2<8\V[X]$ such that $G(b)=0$ always exists.
\end{theorem}
\begin{proof}
The proof can be found in \cite{Egozcue15}.
\end{proof}

\subsection{Discrete priors and the switching strategy}
We only considered switching strategies for continuous priors thus far. If $X$ is distributed discretely by distribution $\P\in\Pmod$, then switching strategies are still possible. As in the continuous case, we have
\begin{equation}
\E[R|X=x]=x(2-p)+pxP(x)-x(1-p)P(2x).
\end{equation}
The expected return is therefore
\begin{align}
\E[R]&=\sum_x f(x)\E[R|X=x]\\
&=(2-p)\E[X]+\sum_x xf(x)\big(pP(x)-(1-p)P(2x)\big).
\end{align}
A change in variables like the continuous case now becomes a bit awkward. Let $S$ be support of $X$, then
\begin{equation}
\sum_{x\in \supp_{\P}(X)}xf(x)P(2x)=\sum_{x\in2\supp_{\P}(X)}\frac{x}{2}f\left(\frac{x}{2}\right)P(x)
\end{equation}
holds. Thus we get
\begin{align}
G&=\sum_{x\in \supp_{\P}(X)}xf(x)(pP(x)-(1-p)P(2x))\\
&=p\sum_{x\in \supp_{\P}(X)}xP(x)f(x)-\frac{1-p}{2}\sum_{x\in2\supp_{\P}(X)}xf\left(\frac{x}{2}\right)P(x),
\end{align}
and since in the discrete case $\supp_{\P}(X)=2\supp_{\P}(X)$ does not necessarily hold the latter formula cannot be easily written in a single sum.

Put $p=\frac{1}{2}$, then it becomes clear that $P(x)\geq P(2x)$ is sufficient for non-negative gain. Thus any decreasing switching strategy will again be better than always keeping the envelope or always switching. Since this is also the case for continuous priors, we can recap both cases in the following theorem.

\begin{theorem}\label{thm:switchall}
Let $f$ be any prior on $X$ with finite mean and suppose the envelope is handed to the player with uniform distribution. Let $P$ be a decreasing switching strategy that is strictly decreasing on at least one subset $U\subset(0,\infty)$ that has positive probability measure. Then $P$ will lead to a positive gain and is a better strategy than either always keeping the envelope or always switching the envelope.
\end{theorem}
\begin{proof}
This theorem has already been proven in parts in the previous sections, so we'll only give a summary here. The gain, the difference between strategy $P$ and always keeping or switching envelopes, is defined as
\begin{equation}
G=\frac{1}{2}\int_0^\infty xf(x)(P(x)-P(2x))dx
\end{equation}
when $X$ is continuous and as
\begin{equation}
G=\frac{1}{2}\sum_xxf(x)(P(x)-P(2x))
\end{equation}
when $X$ is discrete. As $P$ is decreasing, $P(x)\geq P(2x)$ will always hold, making $G$ non-negative. If $P$ is also strictly decreasing on a subset $U\subset(0,\infty)$ with positive probability measure, $G$ becomes is strictly positive.
\end{proof}

\section{The Ali Baba problem}\label{sec:EnvelopeAli}
We thus far only studied the two envelope problem where there is only one player. Consider now the following Ali Baba problem mentioned by Nalebuff in 1989 \cite{Nalebuff89}. In the Ali Baba problem, envelope $A$ is filled first and then given to Ali. Then a hidden fair coin is tossed to decide whether envelope $B$ must contain value $2A$ or $\frac{1}{2}A$, where after filling the envelope it is given to Baba. Ali and Baba are allowed to privately look at the contents of their envelope. If they both agree that switching is the better choice, they are able to do so.

Take a look at the following reasoning taken from the introduction of \cite{Nalebuff89}. First consider Ali's choice. Baba has $\frac{1}{2}x$ money with probability $\frac{1}{2}$ and $2x$ money with probability $\frac{1}{2}$. He will reason that on average $B$ has $\frac{5}{4}x$ money, thus Ali always proposes a switch. Consider Baba's viewpoint next. Say he has an amount $y$, then $A$ has $2y$ or $\frac{1}{2}y$ amount of money. Thus Baba expects an amount of $\frac{5}{4}y$ in Ali's envelope, making him also wanting to switch. They both want to switch, while Ali obtained a fixed value and Baba's value is linked to this value. This is considered paradoxical.

The problem in this paradox again arises from wrongly applying probability theory like in Section~\ref{sec:EnvelopeNaive}. Call $x$ the amount of money in envelope $A$. The probability space is
\begin{equation}
\Omega=\left(\X=\left\{(x,2x),\left(x,\frac{1}{2}x\right)\right\},2^\X,\P\right)
\end{equation}
where $\P$ is the probability measure with $\P\left[\left(x,\frac{1}{2}x\right)\right]=\P[(x,2x)]=\frac{1}{2}$. Since Ali always gets an amount $x$, the expected value of Baba's envelope calculated from Ali's viewpoint remains the same:
\begin{equation}
\E[B]=\sum_{b\in\left\{\frac{x}{2},2x\right\}}b\P[B=b|A=x]=\frac{x}{2}\cdot\frac{1}{2}+2x\cdot\frac{1}{2}=\frac{5}{4}x.
\end{equation}
Therefore Ali will always want to switch. Consider now Baba's viewpoint. He either receives an amount $2x$ or $\frac{1}{2}x$. The corresponding expected values are
\begin{align}
\E[A|B=2x]&=\sum_{a\in\{x,4x\}}a\P[A=a|B=2x]=1\cdot x+0,\\
\E\left[A\middle|B=\frac{1}{2}x\right]&=\sum_{a\in\left\{\frac{x}{4},x\right\}}a\P[A=a|B=\frac{1}{2}x]=0+1\cdot x.
\end{align}
Thus the expected value of Ali's envelope is
\begin{align}
\E[A]=\E[\E[A|B]]&=\sum_{b\in\left\{\frac{x}{2},2x\right\}}\P[B=b]\E[A|B=b]\\
&=\frac{1}{2}x+\frac{1}{2}x=x.
\end{align}
It is unclear for Baba whether he should switch, as $A$ is expected to have on average value $x$.

Let $p\in[0,1]$ be the probability that $A$ and $B$ agree to switch. Consider the probability space
\begin{equation}
\Omega'=\left(\Y=\left\{(x,-x),\left(-\frac{1}{2}x,\frac{1}{2}x\right),(0,0)\right\},2^\Y,\P\right)
\end{equation}
with $\P[\{(x,-x)\}]=\P\left[\left\{-\frac{1}{2}x,\frac{1}{2}x\right\}\right]=\frac{1}{2}p$ and $\P[\{(0,0)\}]=1-p$. When there is no switch, $A$ and $B$ gain nothing. The probability of no switch is $1-p$, therefore $\{(0,0)\}$ has mass $1-p$. The probability of switching is $p$ and $B$ has $2x$ with probability $\frac{1}{2}$, therefore $\{(x,-x)\}$ has mass $\frac{1}{2}p$. Let $G$ be the vector of gains. The expected gains are
\begin{align}
\E[G]=\begin{pmatrix}x\\-x\end{pmatrix}\P[\{(x,-x)\}]+\begin{pmatrix}-\frac{1}{2}x\\\frac{1}{2}x\end{pmatrix}\P\left[\left\{\left(-\frac{1}{2}x,\frac{1}{2}x\right)\right\}\right]=\begin{pmatrix}\frac{1}{4}px\\-\frac{1}{4}px\end{pmatrix}.
\end{align}
The expected gains sum to $0$, thus no money is magically put into the system. Furthermore, $A$ will always profit in the long run for any switching strategy with $p>0$ as he initially obtains a fixed value $x$ and the expected value obtained by $B$ is $\E[B]=\frac{5}{4}\E[A]$. Thus Baba must always refuse the switching request from Ali in order to lose no money, giving a trivial non-paradoxical game.

\subsection{Different versions of the Ali Baba problem}
This is just one version of the Ali Baba problem; At least four different variations can be put upon the problem. Those problems are discussed by Nickerson and Falk in 2006 \cite{Nickerson06} and we will give a quick overview. For some variations the optimal strategy is independent of a prior on $X$, for others a prior needs to be taken into account.

Nickerson and Falk considered the following three variants on the Ali Baba problem in \cite{Nickerson06}:
\begin{enumerate}
\item is the distribution on $X$ unknown or from the uniform distribution between $0$ and $100$,
\item do the players know which envelope they received and
\item are the players able to look at the contents?
\end{enumerate}
The first variant is not treated here as we assume that the players do not know the distribution on $X$. Even if they do know, \cite{Nickerson06} only considers the uniform prior between $0$ and $100$ which we find too restrictive and not realistic. Here we always assume that the prior on the first envelope is unknown, possibly unbounded, reducing the number of different problems to four.

\begin{table}
\centering
\begin{tabular}{cc|cc}
Envelope known&Contents known&Ali's choice&Baba's choice\\\hline
Yes&Yes&Trade&Prior\\
Yes&No&Trade&Keep\\
No&Yes&Prior&Prior\\
No&No&Indifferent&Indifferent
\end{tabular}

\caption{Table taken from \cite{Nickerson06} giving advice to Ali and Baba whether they should switch their envelopes. `Envelope known' means that both players know Ali received the first envelope. `Contents known' means both players are allowed to look at their envelope's contents. When `Prior' is stated, Ali or Baba should decide on the prior they impose on the value of their envelope.}
\label{tbl:alibaba}
\end{table}

Table~\ref{tbl:alibaba} gives all optimal strategies. Unfortunately, two out of four cases depend on the prior Ali and Baba impose on their envelope. If both players know the contents of their envelope, the prior on the observed value is needed to give an advice to switching.\\
Note that Ali must always trade if he knows he received the first envelope. In this case the expected value of Baba's envelope is $\E[B]=\frac{5}{4}\E[A]$. In both cases however Baba must either decide on his prior or always keep the envelope, thus blindly switching for all values is only fortunate when the prior has infinite mean. This debunks the paradox in most cases and when the mean is infinite, the paradox can be classified as St.~Petersburg-like.\\
If both players have no information, the symmetry in the game dictates that there is no information to base a player's strategy on. No paradoxical results can be obtained here.

All variants can be investigated further to obtain optimal strategies. Cover's switching strategy can most likely be applied here. I believe that similar results as in the initial two envelope problem will rise here as well. I leave this open for further research.

\section{Concluding remarks}\label{sec:EnvelopeConcl}
The two envelope problem is another example of why performing conditional probability incorrectly can lead to contradicting and paradoxical results. Here paradoxical results arise by wrongly applying conditional probability. Most calculate the expected value of envelope $B$ as
\begin{equation}
\E[B]=\frac{A}{2}\P\left[B=\frac{A}{2}\right]+2A\P[B=2A],
\end{equation}
however random variable $A$ is used here twice with a different context. As observed in Section~\ref{sec:EnvelopeNaive}, the actual calculation should be
\begin{equation}
\E[B]=\E[A|A<B]+\frac{1}{4}\E[A|A>B],
\end{equation}
where $\E[A|A<B]$ and $\E[A|A>B]$ are impossible to calculate without having more information. When the lowest value of both envelopes $X=\min\{A,B\}$ is considered, we observe that
\begin{equation}
\E[A]=\frac{3}{2}\E[X]=\E[B]
\end{equation}
which is not considered as paradoxical.

We now only need to know the distribution of $X$. All probability distributions on $(0,\infty)$ are however possible. In Section~\ref{sec:EnvelopeSafe} we saw that safe probability does not lead to new insights, in contrast to the problems in Chapter~\ref{chap:DiscPara}. Proposition~\ref{prop:EnvelopeIndSafe} states that it is marginally safe to assume that envelope $B$ has twice the value of $A$ with probability of 50\%, however in Section~\ref{sec:EnvelopeFormal} we already saw such distribution does not exist when infinitely many values of $X$ are possible. When $\Psafe$ is unbiased for $\EnvInd|A$, then 
\begin{equation}
\int_0^\infty \Psafe[B=2A|A=a]f_A(a)da=\frac{1}{2}
\end{equation}
is needed, where $f_A$ is the probability density function of $A$. We however need more information on $f_A$ to create a convincing $\Psafe$ satisfying this requirement and this is not possible from the problems statement.

When we state that $B=2A$ happens with probability $\frac{1}{2}$ independent of $A$'s value and we base our decisions on this assumption, we will on average get a return of $\frac{3}{2}\E[X]$. If we drop this assumption, we can improve on this return. Cover switching states that we create a strategy $P\colon(0,\infty)\to[0,1]$ which assigns a probability of switching to each observed value. The gain $G$ relative to the trivial strategies can then be defined by
\begin{equation}
G=\frac{1}{2}\int_0^\infty xf(x)(P(x)-P(2x))dx
\end{equation}
with $f$ the density function on $X$. For the never or always switching strategies we have zero gain. Theorem~\ref{thm:switchall} states that we only need to make $P$ decreasing in order to perform as well as the `never switching' strategy. This is quite intuitive, as you are less likely to swap the envelopes when you initially obtain a high value. When a low value is observed, you will lose less if you swap it for an even lower envelope.\\
Initially it was unknown how much gain a switching strategy yields, as nothing is known of the distribution of $X$. The gain $G$ can therefore become arbitrarily close to zero. You can for example apply threshold switching with $31$ as threshold, while $X$ only takes values higher than $94$. Recently in 2015, Egozcue and Fuentes García \cite{Egozcue15} proved that in certain conditions only depending on the expectation value and variance of the distribution on $X$ an optimal threshold value for threshold switching can be obtained, resulting in a lower bound for the gain which is strictly positive as described in Theorem~\ref{thm:EnvelopeSwitchBound}. In this case one is able to actually improve on the trivial `never switching' strategy by at least a certain amount.

The most important observations for this thesis are in Sections~\ref{sec:EnvelopeNaive} and \ref{sec:EnvelopeFormal}. When explicitly writing down the probability spaces used for studying this problem, one first observes that the calculation performed in Equation~\ref{eq:EnvelopeIntroWrong} is wrong. Furthermore, one observes that the naive probability space of Section~\ref{sec:EnvelopeNaive} with only $\Omega=\{(x,2x),(2x,x)\}$ as sample space is too restrictive. Only then you are able to extend this probability space to the one in Section~\ref{sec:EnvelopeFormal} including all possible distributions on the lowest value $X$. This enables you also to observe that $\P[B=2A|A=a]=\frac{1}{2}$ for all $a\in(0,\infty)$ is simply not possible; an assumption that does follow from safe probability and that everyone starting to study this problem makes. This underlines the message that when performing conditional probability, the probability space with the accompanying $\sigma$-algebra should always be taken into account to avoid paradoxical results.

\bibliographystyle{alpha}
\bibliography{../Referenties/Referenties}

\appendix
\chapter{Corrections to [GHSR17]}
\section{Corrections to appendix 1}\label{app:CorLong}
\pagenumbering{Alph}
In appendix 1, equation 94 of the proof of the conditional expectation on latitudes in \cite{Gyenis17}, they claim that the volume of the unit sphere is $2\pi$, whereas they should have claimed that the surface area of the unit sphere is $4\pi$. Luckily this constant is not actually used in the computations, thus their mistake has no impact on the rest of their article.

\section{Corrections to appendix 2}\label{app:CorMer}
I suggest the following corrections on appendix 2, the proof of conditional expectation on meridians:
\begin{enumerate}
\item In the verification \cite{Gyenis17} claims that $\int_0^\pi\sin\theta d\theta=1$ holds between equations (107) and (108) and between equations (115) and (116), while that integral actually has value $2$.
\item The conditional distribution of \cite{Gyenis17} is verified on a half meridian arc on page 2614, while this distribution must be verified on a full circle in order to be compared with the latitudes. Verification on a full meridian, e.g.~computation of $q(C)$ in formula (85), quickly reveals that the conditional distribution of \cite{Gyenis17} integrates to $2$.
\item The random variable $X$ is integrated on the domain $[0,2\pi)$, while $X$ is only defined on $[0,2\pi)\times[0,\pi]\in\mathfrak{M}$. The set $A\times[0,2\pi)$ is not an element of $\mathfrak{M}$.
\item Between equations (105) and (106) of \cite{Gyenis17}, they implicitly claim that the identity $X(\phi,\theta)=X(\phi,\theta+\pi)$ holds for all $\F$-measurable $X$, where now notation of \cite{Gyenis17} is used. This is most certainly false without any more restrictions on $X$.
\item Before equation (85) a measure $q_\mathcal{M}$ is defined on a whole meridian. Since the integral is taken from $\psi=0$ to $\psi=2\pi$, the integral of $q_\mathcal{M}$ over $S$ becomes $1$. However, as pointed out earlier, $\psi>\pi$ is not in our domain. Thus the integral must be split up in two arcs with $q_{\mathcal{M}}$ taking value $\frac{1}{2}$ on each arc.
\item The normalization constant is used in equation (103) of \cite{Gyenis17} is $2\pi$, where it must be $4\pi$. This does however not impact further calculations, like the same mistake made from equation (109) to (110).
\end{enumerate}

\newpage

\printindex

\end{document}